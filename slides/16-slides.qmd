---
title: "Point Pattern Analysis"
subtitle: "HES 505 Fall 2022: Session 16"
author: "Matt Williamson"
format: 
  revealjs:
    theme: mytheme.scss
    slide-number: true
    show-slide-number: print
    self-contained: true  
---

```{r}
#| include: false
library(tidycensus)
library(sf)
library(tidyverse)
library(socviz)
library(maps)
library(tmap)
library(spData)
library(terra)
library(maptools)
library(spatstat)
library(tmap)
library(gstat)
```

# Objectives {background="#0033A0"}

- Define a point process and their utility for ecological applications

- Define first and second-order Complete Spatial Randomness

- Use several common functions to explore point patterns

- Leverage point patterns to interpolate missing data

## What is a point pattern?

::: columns
::: {.column width="60%"}
::: {style="font-size: 0.7em"}
* _Point pattern_: A __set__ of __events__ within a study region (i.e., a _window_) generated by a random process

* __Set__: A collection of mathematical __events__

* __Events__: The existence of a point object of the type we are interested in at a particular location in the study region

* A _marked point pattern_ refers to a point pattern where the events have additional descriptors

:::
:::
::: {.column width="40%"}
::: {style="font-size: 0.7em"}
__Some notation:__

* $S$: refers to the entire set

* $\mathbf{s_i}$ denotes the vector of data describing point $s_i$ in set $S$

* $\#(S \in A )$ refers to the number of points in $S$ within study area $A$
:::
:::
:::

## Requirements for a set to be considered a point pattern

* The pattern must be mapped on a plane to preserve distance

* The study area, $A$, should be objectively determined

* There should be a $1:1$ correspondence between objects in $A$ and events in the pattern

* Events must be _proper_ i.e., refer to actual locations of the event

* For some analyses the pattern should be a census of the relevant events

## Describing Point Patterns

::: columns
::: {.column width="60%"}
::: {style="font-size: 0.7em"}

* _Density-based metrics_: the $\#$ of points within area, $a$, in study area $A$

* _Distance-based metrics_: based on nearest neighbor distances or the distance matrix for all points

* _First order_ effects reflect variation in __intensity__ due to variation in the 'attractiveness' of locations

* _Second order_ effects reflect variation in __intensity__ due to the presence of points themselves
:::
:::
::: {.column width="40%"}
![from Manuel Gimond](img/slide_16/1st_2nd_order_property.png)
:::
:::
## Centrography
::: columns
::: {.column width="40%"}
::: {style="font-size: 0.7em"}
* _Mean center_: the point, $\hat{\mathbf{s}}$, whose coordinates are the average of all events in the pattern
* _Standard distance_: a measure of the dispersion of points around the _mean center_
* _Standard ellipse_: dispersion in one dimension
:::
:::
::: {.column width="60%"}
![From Manuel Gimond](img/slide_16/centrography.png) 
:::
:::

## Analyzing Point Patterns

* Modeling random processes means we are interested in probability densities of the points (first-order;density)

* Also interested in how the presence of some events affects the probability of other events (second-order;distance)

* Finally interested in how the attributes of an event affect location (marked)

* Need to introduce a few new packages (`spatstat` and `gstat`)


## Density based methods

::: columns
::: {.column width="60%"}

* The overall _intensity_ of a point pattern is a crude density estimate

$$
\begin{equation}
\hat{\lambda} = \frac{\#(S \in A )}{a}
\end{equation}
$$

* Local density = quadrat counts
:::
::: {.column width="40%"}
```{r}
#| fig-width: 5
#| fig-height: 5
nclust <- function(x0, y0, radius, n) {
              return(runifdisc(n, radius, centre=c(x0, y0)))
            }
x <- rpoispp(lambda =50)
Q = quadratcount(x)
plot(x, main="")
plot(Q, add=TRUE)
```
:::
:::


# Analyzing Point Patterns {background="#0033A0"}

## Kernel Density Estimates (KDE)

$$
\begin{equation}
\hat{f}(x) = \frac{1}{nh_xh_y} \sum_{i=1}^n k\bigg(\frac{{x-x_i}}{h_x},\frac{{y-y_i}}{h_y} \bigg)
\end{equation}
$$
::: {style="font-size: 0.7em"}
* Assume each location in $\mathbf{s_i}$ drawn from unknown distribution

* Distribution has probability density $f(\mathbf{x})$

* Estimate $f(\mathbf{x})$ by averaging probability "bumps" around each location

* Need different object types for most operations in `R` (`as.ppp`)
:::

## Kernel Density Estimates (KDE)
::: {style="font-size: 0.7em"}
* $h$ is the bandwidth and $k$ is the kernel

* We can use `stats::density` to explore

* __kernel__: defines the shape, size, and weight assigned to observations in the window

* __bandwidth__ often assigned based on distance from the window center

```{r}
#| echo: true
x <- rpoispp(lambda =50)
K1 <- density(x, bw=2)
K2 <- density(x, bw=10)
K3 <- density(x, bw=2, kernel="disc")
```
:::
```{r}
par(mfrow=c(1,3))
plot(K1, main="Bandwidth=2")
plot(K2, main="Bandwidth=10")
plot(K3, main="Bandwidth=2, kernel=disc")
par(mfrow=c(1,1))
```

## Choosing bandwidths and kernels

* Small values for $h$ give 'spiky' densities

* Large values for $h$ smooth much more

* Some kernels have optimal bandwidth detection

* `tmap` package (later) provides additional functionality

# Second-Order Analysis {background="#0033A0"}

## Second-Order Analysis

* KDEs assume independence of points (first order randomness)

* Second-order methods allow dependence amongst points (second-order randomness)

* Several functions for assessing second order dependence ($K$, $L$, and $G$)

## Distance based metrics
::: columns
::: {.column width="60%"}
* Provide an estimate of the _second order_ effects

* _Mean nearest-neighbor distance_:
$$\hat{d_{min}} = \frac{\sum_{i = 1}^{m} d_{min}(\mathbf{s_i})}{n}$$
:::
::: {.column width="40%"}
```{r}
#| echo: true

ANN <- apply(nndist(x, k=1:50),2,FUN=mean)
plot(ANN ~ eval(1:50), type="b", main=NULL, las=1)
```
:::
:::

## Ripley's $K$ Function
::: {style="font-size: 0.7em"}
* Nearest neighbor methods throw away a lot of information

* If points have independent, fixed marginal densities, then they exhibit _complete, spatial randomness_ (CSR)

* The _K_ function is an alternative, based on a series of circles with increasing radius

$$
\begin{equation}
K(d) = \lambda^{-1}E(N_d)
\end{equation}
$$

* We can test for clustering by comparing to the expectation:

$$
\begin{equation}
K_{CSR}(d) = \pi d^2
\end{equation}
$$
* if $k(d) > K_{CSR}(d)$ then there is clustering at the scale defined by $d$
:::

## Ripley's $K$ Function

* When working with a sample the distribution of $K$ is unknown

* Estimate with

$$
\begin{equation}
\hat{K}(d) = \hat{\lambda}^{-1}\sum_{i=1}^n\sum_{j=1}^n\frac{I(d_{ij} <d)}{n(n-1)}
\end{equation}
$$

where:
$$
\begin{equation}
\hat{\lambda} = \frac{n}{|A|}
\end{equation}
$$
## Ripley's $K$ Function

* Using the `spatstat` package

::: columns
::: {.column width="40%"}
```{r}
#| fig-width: 4
#| fig-height: 4
data(bramblecanes)
plot(bramblecanes)
```
:::
::: {.column width="60%"}
```{r}
#| echo: true
kf <- Kest(bramblecanes, correction-"border")
plot(kf)
```
:::
:::

## Ripley's $K$ Function
* accounting for variation in $d$

```{r}
#| echo: true
kf.env <- envelope(bramblecanes, correction="border", envelope = FALSE, verbose = FALSE)
plot(kf.env)
```

## Other functions

::: columns
::: {.column width="60%"}
* $L$ function: square root transformation of $K$

* $G$ function: the cummulative frequency distribution of the nearest neighbor distances

* $F$ function: similar to $G$ but based on randomly located points


:::
::: {.column width="40%"}
```{r}
#| fig-width: 5
#| fig-height: 5
gf.env <- envelope(bramblecanes, Gest, correction="border", verbose = FALSE)
plot(gf.env)
```
:::
:::

