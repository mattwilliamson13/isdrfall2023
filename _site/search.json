[
  {
    "objectID": "assignment/01-intro.html",
    "href": "assignment/01-intro.html",
    "title": "Assignment 1: Introductory material",
    "section": "",
    "text": "The first part of the course was designed to introduce some of the foundations of working in R, developing programming workflows, and getting help. These topics are important for building robust spatial workflows, but their utility extends beyond that to most things you’ll do in R during the course of your graduate research. This homework is meant to help reinforce those concepts and identify any gaps that I need to fill in as we go. Make sure to check out the example too!. By the end of this assignment you should be able to:\nYou’ll need to accept the link to access the questions."
  },
  {
    "objectID": "assignment/01-intro.html#instructions",
    "href": "assignment/01-intro.html#instructions",
    "title": "Assignment 1: Introductory material",
    "section": "Instructions",
    "text": "Instructions\n\nAfter you’ve joined the assignment repository, you should have this file (named Readme.md) inside of a R project named assignment-1-xx where xx is your github username (or initials).\nOnce you’ve verified that you’ve correctly cloned the assignment repository, create a new Quarto document. Name this file assignment-1-xxx.qmd and give it a title (like M Williamson Assignment 1). Make sure that you select the html output option (Quarto can do a lot of cool things, but the html format is the least-likely to cause you additional headaches). We’ll be using Quarto throughout the course so it’s worth checking out the other tutorials in the getting started section.\nCopy the questions below into your document and change the color of their text.\nSave the changes and make your first commit!\nAnswer the questions making sure save and commit at least 4 more times (having 5 commits is part of the assignment).\nRender the document to html (you should now have at least 3 files in the repository: Readme.md, assignment-1-xx.qmd, and assignment-1-xx.html). Commit these changes and push them to the repository on GitHub. You should see the files there when you go to github.com."
  },
  {
    "objectID": "assignment/final-proj.html",
    "href": "assignment/final-proj.html",
    "title": "Final Project",
    "section": "",
    "text": "The final project is an opportunity to bring all of the things you’ve learned in the course into a single reproducible workflow to answer a question of your choosing. Because each of you are in different stages of collecting your own data and because confronting datasets that aren’t yours can help clarify important concepts and design elements, I’m asking you to develop an analysis of data that isn’t yours. This final project should help you demonstrate:\n\nProper data management, cleaning, and manipulation technques\nThe ability to summarize spatial data and apply different statistical analyses to it\nThe ability to evaluate the performance of statistical models\nThe ability to generate visualizations that support your analyses\nThe ability to integrate code, analysis, and visualization with text descrbing your approach and discussing your results"
  },
  {
    "objectID": "assignment/final-proj.html#requirements",
    "href": "assignment/final-proj.html#requirements",
    "title": "Final Project",
    "section": "Requirements",
    "text": "Requirements\nDatasets. The ability to manipulate and integrate a variety of data types, resolutions, and formats is a key component of this course. Your analysis should incorporate at least 5 datasets. The ultimate compostion of your database is up to you, but I’d like you to include 1 tabular dataset, 1 vector dataset, and 1 raster dataset. You should choose the other 2 (or more) to give you practice with the data types that are most relevant to your objectives and/or research.\nAnalyses. You’ve learned several classes of analyses (e.g., overlays, point-pattern, multivariate regression, and statistical learning). Apply at least one (preferably the one most tied to your own objectives and research) of these analyses to address your question. In the course of doing so, you’ll need to justify your choice, assess whether your data meets appropriate assumptions, and evaluate the implications of key assumptions you make. For example, if you’re conducting an overlay analysis, how does your choice of threshold affect the ultimate result? If you’ve fit a statistical model based on summary statistics (e.g, mean, median), how well does the model fit? How does the model change if you use different slices of the data?\nVisualizations. You should produce a minimum of 3 visualizations to accompany your analysis. One of these should be a publication quality location map. The others are up to you, but should a) help you tell the story of your analysis and b) help you meet your objectives for the course and your own research. These can be additional maps of results, figures that summarize your data or results in non-spatial ways, or interactive graphics that allow you to explore parts of your analysis.\nReporting You can generate a ‘manuscript’ style document (using Quarto) or a flexdashboard (using Quarto and shiny) as the final product. Your report should include:\n\nA brief (1-2 paragraphs) description of your question and why you’re interested in it.\nA Methods section with subsections describing the data sources, any processing steps you took and why, and your process for the analysis. Show your code and provide annotation to describe what you are attempting do with the various steps.\nA Results section that includes tabular results as well as any relevant visualizations that describe your data and analysis.\nA Discussion of your results that puts your results in the context of your question, considers alternative analysis strategies and why they may or may not be better than the approach you chose, describes additional data that might be important for your question, and considers the role of extent and resolution in your analysis."
  },
  {
    "objectID": "assignment/final-proj.html#assessment",
    "href": "assignment/final-proj.html#assessment",
    "title": "Final Project",
    "section": "Assessment",
    "text": "Assessment\nYou’ll submit a draft of the final report on December 7. I’ll give you feedback based on your project and on your objectives for the course. You’ll then have a chance to address my feedback before turning in your final draft on December 15. Your final self-assessment will ask you to reflect on your objectives for the course and evaluate the degree to which your final project demonstrates that you achieved your objectives. Thus, when you are designing your project, make sure that you have your initial objectives in mind.\n\n\n\n\n\n\nTip\n\n\n\nA note on grades: You will be responsible for assessing how well your assignment demonstrates that you achieved your objectives. I reserve the right to change the grade you’ve given yourself, but will provide clear justification for why I’m doing that. Without a completed self-assessment there is no grade for your final project, so please make sure you complete it."
  },
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Assignments",
    "section": "",
    "text": "The main goals of this class is class is to get you comfortable with the manipulation, analysis, and visualization of spatial data using the R computing environment. These assignments are designed to help you practice those skills and reflect on your progress. All of the assignments have their own repository in our GitHub classroom, so you’ll submit them there. I’ll transfer grades over to Canvas so you’ll have an idea where you’re at in the course, but we won’t use Canvas for much else."
  },
  {
    "objectID": "assignment/index.html#self-reflections",
    "href": "assignment/index.html#self-reflections",
    "title": "Assignments",
    "section": "Self-reflections",
    "text": "Self-reflections\nThis course is collaborative. I’m hoping to provide a broad suite of information that can help you analyze spatial data for your graduate research and beyond. That said, you know more than I do about your personal and professional objectives. During the course of the semester, I’ll ask you to submit 3 self-reflections. The first should help me get to know you and get us on the same page with respect to your goals for the course. The second and third will help us assess your progress relative to those goals and identify ways to make sure you’re getting to where you want to go. These self-reflections are the foundation of how you’ll be ‘graded’ in this course, so they are mandatory and need to be submitted by the due date"
  },
  {
    "objectID": "assignment/index.html#problem-sets",
    "href": "assignment/index.html#problem-sets",
    "title": "Assignments",
    "section": "Problem sets",
    "text": "Problem sets\nI’ve created four assignments to practice outlining a workflow, writing R code, and troubleshooting errors. Each assignment integrates concepts from multiple class sessions in an effort to cement new concepts and make sure you don’t forget things you learned earlier in the semester. As such, they involve multiple sections and may take some time. Each week I’ll announce which sections of the homework are most applicable so that you know about where you should be in terms of completing it. The idea is to have you work a bit on the homework throughout each unit. This is to reduce the likelihood that you’ll spend 10 hours on it the day before it’s due and also to encourage you to get in the habit of using git to keep track of your progress.\nI’ll be grading these according to: * Please Resubmit: This indicates that either your code does not run as written (i.e., your Rmarkdown document will not compile on my computer), you did not use Git as instructed, and/or that your responses to the questions I posed indicate that you do not quite understand the material as well as I would like. You’ll need to schedule an appointment to talk with me and we’ll work out what you need to do to get credit for the assignment. Although there isn’t a hard deadline for this resubmission, the assignments build on each other so it’s in your best interest to complete the resubmission before the next assignment. Failure to resubmit will result in no credit for the assignment.\n\nResubmit If You Like: This indicates that all of the code works as written and that you used Git, but that you may have missed some important concepts. Your are welcome to resubmit the assignment and address my comments to help polish the final product, but it is not required for you to get credit for the assignment.\nGood To Go: All of your code works, you completed the necessary Git steps, and all of the pieces are there and polished. I may have some minor comments, but I don’t need you to address them for this assignment.\n\n\n\n\n\n\n\nTip\n\n\n\nLate Work: There is no such thing as ‘late work’ with these assignments. Life happens, sometimes things take longer to finish than you expect. If you turn it in, I’ll give you feedback. That said, the assignments build on each other so it’s probably best to avoid falling too far behind."
  },
  {
    "objectID": "assignment/index.html#final-project",
    "href": "assignment/index.html#final-project",
    "title": "Assignments",
    "section": "Final project",
    "text": "Final project\nAt the end of the course, you will demonstrate your knowledge of spatial analysis workflows through a final project that requires you to integrate a variety of spatial datasets, analyze the data with respect to a question of interest, and create visuals that help you interpret the data.\nComplete details for the final project are here.\nThere is no final exam. This project is your final exam."
  },
  {
    "objectID": "assignment/self-eval1.html",
    "href": "assignment/self-eval1.html",
    "title": "Self-reflection 1",
    "section": "",
    "text": "This is the first of three self-reflections that you’ll complete during the course. These provide an opportunity for me to learn more about you, check-in on how the course is going, and make sure that getting what you need from the course materials. This first reflection also helps us set the standards for your assessment in the course. As such, I’m asking that you complete this in a timely fashion and turn it in by Aug. 30. You’ll need to accept the link to access the questions."
  },
  {
    "objectID": "assignment/self-eval1.html#instructions",
    "href": "assignment/self-eval1.html#instructions",
    "title": "Self-reflection 1",
    "section": "Instructions",
    "text": "Instructions\n\nAfter you’ve joined the assignment repository, you should have this file (named Readme.md) inside of a R project named self-reflection-1-xx where xx is your github username (or initials).\nOnce you’ve verified that you’ve correctly cloned the assignment repository, create a new Quarto document. Name this file self-reflection-1-xxx.qmd and give it a title (like M Williamson Self-Reflection 1). Make sure that you select the html output option (Quarto can do a lot of cool things, but the html format is the least-likely to cause you additional headaches). We’ll be using Quarto throughout the course so it’s worth checking out the other tutorials in the getting started section.\nCopy the questions below into your document and change the color of their text.\nSave the changes and make your first commit!\nAnswer the questions making sure save and commit at least 4 more times (having 5 commits is part of the assignment).\nRender the document to html (you should now have at least 3 files in the repository: Readme.md, self-reflection-1-xx.qmd, and self-reflection-1-xx.html). Commit these changes and push them to the repository on GitHub. You should see the files there when you go to github.com."
  },
  {
    "objectID": "assignment/self-eval2.html",
    "href": "assignment/self-eval2.html",
    "title": "Self-reflection 2",
    "section": "",
    "text": "This is the second of three self-reflections that you’ll complete during the course. We’ll revisit your objectives and check-in on what I can do to help you get the most out of the second half of the course. This is our mid-semester “adjustment”. As such, I’m asking that you complete this in a timely fashion and turn it in by Oct 18. You’ll need to accept the link to access the questions."
  },
  {
    "objectID": "assignment/self-eval2.html#instructions",
    "href": "assignment/self-eval2.html#instructions",
    "title": "Self-reflection 2",
    "section": "Instructions",
    "text": "Instructions\n\nAfter you’ve joined the assignment repository, you should have this file (named Readme.md) inside of a R project named self-reflection-2-xx where xx is your github username (or initials).\nOnce you’ve verified that you’ve correctly cloned the assignment repository, create a new Quarto document. Name this file self-reflection-2-xxx.qmd and give it a title (like M Williamson Self-Reflection 2). Make sure that you select the html output option.\nCopy the questions below into your document and change the color of their text.\nSave the changes and make your first commit!\nAnswer the questions making sure save and commit at least 4 more times (having 5 commits is part of the assignment).\nRender the document to html (you should now have at least 3 files in the repository: Readme.md, self-reflection-2-xx.qmd, and self-reflection-2-xx.html). Commit these changes and push them to the repository on GitHub. You should see the files there when you go to github.com."
  },
  {
    "objectID": "assignment/self-eval3.html",
    "href": "assignment/self-eval3.html",
    "title": "Self-reflection 3",
    "section": "",
    "text": "This is the final self-reflection for the course and provides a way of evaluating your final project relative to your course learning objectives. This final self-reflection is critical for assigning your grades on the final project and the course, in general. As such, I’m asking that you complete this in a timely fashion and turn it in by Dec. 16. You’ll need to accept the link to access the questions."
  },
  {
    "objectID": "assignment/self-eval3.html#instructions",
    "href": "assignment/self-eval3.html#instructions",
    "title": "Self-reflection 3",
    "section": "Instructions",
    "text": "Instructions\n\nAfter you’ve joined the assignment repository, you should have this file (named Readme.md) inside of a R project named self-reflection-1-xx where xx is your github username (or initials).\nOnce you’ve verified that you’ve correctly cloned the assignment repository, create a new Quarto document. Name this file self-reflection-1-xxx.qmd and give it a title (like M Williamson Self-Reflection 1). Make sure that you select the html output option (Quarto can do a lot of cool things, but the html format is the least-likely to cause you additional headaches). We’ll be using Quarto throughout the course so it’s worth checking out the other tutorials in the getting started section.\nCopy the questions below into your document and change the color of their text.\nSave the changes and make your first commit!\nAnswer the questions making sure save and commit at least 4 more times (having 5 commits is part of the assignment).\nRender the document to html (you should now have at least 3 files in the repository: Readme.md, self-reflection-1-xx.qmd, and self-reflection-1-xx.html). Commit these changes and push them to the repository on GitHub. You should see the files there when you go to github.com."
  },
  {
    "objectID": "content/01-content.html",
    "href": "content/01-content.html",
    "title": "Getting Started",
    "section": "",
    "text": "Today we’ll focus on getting oriented to the course and the tools we’ll be using throughout the semester. Readings are designed to help understand some of the ‘rules’ of R syntax and develop an understanding for manipulating different types of data in R."
  },
  {
    "objectID": "content/01-content.html#readings",
    "href": "content/01-content.html#readings",
    "title": "Getting Started",
    "section": "Readings",
    "text": "Readings\n\nThe syllabus, content, examples, and assignments pages for this class\n Chapter 1 - 6 in Venables et al., An Introduction to R (Venables et al. 2009) - for a quick refresher on data types in R (it’s only 30 pages)\n Chapters 1-2 in Douglas et al., An Introduction to R - provides another intro to R that’s been updated and is an open-source book.\n Happy Git and GitHub for the useR - all you really need to know to be a proficient user of git for version control and reproducible workflows."
  },
  {
    "objectID": "content/01-content.html#objectives",
    "href": "content/01-content.html#objectives",
    "title": "Getting Started",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today you should:\n\nBe able to articulate the organization of the course, the approach to grading, and the requirements for the final project\nBe able to access the RStudio Server and Github classroom\nBe able to clone the first self-reflection and assignment and know the process for submitting assignments"
  },
  {
    "objectID": "content/01-content.html#slides",
    "href": "content/01-content.html#slides",
    "title": "Getting Started",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nIntroductions\n\n\nWhy (not) R?\n\n\nAssignments, reflections, expectations\n\n\nGit and github classroom"
  },
  {
    "objectID": "content/02-content.html",
    "href": "content/02-content.html",
    "title": "Basic Data Structures in R",
    "section": "",
    "text": "Today we’ll focus on how R organizes data and how you can managed and manipulate data in R. Readings are designed to give you more information how R conceptualizes data and how various rules and conventions affect your ability to access and manipulate data."
  },
  {
    "objectID": "content/02-content.html#readings",
    "href": "content/02-content.html#readings",
    "title": "Basic Data Structures in R",
    "section": "Readings",
    "text": "Readings\n\n Chapter 3 in Douglas et al., An Introduction to R - provides another intro to R that’s been updated and is an open-source book.\n Writing the perfect question - a blogpost by Jon Skeet that describes the general etiquette for asking coding questions that are likely to get answered.\n Reprex Do’s and Don’ts - provides an overview of the components of a reproducible example and the use of the reprex package to generate them."
  },
  {
    "objectID": "content/02-content.html#objectives",
    "href": "content/02-content.html#objectives",
    "title": "Basic Data Structures in R",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today you should:\n\nBe able to distinguish the major datatypes used in R and deploy functions to determine the data type of a given object.\nBe able to subset and manipulate data using base R and the tidyverse\nUnderstand the key elements of getting help with coding errors"
  },
  {
    "objectID": "content/02-content.html#slides",
    "href": "content/02-content.html#slides",
    "title": "Basic Data Structures in R",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nBasic Data Structures in R\n\n\nAccessing subsets of data\n\n\nManipulating and combining data\n\n\nGetting help"
  },
  {
    "objectID": "content/03-content.html",
    "href": "content/03-content.html",
    "title": "Quarto, pseudocode, and literate programming",
    "section": "",
    "text": "Today we’ll focus on some of the tools for reproducible workflows using R. We’ll introduce Quarto as a means of authoring different kinds of documents. We’ll talk about literate programming and leaving breadcrumbs for yourself (and others). Finally, we’ll begin to work through the ideas of workflow planning"
  },
  {
    "objectID": "content/03-content.html#readings",
    "href": "content/03-content.html#readings",
    "title": "Quarto, pseudocode, and literate programming",
    "section": "Readings",
    "text": "Readings\n\n Authoring in Quarto - an intro to Quarto for developing different kinds of documents. Lots of other resources linked here!!\n Pseudocode: what it is and how to write it - A nice blogpost by Sara Metawalli the sketches out the logic of pseudocode and why it can be helpful.\n The Whole Game - from Wickham et al., R for Data Science (Wickham and Grolemund 2016). Focus on the sections that begin with “Workflow” to get a sense for how we’ll start putting the pieces together.\n Scripts, algorithms, and functions - chapter 11 in in Lovelace et al., Geocomputation with R (Lovelace et al. 2019) introduces some concepts behind geospatial programming. A few of these pieces will make more sense in the next few weeks, but the general advice on constructing code and planning analyses is useful now."
  },
  {
    "objectID": "content/03-content.html#objectives",
    "href": "content/03-content.html#objectives",
    "title": "Quarto, pseudocode, and literate programming",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today you should:\n\nBe able to develop basic docs with Quarto\nUnderstand the basics of creating readable code\nUse pseudocode to sketch out a computational problem"
  },
  {
    "objectID": "content/03-content.html#slides",
    "href": "content/03-content.html#slides",
    "title": "Quarto, pseudocode, and literate programming",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nLiterate programming\n\n\nIntroducing Quarto\n\n\nPlanning your workflow"
  },
  {
    "objectID": "content/04-content.html",
    "href": "content/04-content.html",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "",
    "text": "Functions - from Wickham et al., R for Data Science (Wickham and Grolemund 2016) describes the logic of functions and how to approach them with R and the tidyverse.\n Iteration - from Wickham et al., R for Data Science (Wickham and Grolemund 2016) provides an introduction to iteration using for loops and then builds on that to introduce the map family of functions.\n The Apply Family - from the UC Business Analytics R Programming Guide provides a nice reference on the apply family. These functions are very powerful, but their syntax isn’t as intuitive."
  },
  {
    "objectID": "content/04-content.html#objectives",
    "href": "content/04-content.html#objectives",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today, you should be able to:\n\nDescribe the benefit of functions\nDescribe the basic components of functions\nDesign your own simple functions\nUse the apply and map families of functions to automate repetitive tasks"
  },
  {
    "objectID": "content/04-content.html#slides",
    "href": "content/04-content.html#slides",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nWhy use functions?\n\n\nDesigning functions\n\n\nThe map and apply families"
  },
  {
    "objectID": "content/06-content.html",
    "href": "content/06-content.html",
    "title": "Spatial Data is Special Data",
    "section": "",
    "text": "Coordinate Reference Systems Section 2.4 in Lovelace et al., Geocomputation with R (Lovelace et al. 2019)\n Chapter 1: Introduction in Essentials of Geographic Information Systems by Campbell and Shin (Campbell and Shin 2011)\n Scale and Projections - a portion of Mapping, Society, and Technology an Laura Matson and Melinda Kernik."
  },
  {
    "objectID": "content/06-content.html#objectives",
    "href": "content/06-content.html#objectives",
    "title": "Spatial Data is Special Data",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today, you should be able to:\n\nArticulate why we care about space\nDescribe elements of spatial data\nDefine a coordinate reference system and its importance\nDescribe several ways to load spatial data into R\nIdentify, assign, and change projections R"
  },
  {
    "objectID": "content/06-content.html#slides",
    "href": "content/06-content.html#slides",
    "title": "Spatial Data is Special Data",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nGeography\n\n\nProjections\n\n\nSpatial Data in R"
  },
  {
    "objectID": "content/07-content.html",
    "href": "content/07-content.html",
    "title": "Spatial Data as Vectors",
    "section": "",
    "text": "The introductory vignette for the sf package has a lot of useful info on sf objects and conventions.\n Section 2.2 on Vector Data and Sections 5.1-5.3 on Geographic Operations in Lovelace et al. (Lovelace et al. 2019) - for more details about vectors and geometric operations on vectors.\n Section 3.1 and 3.2 of Spatial Data Science, a bookdown project by Edzer Pebesma and Roger Bivand (of the sf, sp, rgeos, and rgdal packages)"
  },
  {
    "objectID": "content/07-content.html#objectives",
    "href": "content/07-content.html#objectives",
    "title": "Spatial Data as Vectors",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today, you should be able to:\n\nArticulate the role of the data model in geographic information systems\nDescribe the key elements of vector data\nUse the sf package to read and manipulate vector data\nDefine geometry in the context of vector objects and troubleshoot common problems"
  },
  {
    "objectID": "content/07-content.html#slides",
    "href": "content/07-content.html#slides",
    "title": "Spatial Data as Vectors",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nGeography\n\n\nProjections\n\n\nSpatial Data in R"
  },
  {
    "objectID": "content/08-content.html",
    "href": "content/08-content.html",
    "title": "Operations on Vector Data I",
    "section": "",
    "text": "We are going to continue building on the use of the vector data model so we’ll keep working through the readings from last session.\n\n The introductory vignette for the sf package has a lot of useful info on sf objects and conventions.\n Section 2.2 on Vector Data and Sections 5.1-5.3 on Geographic Operations in Lovelace et al. (Lovelace et al. 2019) - for more details about vectors and geometric operations on vectors.\n Section 3.1 and 3.2 of Spatial Data Science, a bookdown project by Edzer Pebesma and Roger Bivand (of the sf, sp, rgeos, and rgdal packages)"
  },
  {
    "objectID": "content/08-content.html#objectives",
    "href": "content/08-content.html#objectives",
    "title": "Operations on Vector Data I",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today, you should be able to:\n\nDefine valid geometries and approaches for validating geometries in R\nUnderstand predicates and measures in the context of spatial operations in sf\nUse st_* to evaluate attributes of geometries and calculate measurements"
  },
  {
    "objectID": "content/08-content.html#slides",
    "href": "content/08-content.html#slides",
    "title": "Operations on Vector Data I",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nValid Geometries\n\n\nPredicates\n\n\nMeasurements"
  },
  {
    "objectID": "content/09-content.html",
    "href": "content/09-content.html",
    "title": "Operations on Vector Data II",
    "section": "",
    "text": "We are going to continue building on the use of the vector data model so we’ll keep working through the readings from last session.\n\n The introductory vignette for the sf package has a lot of useful info on sf objects and conventions.\n Section 2.2 on Vector Data and Sections 5.1-5.3 on Geographic Operations in Lovelace et al. (Lovelace et al. 2019) - for more details about vectors and geometric operations on vectors.\n Section 3.1 and 3.2 of Spatial Data Science, a bookdown project by Edzer Pebesma and Roger Bivand (of the sf, sp, rgeos, and rgdal packages)"
  },
  {
    "objectID": "content/09-content.html#objectives",
    "href": "content/09-content.html#objectives",
    "title": "Operations on Vector Data II",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today, you should be able to:\n\nComplete a workflow for identifying and remedying invalid geometries\nDescribe the various unary, binary, and n-ary transformers\nUse predicates and dplyr::filter to subset spatial data"
  },
  {
    "objectID": "content/09-content.html#slides",
    "href": "content/09-content.html#slides",
    "title": "Operations on Vector Data II",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nFinal Project\n\n\nTransformations\n\n\nSubsetting"
  },
  {
    "objectID": "content/10-content.html",
    "href": "content/10-content.html",
    "title": "Spatial data as matrices and rasters",
    "section": "",
    "text": "Today we’ll be exploring the raster data model and how it is implemented within the spatial packages in the R computing environment. These chapters are not ‘prerequisite’ reading for the week, but provide a lot of helpful background for raster proccessing in R.\n\n The raster package vignette has a number of helpful examples for different workflows with raster objects in R.\n The terra package vignette describes the new raster functions available in terra, their relationship to those in the raster package, and the changes in syntax between the two.\n The Functional Programming and Measuring performance from Advanced R (Wickham 2019) provide an excellent introduction to developing your own functions for repeated operations and ways to optimise code for large problems. Raster data processing often involves repeating (sometimes multiple) steps 100s of times. These chapters introduce strategies for developing functions for repeated operations and identfying and fixing bottlenecks in those functions."
  },
  {
    "objectID": "content/10-content.html#objectives",
    "href": "content/10-content.html#objectives",
    "title": "Spatial data as matrices and rasters",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today, you should be able to:\n\nDescribe the raster data model and its representation in R\nAccess the elements that define a raster\nBuild rasters from scratch using matrix operations and terra"
  },
  {
    "objectID": "content/10-content.html#slides",
    "href": "content/10-content.html#slides",
    "title": "Spatial data as matrices and rasters",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nThe Raster Data Model\n\n\nComponents of Rasters in R\n\n\nBuilding Rasters"
  },
  {
    "objectID": "content/11-content.html",
    "href": "content/11-content.html",
    "title": "Operations With Raster Data I",
    "section": "",
    "text": "Now that we’ve learned a bit about the raster data model, we’ll begin using terra to manage and manipulate rasters. We’ll start with some of the predicate and measure functions and build up to more complex transformations.\n\n The terra package vignette describes the new raster functions available in terra, their relationship to those in the raster package, and the changes in syntax between the two.\n The Raster GIS Operations in R with terra chapter from Jasper Slingsby’s “A Minimal Introduction to GIS (in R)” bookdown project has worked examples of many of the operations we’ll learn today."
  },
  {
    "objectID": "content/11-content.html#objectives",
    "href": "content/11-content.html#objectives",
    "title": "Operations With Raster Data I",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today, you should be able to:\n\nEvaluate logical conditions with raster data\nCalculate different measures of raster data\nAlign rasters for spatial processing"
  },
  {
    "objectID": "content/11-content.html#slides",
    "href": "content/11-content.html#slides",
    "title": "Operations With Raster Data I",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nPredicates\n\n\nMeasures\n\n\nAligning Rasters"
  },
  {
    "objectID": "content/12-content.html",
    "href": "content/12-content.html",
    "title": "Operations With Raster Data II",
    "section": "",
    "text": "One of the most attractive reasons for using the raster data model (and terra, specifically) is the relative ease and speed with which you can manipulate values within a raster or combine multiple rasters to generate new data. We’ll focus on that today.\n\n The terra package vignette describes the new raster functions available in terra, their relationship to those in the raster package, and the changes in syntax between the two.\n The Raster GIS Operations in R with terra chapter from Jasper Slingsby’s “A Minimal Introduction to GIS (in R)” bookdown project has worked examples of many of the operations we’ll learn today."
  },
  {
    "objectID": "content/12-content.html#objectives",
    "href": "content/12-content.html#objectives",
    "title": "Operations With Raster Data II",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today, you should be able to:\n\nAccess and manipulate cell values of a raster\nGenerate new rasters using mathematical functions\nSummarize rasters using global functions\nGenerate new rasters describing the spatial context of individual cells"
  },
  {
    "objectID": "content/12-content.html#slides",
    "href": "content/12-content.html#slides",
    "title": "Operations With Raster Data II",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nRevisiting Projections\n\n\nCell-based operations\n\n\nGlobal operations\n\n\nContext methods"
  },
  {
    "objectID": "content/13-content.html",
    "href": "content/13-content.html",
    "title": "Combining Raster and Vector Data",
    "section": "",
    "text": "As we move towards a complete geospatial statistical workflow, we’ll need to be able to combine data from both raster and vector datasets. Sometimes that will mean simply converting from one format to another. In other cases, we’ll need to create new datasets based on calculations that integrate different data models. We’ll do some of that today.\n\n The Integrating rasters and vectors chapter of Michael Dorman’s Introduction to Spatial Data Programming with R online textbook has a number of worked examples combining vector and raster data.\n Raster-vector interactions Chapter 6 in Lovelace et al., Geocomputation with R (Lovelace et al. 2019) has a great description of why you might do some of these things in your analysis."
  },
  {
    "objectID": "content/13-content.html#objectives",
    "href": "content/13-content.html#objectives",
    "title": "Combining Raster and Vector Data",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today, you should be able to:\n\nClip, crop, or extend vector and raster data so that extents align\nConvert between raster and vector datasets\nGenerate new rasters describing the spatial arrangement of vector data\nExtract raster values as attributes of vector data"
  },
  {
    "objectID": "content/13-content.html#slides",
    "href": "content/13-content.html#slides",
    "title": "Combining Raster and Vector Data",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nModifying the extent\n\n\nConversions\n\n\nDistance\n\n\nExtractions"
  },
  {
    "objectID": "content/14-content.html",
    "href": "content/14-content.html",
    "title": "Building Spatial Databases with Attributes",
    "section": "",
    "text": "Today we’ll begin exploring typical workflows for spatial analysis by working with attribute data. Attributes generally provide additional information about a location that we can use for visualization and analysis. Unlike spatial operations that we’ll explore next week, attribute data do not all require geographic information (but they do need some means of relating to a geography). These chapters are not ‘prerequisite’ reading for the week, but provide a lot of helpful background for attribute operations in R.\n\n The Tidy Data and Relational Data sections from R For Data Science (Wickham and Grolemund 2016) provide a great overview to data cleaning and manipulation functions available in the tidyverse.\n Doing things with multiple tables has a lot of nice visual examples of for using the _join functions in dplyr.\n This article (Di Minin et al. 2021) provides a recent recap of a variety of reasons why we may need to combine data from multiple, often disparate, sources."
  },
  {
    "objectID": "content/14-content.html#objectives",
    "href": "content/14-content.html#objectives",
    "title": "Building Spatial Databases with Attributes",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today, you should be able to:\n\nDefine spatial analysis\nDescribe the steps in planning a spatial analysis\nUnderstand the structure of relational databases\nBegin building a database for spatial analysis"
  },
  {
    "objectID": "content/14-content.html#slides",
    "href": "content/14-content.html#slides",
    "title": "Building Spatial Databases with Attributes",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nBuilding spatial databases based on attributes\n\n\nWorkflows for spatial analysis\n\n\nDatabases and attributes\n\n\nCommon attribute operations\n\n\nJoining (a)spatial data"
  },
  {
    "objectID": "content/15-content.html",
    "href": "content/15-content.html",
    "title": "Building Databases with Location",
    "section": "",
    "text": "Today we’ll continue our development of attributes (or covariates) in our spatial databases. We’ll look at developing attributes that describe various geographic properties along with joining and subsetting based on locations."
  },
  {
    "objectID": "content/15-content.html#resources",
    "href": "content/15-content.html#resources",
    "title": "Building Databases with Location",
    "section": "Resources",
    "text": "Resources\nThese chapters are not ‘prerequisite’ reading for the week, but provide a lot of helpful background for determining spatial relations between vector datasets and extracting those into attribute tables for subsequent visualization and analysis.\n\n The Spatial Data Operations Chapter in (Lovelace et al. 2019) makes the concepts of a network concrete (literally) by using a transportation route example to illustrate the various components of a network analysis in R.\n Attributes and Support of Spatial Data Science, a bookdown project by Edzer Pebesma and Roger Bivand (of the sf, sp, rgeos, and rgdal packages)"
  },
  {
    "objectID": "content/15-content.html#objectives",
    "href": "content/15-content.html#objectives",
    "title": "Building Databases with Location",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today, you should be able to:\n\nGenerate new features using geographic data\nUse topological subsetting to reduce features based on geography\nUse spatial joins to add attributes based on location"
  },
  {
    "objectID": "content/15-content.html#slides",
    "href": "content/15-content.html#slides",
    "title": "Building Databases with Location",
    "section": "Slides",
    "text": "Slides\nThe slides for today’s lesson are available online as an HTML file. Use the buttons below to open the slides either as an interactive website or as a static PDF (for printing or storing for later). You can also click in the slides below and navigate through them with your left and right arrow keys.\n\n View all slides in new window  Download PDF of all slides\n\n\n\nBuilding spatial databases based on attributes\n\n\nRevisting spatial analysis\n\n\nEstimating spatial attributes\n\n\nTopological subsetting\n\n\nSpatial joins"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Readings and slides",
    "section": "",
    "text": "View all slides in new window  Download PDF of all slides\n\nThe slides are also embedded on each page. You can click in the slides and navigate through them with ← and →. If you type ? (or shift + /) while viewing the slides you can see a list of slide-specific commands (like f for fullscreen or p for presenter mode if you want to see my notes)."
  },
  {
    "objectID": "example/getting-setup.html",
    "href": "example/getting-setup.html",
    "title": "Getting Setup",
    "section": "",
    "text": "We are using GitHub classroom for all of the assignments in this course. This allows each of you to have your own repositories for version control and backup of your code without the worries of stepping on someone else toes. The goal of this class is not to have you become a ‘master’ of all things git, but I am hoping you’ll learn the utility of version control and adopt as much of it as make sense for you and your workflows.\n\n\nThe first thing you’ll need to do is accept the invitation to ’assignment-1` repository (repo). This should automatically clone (make an exact copy) of the assignment repo in your personal account.\n\n\n\nUnfortunately, GitHub has ended its support for username/password remote authentication. Instead, it uses something called a Personal Access Token. You can read more about it here if you are interested, but the easiest way to deal with this is by following Jenny Bryan’s happygitwithr recommended approach:\n\nIntroduce yourself to git: There are a number of ways to do this, but I find this to be the easiest\n\n\n\nCode\nlibrary(usethis) #you may need to install this using install.packages('usethis')\nuse_git_config(user.name = \"Matt Williamson\", user.email = \"mattwilliamson@boisestate.edu\") #your info here\n\n\n\nGet a PAT if you don’t have one already (make sure you save it somewhere)\n\n\n\nCode\nusethis::create_github_token()\n\n\n\nStore your credential for use in RStudio\n\n\n\nCode\nlibrary(gitcreds) #may need to install this too\n\ngitcreds_set() #should prompt you for your pat - paste it here\n\n\n\nVerify that Rstudio has saved your credential\n\n\n\nCode\ngitcreds_get()\n\n\nR should return something that looks like this:\n\n\n\n\n\n\n\n\n\nGo to File>New Project and choose the “Version Control” option\nSelect “Git” (Not Subversion)\npaste the link from the “Clone Repository” button into the “Repository URL” space\n\n\n\n\nAssuming all this has worked, you should be able to click on the “Git” tab and see something like this:\n\n\n\n\n\n\n\n\n\nEverytime you begin working on code, make sure you “Pull” from the remote repository to make sure you have the most recent version of things (this is especially important when you are collaborating with people).\nMake some changes to code\nSave those changes\n“Commit” those changes - Think of commits as ‘breadcrumbs’ they help you remember where you were in the coding process in case you need to revert back to a previous version. Your commit messages should help you remember what was ‘happening’ in the code when you made the commit. In general, you should save and commit fairly frequently and especially everytime you do something ‘consequential’. Git allows you to ‘turn back time’, but that’s only useful if you left enough information to get back to where you want to be.\nPush your work to the remote - when you’re done working on the project for the day, push your local changes to the remote. This will ensure that if you switch computers or if someone else is going to work on the project, you (or they) will have the most recent version. Plus, if you don’t do this, step 1 will really mess you up."
  },
  {
    "objectID": "example/getting-setup.html#quarto",
    "href": "example/getting-setup.html#quarto",
    "title": "Getting Setup",
    "section": "Quarto",
    "text": "Quarto\nThis is a Quarto document (in fact, this whole webpage and all of the slides were built with Quarto). Quarto uses the knitr package to render files containing R, python, and julia to Markdown as a means of rendering code, text, math, figures, and tables to a variety of formats.\n\n\n\n\n\nMarkdown is a simple formatting syntax for authoring HTML documents (it’s the basis for the Readme docs that GitHub creates for you). From there, RStudio calls pandoc to render the markdown file into your chosen output format. I’m telling you this because there will be times when some part of this pipeline may break and you’ll need to know where the errors might be coming from.\nYou can create new Quarto documents by going to File >> New File >> New Quarto Document (or Presentation). There are lots of new documents devoted to Quarto, but some of them may assume you have some familiarity with Markdown or Rmarkdown. As such, I’m keeping this links to helpful Rmarkdown resources like this cheatsheet and a much longer user’s guide in case you need more in-depth discussion of some of the ideas behind authoring in Quarto. I don’t expect you to become an expert in Quarto, but it is a helpful way to keep all of your thoughts and code together in a single, coherent document. Getting proficient in Quarto and git allows you to work with collaborators on an analysis, graphics, and manuscript all within a single platform. This fully-integrated workflow takes practice and patience (especially when you have collaborators that are new to this approach), this course is just an initial step down that path. I’ll do my best to keep it simple - please let me know if you have questions!"
  },
  {
    "objectID": "example/getting-setup.html#the-example",
    "href": "example/getting-setup.html#the-example",
    "title": "Getting Setup",
    "section": "The Example",
    "text": "The Example\n\nSetup\nThe University of Exeter has been conducting an ongoing survey to understand the age at which the belief in Santa Claus begins to drop off. A sample of the data is located in your assignment01 folder. Our task is to bring the data into R, conduct some preliminary exploration of the data, and then fit a model to the data to see if age predicts belief in Santa. We’ll start by branching off of the master Quarto doc in our GitHub repo and then work through the steps together.\n\n\nPseudocode\nBefore we get started, let’s sketch out the steps in our analysis using pseudocode. If you take a look at the tasks I’ve outlined above, you might construct your pseudocode like this:\n\n\nCode\nLOAD: all packages that we need for the analysis\nREAD: Data located in isthereasanta.txt\nCHECK: Data structure and values\nCLEAN: Are there odd values?\nPLOT: Age vs Belief\nMODEL: GLM of Age vs. belief\n\n\n\n\nProgramming\nNow that we have the basic steps in place, let’s transform the pseudocode into a repeatable Quarto document that explains what we’re doing, why, and what we found.\n\nLoad the packages\nPart of what makes R so powerful for data analysis is the number of ready-made functions and packages that are designed for all the things. That said, you can’t take advantage of that power if you don’t load them into your session so that their functions become available. In general, it’s best to do that first thing your document so that other folks can see what packages are necessary before you start running analyses. If you pay attention when these packages load, you may see warnings that a function is masked. This happens because two (or more) packages have functions with the same name. We can be explicit about which version we want by using packagename::functionname(). You’ll see that more later this semester.\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\n\nRead the Data\nBased on our pseudocode our first step is the read the data. We can create headings in Quarto using different numbers of # symbols to keep things organized. The code below uses ``` to create the code chunk and then {r} to tell Quarto which environment to use when running it. I’m specifying a filepath because I’m not working within our git repo, this isn’t great practice, but it’s necessary for the webpage to render correctly. We use paste0 to combine the filepath with the file name (isthereasanta.txt) then read in the data using read_table.\n\n\nCode\nfilepath <- \"/Users/mattwilliamson/Google Drive/My Drive/TEACHING/Intro_Spatial_Data_R/Data/2022/assignment01/\"\n#READ\nsanta <- read_table(paste0(filepath, \"isthereasanta.txt\"))\n\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  Believe = col_logical(),\n  Age = col_double(),\n  Gender = col_character(),\n  Presents = col_double(),\n  Behaviour = col_character()\n)\n\n\n\n\nCheck out the Data\nNow that we’ve got the data loaded and assigned it to the santa object. It’s always a good idea to take a look and make sure things look the way you expect, check for NAs, and get a basic understanding of the way your data is being represented by R. This process will get more involved once we start working with spatial data, but it’s good to get in the habit now. We’ll start by looking at the first few rows (using head()), then get a sense for the classes of data using str(), and check for any NAs.\n\n\nCode\nhead(santa)\n\n\n# A tibble: 6 × 5\n  Believe   Age Gender Presents Behaviour\n  <lgl>   <dbl> <chr>     <dbl> <chr>    \n1 FALSE       9 male         25 naughty  \n2 TRUE       NA male         20 nice     \n3 TRUE        4 female       30 nice     \n4 TRUE        4 male         34 naughty  \n5 FALSE      10 female       27 nice     \n6 FALSE      NA female       43 naughty  \n\n\nCode\nstr(santa)\n\n\nspec_tbl_df [50 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Believe  : logi [1:50] FALSE TRUE TRUE TRUE FALSE FALSE ...\n $ Age      : num [1:50] 9 NA 4 4 10 NA 4 6 8 8 ...\n $ Gender   : chr [1:50] \"male\" \"male\" \"female\" \"male\" ...\n $ Presents : num [1:50] 25 20 30 34 27 43 21 23 32 17 ...\n $ Behaviour: chr [1:50] \"naughty\" \"nice\" \"nice\" \"naughty\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Believe = col_logical(),\n  ..   Age = col_double(),\n  ..   Gender = col_character(),\n  ..   Presents = col_double(),\n  ..   Behaviour = col_character()\n  .. )\n\n\nCode\nany(is.na(santa))\n\n\n[1] TRUE\n\n\nYou’ll notice a few things. First, because we read this in using the read_table function, the result is a tibble. As such, head() returns both the data and the classes. This makes the result of str() largely redundant (note that if santa were a data.frame this would not be true). The combination of any() with is.na() asks whether any of the cells in santa have an NA value. You can see that there are NAs. Most statistical modeling functions in R don’t like NAs so we’ll try to clean those up here. Before we clean them, let’s try to learn what they are. We can use which() to identify the locations of the NAs.\n\n\nCode\nwhich(is.na(santa), arr.ind = TRUE)\n\n\n     row col\n[1,]   2   2\n[2,]   6   2\n[3,]  20   2\n\n\nWe see that all of them are in the age column (our key predictor variable!). We could also have discovered this using summary().\n\n\nCode\nsummary(santa)\n\n\n  Believe             Age           Gender             Presents   \n Mode :logical   Min.   : 4.00   Length:50          Min.   : 3.0  \n FALSE:25        1st Qu.: 5.00   Class :character   1st Qu.:20.0  \n TRUE :25        Median : 7.00   Mode  :character   Median :26.5  \n                 Mean   : 6.83                      Mean   :27.0  \n                 3rd Qu.: 9.00                      3rd Qu.:33.5  \n                 Max.   :10.00                      Max.   :57.0  \n                 NA's   :3                                        \n  Behaviour        \n Length:50         \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\n\n\n\nClean the data\nDeciding how to clean NAs is an important decision. Many people choose to drop any incomplete records. We can do that with complete.cases() and see that the resulting object now has only 47 rows.\n\n\nCode\nsanta_complete_cases <- santa[complete.cases(santa),]\n\n\nDropping the incomplete cases may seem like a “safe” approach, but what if there is some systematic reason for the data to be incomplete. Maybe older people are less likely to provide their age? If that’s the case, then dropping these cases may bias our dataset and the models that result. In that case, we may decide to “impute” values for the NAs based on some principled approach. We’ll talk more about what it means to take a principled approach to imputation later in this class. For now, let’s just try to strategies: 1 where we assign the mean() value of age and one where we assign the max() value (to reflect our hypothesis that older people may not provide their age). We’ll do this by using the ifelse() function. Note that we can only do this because all of the NAs are in a single column.\n\n\nCode\nsanta_mean <- santa\nsanta_mean$Age <- ifelse(is.na(santa_mean$Age), round(mean(santa_mean$Age, na.rm=TRUE),digits=0), santa_mean$Age)\n\nsanta_max <- santa\nsanta_max$Age <- ifelse(is.na(santa_max$Age), max(santa_max$Age, na.rm=TRUE), santa_max$Age)\n\n\n\n\nPlot the Data\nNow that we have a few clean datasets, let’s just take a quick look to see if our intuition is correct about the relationship between age and belief in santa. The idea isn’t so much to “prove” your hypothesis, but rather to get to know your data better as a means of identifying potential outliers and thinking about the distribution of your data.\n\n\nCode\nplot(Believe ~ Age, data=santa_complete_cases, main=\"Age vs. Belief in Santa (complete cases)\")\n\n\n\n\n\nCode\nplot(Believe ~ Age, data=santa_mean, main=\"Age vs. Belief in Santa (Age at mean)\")\n\n\n\n\n\nCode\nplot(Believe ~ Age, data=santa_max, main=\"Age vs. Belief in Santa (Age at max)\")\n\n\n\n\n\nThese plots highlight two things. First, because Believe is a logical variable, the only possible outcomes are 0 and 1. This means we can’t fit a typical linear regression (we’ll use a logistic regression instead). Also, we notice that our choice of imputation strategy makes a difference! Let’s fit some models and see what kind of difference it makes.\n\n\nFit Some Models\nWe’ll be using a generalized linear model for this analysis. The details will come up later, but for now, let’s keep it simple. The syntax for the glm() function is relatively straightforward. First we specify the model Believe ~ Age, then we tell it what family binomial(link=\"logit\"), then we remind R of the data. We use the binomial family because there are only 2 possible outcomes (TRUE and FALSE).\n\n\nCode\nfit_complete_cases <- glm(Believe ~ Age, family=binomial(link=\"logit\"), data=santa_complete_cases)\nfit_mean <- glm(Believe ~ Age, family=binomial(link=\"logit\"), data=santa_mean)\nfit_max <- glm(Believe ~ Age, family=binomial(link=\"logit\"), data=santa_max)\n\nsummary(fit_complete_cases)$coef\n\n\n              Estimate Std. Error   z value     Pr(>|z|)\n(Intercept)  6.1939449   1.686432  3.672810 0.0002398983\nAge         -0.8909717   0.233676 -3.812851 0.0001373730\n\n\nCode\nsummary(fit_mean)$coef\n\n\n              Estimate Std. Error   z value     Pr(>|z|)\n(Intercept)  6.1309466  1.6636430  3.685254 0.0002284749\nAge         -0.8912996  0.2329537 -3.826081 0.0001301993\n\n\nCode\nsummary(fit_max)$coef\n\n\n             Estimate Std. Error   z value     Pr(>|z|)\n(Intercept)  5.549176  1.5120932  3.669864 0.0002426799\nAge         -0.784327  0.2043065 -3.838973 0.0001235502\n\n\nWe see the older a person is, the less likely they are to believe in Santa! We also see that the choice of how we handle NAs affects the size of the effect, but not the direction. In class, we’ll write a function to simulate some new data based on this model and see if our results are robust to different assumptions.\n\n\n\nRendering the document\nWhen you click the Render button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document."
  },
  {
    "objectID": "example/index.html",
    "href": "example/index.html",
    "title": "Examples",
    "section": "",
    "text": "This section has some worked examples demonstrating the use of different packages and giving some ‘roadmaps’ for completing different spatial operations. These are mostly my opinions, your mileage may vary, but I’ll try to justify why I do things the way that I do so that you can make an informed choice when you decide to deviate from that path."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Intro to Spatial Data in R",
    "section": "",
    "text": "Instructor\n\n   Dr. Matt Williamson\n   4125 Environmental Research Building\n   mattwilliamson@boisestate.edu\n   MwilliamsonMatt\n   Schedule an appointment\n\n\n\nCourse details\n\n   Mondays and Wednesdays\n   August 22–December 16, 2022\n   1:30–2:45 PM\n   Mathematics 126\n   Slack\n\n\n\nContacting me\nE-mail and Slack are the best ways to get in contact with me. I will try to respond to all course-related e-mails and Slack messages within 48 hours (really), but also remember that life can be busy and chaotic for everyone (including me!), so if I don’t respond right away, don’t worry!"
  },
  {
    "objectID": "resource/data.html",
    "href": "resource/data.html",
    "title": "Fun datasets",
    "section": "",
    "text": "So much data, so little time… Here are some links to help you get started finding data for your geospatial projects"
  },
  {
    "objectID": "resource/data.html#spatial-data-repositories",
    "href": "resource/data.html#spatial-data-repositories",
    "title": "Fun datasets",
    "section": "Spatial Data Repositories",
    "text": "Spatial Data Repositories\n\nDataBasin: Lots of spatial data related to conservation issues across the US. The AdaptWest portal has tons of spatial data on climate change and its potential impacts.\nUS Protected Areas Database: PAD-US is America’s official national inventory of U.S. terrestrial and marine protected areas that are dedicated to the preservation of biological diversity and to other natural, recreation and cultural uses, managed for these purposes through legal or other effective means. PAD-US also includes the best available aggregation of federal land and marine areas provided directly by managing agencies, coordinated through the Federal Geographic Data Committee (FGDC) Federal Lands Working Group.\nUSGS Gap Analysis Project: A variety of datasets depicting land cover and species distributions."
  },
  {
    "objectID": "resource/data.html#general-data-repositories",
    "href": "resource/data.html#general-data-repositories",
    "title": "Fun datasets",
    "section": "General Data Repositories",
    "text": "General Data Repositories\n\nData is Plural newsletter: Jeremy Singer-Vine sends a weekly newsletter of the most interesting public datasets he’s found. You should subscribe to it. He also has an archive of all the datasets he’s highlighted.\nGoogle Dataset Search: Google indexes thousands of public datasets; search for them here.\nKaggle: Kaggle hosts machine learning competitions where people compete to create the fastest, most efficient, most predictive algorithms. A byproduct of these competitions is a host of fascinating datasets that are generally free and open to the public. See, for example, the European Soccer Database, the Salem Witchcraft Dataset or results from an Oreo flavors taste test.\n360Giving: Dozens of British foundations follow a standard file format for sharing grant data and have made that data available online.\nUS City Open Data Census: More than 100 US cities have committed to sharing dozens of types of data, including data about crime, budgets, campaign finance, lobbying, transit, and zoning. This site from the Sunlight Foundation and Code for America collects this data and rates cities by how well they’re doing."
  },
  {
    "objectID": "resource/data.html#political-science-and-economics-datasets",
    "href": "resource/data.html#political-science-and-economics-datasets",
    "title": "Fun datasets",
    "section": "Political science and economics datasets",
    "text": "Political science and economics datasets\nThere’s a wealth of data available for political science- and economics-related topics:\n\nFrançois Briatte’s extensive curated lists: Includes data from/about intergovernmental organizations (IGOs), nongovernmental organizations (NGOs), public opinion surveys, parliaments and legislatures, wars, human rights, elections, and municipalities.\nThomas Leeper’s list of political science datasets: Good short list of useful datasets, divided by type of data (country-level data, survey data, social media data, event data, text data, etc.).\nErik Gahner’s list of political science datasets: Huge list of useful datasets, divided by topic (governance, elections, policy, political elites, etc.)\nInside AirBnB a Creative Commons-licensed dataset with a ton of spatially referenced info on AirBnBs in cities across the globe."
  },
  {
    "objectID": "resource/data.html#the-30daymapchallenge",
    "href": "resource/data.html#the-30daymapchallenge",
    "title": "Fun datasets",
    "section": "The #30daymapchallenge",
    "text": "The #30daymapchallenge\nThe #30daymapchallenge is a social mapping/cartography/data visualization challenge designed to encourage experimentation with different types of datasets and mapping approaches. Searching the hashtag on social media (especially Twitter) will bring up a bunch of cool examples. Here are a few repositories to help you get started:\n\nThe Official #30DayMapChallenge Repo has an archive of past challenges and a description of what this is all about.\nBob Rudis’ 2019 bookdown project Contains both code and useful information for generating the visualizations along with sources for data.\nAlexandra Kapp’s 2020 repository makes use of some of the newer animation and interactive visualization techniques.\nThe R-Spatial list of 2020 challenge repositories"
  },
  {
    "objectID": "resource/git.html",
    "href": "resource/git.html",
    "title": "Helpful git links",
    "section": "",
    "text": "Getting in the habit of using version control can be challenging, especially if you are collaborating with others. The challenge gets worse when some of those collaborators are not familiar with the importance of version control. Here are a few links to try and make your (and their) transition a little smoother."
  },
  {
    "objectID": "resource/git.html#installing-git-and-making-it-play-nice-with-r",
    "href": "resource/git.html#installing-git-and-making-it-play-nice-with-r",
    "title": "Helpful git links",
    "section": "Installing Git and making it play nice with R",
    "text": "Installing Git and making it play nice with R\nHappy git with R is Jenny Bryan’s: extremely helpful introduction to git and incorporating it into your R workflow."
  },
  {
    "objectID": "resource/git.html#getting-the-hang-of-git",
    "href": "resource/git.html#getting-the-hang-of-git",
    "title": "Helpful git links",
    "section": "Getting the hang of git",
    "text": "Getting the hang of git\nUnderstanding the logic of git: provides a relatively accessible explanation of the various operations in git and links that to commonly used syntax.\nOh Sh@t, Git?!?: A less technical, more irreverant introduction to git workflows and fixing the inevitable challenges of version control. (G-rated version available at Dang it, Git?!?)."
  },
  {
    "objectID": "resource/index.html",
    "href": "resource/index.html",
    "title": "Resources",
    "section": "",
    "text": "I have included a bunch of extra resources and guides related to R and coding, potentially interesting data, and cool visualizations. Let me know when you find fun things to include here!"
  },
  {
    "objectID": "resource/install.html",
    "href": "resource/install.html",
    "title": "Installing R, RStudio, and tidyverse",
    "section": "",
    "text": "You will do all of your work in this class with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard—R handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code."
  },
  {
    "objectID": "resource/install.html#rstudio-on-your-computer",
    "href": "resource/install.html#rstudio-on-your-computer",
    "title": "Installing R, RStudio, and tidyverse",
    "section": "RStudio on your computer",
    "text": "RStudio on your computer\nRStudio.cloud is convenient, but it can be slow and it is not designed to be able to handle larger datasets, more complicated analysis, or fancier graphics. Over the course of the semester, you should wean yourself off of RStudio.cloud and install all these things locally. This is also important if you want to customize fonts, since RStudio.cloud has extremely limited support for fonts other than Helvetica.\nHere’s how you install all these things\n\nInstall R\nFirst you need to install R itself (the engine).\n\nGo to the CRAN (Collective R Archive Network)1 website: https://cran.r-project.org/\nClick on “Download R for XXX”, where XXX is either Mac or Windows:\n\nIf you use macOS, scroll down to the first .pkg file in the list of files (in this picture, it’s R-4.0.0.pkg; as of right now, the current version is 4.2.1) and download it.\nIf you use Windows, click “base” (or click on the bolded “install R for the first time” link) and download it.\n\nDouble click on the downloaded file (check your Downloads folder). Click yes through all the prompts to install like any other program.\nIf you use macOS, download and install XQuartz. You do not need to do this on Windows.\n\n\n\nInstall RStudio\nNext, you need to install RStudio, the nicer graphical user interface (GUI) for R (the dashboard). Once R and RStudio are both installed, you can ignore R and only use RStudio. RStudio will use R automatically and you won’t ever have to interact with it directly.\n\nGo to the free download location on RStudio’s website: https://www.rstudio.com/products/rstudio/download/#download\nThe website should automatically detect your operating system (macOS or Windows) and show a big download button for it:\nIf not, scroll down a little to the large table and choose the version of RStudio that matches your operating system.\nDouble click on the downloaded file (again, check your Downloads folder). Click yes through all the prompts to install like any other program.\n\nDouble click on RStudio to run it (check your applications folder or start menu).\n\n\nInstall tidyverse\nThe tidyverse consists of dozens of packages (including ggplot2) that all work together. Rather than install each individually, you can install a single magical package and get them all at the same time.\nYou can install packages manually in RStudio, but this can be a bit fragile, especially for some of the spatial packages. Instead of using the RStudio GUI we’ll just install thins at the prompt. To install the tidyverse pacakge (and all of its associated dependencies) run the following: install.packages(\"tidyverse\")."
  },
  {
    "objectID": "resource/lastyear.html",
    "href": "resource/lastyear.html",
    "title": "Last year’s class",
    "section": "",
    "text": "Last year was the first time I taught this class in it’s current format. I built a number of worked examples to try to clarify how different parts of a spatial workflow come together. Although the examples are far from perfect (I’m hoping this year’s are better), the page does have a number of potentially useful pieces. Check out the examples to access these."
  },
  {
    "objectID": "resource/r.html",
    "href": "resource/r.html",
    "title": "Getting started with R Spatial",
    "section": "",
    "text": "I highly recommend subscribing to the R Weekly newsletter. This e-mail is sent every Monday and is full of helpful tutorials about how to do stuff with R.\nSearching for help with R on Google can sometimes be tricky because the program name is a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot”, but if it does struggle, try searching for “rstats” instead (e.g. “rstats scatterplot”). Also, since most of your R work in this class will deal with ggplot2, it’s often easier to just search for that instead of the letter “r” (e.g. “ggplot scatterplot”).\nThese resources are also really really helpful:\n\n\n\nAn Introduction to R: The definitive introductory text by Venables, Smith, and the R Core Team.\nSwirl: A set of free, self-contained tutorials that run from within your RStudio terminal.\nR for Data Science: A free online book for learning the basics of R and the tidyverse.\nR and RStudio cheat sheets: A large collection of simple cheat sheets for RStudio, ggplot2, and other R-related things.\nStat 545: Dr. Jenny Bryan at RStudio has an entire introductory course in R, visualization, and data analysis online.\nSTA 112FS: Data Science: Dr. Mine Çetinkaya-Rundel at the University of Edinburgh / Duke University has an entire introductory course in R, visualization, and data science online.\nCSE 631: Principles & Practice of Data Visualization: Yet another introductory course for R and ggplot2 by Dr. Alison Presmanes Hill at RStudio.\n\n\n\n\n\nsf cheatsheet: An at-a-glance description of the various sf verbs and their application.\nGeocomputation with R: Online version of the textbook by Lovelace, Nowosad, and Muenchow.\n[Robert’s Page]"
  },
  {
    "objectID": "resource/rmarkdown.html",
    "href": "resource/rmarkdown.html",
    "title": "Authoring in Rmarkdown and Quarto",
    "section": "",
    "text": "This webpage and all of my slides were built with Quarto (and last year’s was built with Rmarkdown and blogdown). Having gone through the process of learning how make that work, I’m convinced that having a working knowledge of one or both of these is useful. As such, you’ll be using Rmarkdown or Quarto (your choice) to complete your assignments and render them to html. To help you get started here are a few links:"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Here’s your roadmap for the semester!\n\nContent (): This page contains the readings, slides, and recorded lectures for the week. Read and watch these before our in-person class.\nExample (): This page contains fully annotated R code and other supplementary information that you can use as a reference for your assignments and project. This is only a reference page—you don’t have to necessarily do anything here. Some sections also contain videos of me live coding the examples so you can see what it looks like to work with R in real time. This page will be very helpful as you work on your assignments.\nAssignment (): This page contains the instructions for each assignment. Weekly reports are due by noon on the day of class. Other assignments are due by 11:59 PM on the day they’re listed.\n\n\n\n\n\n\n\nSubscribe!\n\n\n\nYou can subscribe to this calendar URL in Outlook, Google Calendar, or Apple Calendar:\n\n\n\n Download\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nAssignment\n\n\n\n\n\n\nSession 1\n\n\n\n\nAugust 22\n\n\nIntroduction to the course\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 2\n\n\n\n\nAugust 24\n\n\nBasic data structures in R\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 3\n\n\n\n\nAugust 29\n\n\nRmarkdown, pseudocode, and literate programming\n\n\n\n\n\n\n\n\n\n\n\n\n\nAugust 30\n\n\nSelf-Evaluation 1 due  (submit by 23:59:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 4\n\n\n\n\nAugust 31\n\n\nRepetitive tasks, pipes, and functional programming\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 5\n\n\n\n\nSeptember 5\n\n\nNo Class(Labor Day)\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\nSeptember 6\n\n\nHomework 1  (submit by 23:59:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nAssignment\n\n\n\n\n\n\nSession 6\n\n\n\n\nSeptember 7\n\n\nSpatial data is special data\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 7\n\n\n\n\nSeptember 12\n\n\nSpatial data as vectors\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 8\n\n\n\n\nSeptember 14\n\n\nOperations with vector data I\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 9\n\n\n\n\nSeptember 19\n\n\nOperations with vector data II\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 10\n\n\n\n\nSeptember 21\n\n\nSpatial data as matrices and rasters\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 11\n\n\n\n\nSeptember 26\n\n\nOperations with raster data I\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 12\n\n\n\n\nSeptember 28\n\n\nOperations with raster data II\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 13\n\n\n\n\nOctober 3\n\n\nCombining vector and raster operations  (submit by 23:59:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 2\n\n\n\n\nOctober 4\n\n\nHomework 2  (submit by 23:59:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nAssignment\n\n\n\n\n\n\nSession 14\n\n\n\n\nOctober 5\n\n\nBuilding analysis databates using attributes\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 15\n\n\n\n\nOctober 10\n\n\nBuilding analysis databates using location\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 16\n\n\n\n\nOctober 12\n\n\nAssessing spatial autocorrelation\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 17\n\n\n\n\nOctober 17\n\n\nPoint pattern analysis and hypothesis testing\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 18\n\n\nSelf-Evaluation 2 due\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 18\n\n\n\n\nOctober 19\n\n\nInterpolation\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 19\n\n\n\n\nOctober 24\n\n\nMultivariate statistical analysis I\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 20\n\n\n\n\nOctober 26\n\n\nMultivariate statistical analysis II\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 21\n\n\n\n\nOctober 31\n\n\nMultivariate statistical analysis III\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 3\n\n\n\n\nNovember 1\n\n\nHomework 3  (submit by 23:59:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nAssignment\n\n\n\n\n\n\nSession 22\n\n\n\n\nNovember 2\n\n\nBasic data visualization principles\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 23\n\n\n\n\nNovember 7\n\n\nIntroduction to ggplot\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 24\n\n\n\n\nNovember 9\n\n\nMaps, truth, and cartography\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 25\n\n\n\n\nNovember 14\n\n\nStatic maps in R\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 26\n\n\n\n\nNovember 16\n\n\nBuilding better maps\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 4\n\n\n\n\nNovember 18\n\n\nHomework 4  (submit by 23:59:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 27\n\n\n\n\nNovember 21\n\n\nNo Class\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 28\n\n\n\n\nNovember 23\n\n\nNo Class(Fall Break)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 29\n\n\n\n\nNovember 28\n\n\nIntroduction to interactive maps I(Fall Break)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 30\n\n\n\n\nNovember 30\n\n\nInteractive maps II\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nContent\n\n\nExample\n\n\nAssignment\n\n\n\n\n\n\nFinal Project Draft\n\n\n\n\nDecember 2\n\n\nFinal Project Draft  (submit by 23:59:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 31\n\n\n\n\nDecember 5\n\n\nConclusion\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession 32\n\n\n\n\nDecember 7\n\n\nFinal Project Workday\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinal Project\n\n\n\n\nDecember 15\n\n\nFinal Project Due  (submit by 23:59:00)\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecember 16\n\n\nFinal Self-Evaluation Due  (submit by 23:59:00)"
  },
  {
    "objectID": "slides/01-slides.html#todays-plan",
    "href": "slides/01-slides.html#todays-plan",
    "title": "Getting Started",
    "section": "Today’s Plan",
    "text": "Today’s Plan\n\n\nIntroductions\nWhy (not) R?\nCourse logistics and resources\nTesting out RStudio, git, and GitHub Classroom"
  },
  {
    "objectID": "slides/01-slides.html#about-me",
    "href": "slides/01-slides.html#about-me",
    "title": "Getting Started",
    "section": "About Me",
    "text": "About Me\n\n\n\n\nWhat I do\nMy path to this point\nWhy I teach this course"
  },
  {
    "objectID": "slides/01-slides.html#what-about-you",
    "href": "slides/01-slides.html#what-about-you",
    "title": "Getting Started",
    "section": "What about you?",
    "text": "What about you?\n\n\nWhere are you from?\nWhat do you like most about Boise?\nWhat do you miss most about “home”?\nWhat is your research?"
  },
  {
    "objectID": "slides/01-slides.html#why-r",
    "href": "slides/01-slides.html#why-r",
    "title": "Getting Started",
    "section": "Why R?",
    "text": "Why R?\n\n\n\n\nOpen Source\nHuge useR community\nIntegrated analysis pipelines\nReproducible workflows\n\n\n\n\nCodePlot\n\n\n\nlibrary(maps)\nlibrary(socviz)\nlibrary(tidyverse)\nparty_colors <- c(\"#2E74C0\", \"#CB454A\") \nus_states <- map_data(\"state\")\nelection$region <- tolower(election$state)\nus_states_elec <- left_join(us_states, election)\np0 <- ggplot(data = us_states_elec,\n             mapping = aes(x = long, y = lat,\n                           group = group, \n                           fill = party))\np1 <- p0 + geom_polygon(color = \"gray90\", \n                        size = 0.1) +\n    coord_map(projection = \"albers\", \n              lat0 = 39, lat1 = 45) \np2 <- p1 + scale_fill_manual(values = party_colors) +\n    labs(title = \"Election Results 2016\", \n         fill = NULL)"
  },
  {
    "objectID": "slides/01-slides.html#why-not-r-1",
    "href": "slides/01-slides.html#why-not-r-1",
    "title": "Getting Started",
    "section": "Why not R?",
    "text": "Why not R?\n\n\n\nCoding can be hard…\nMemory challenges\nSpeed\nDecision fatigue\n\n\n\n## ---\n## Error: could not find function \"performance\"\n## ---\n##  [1] \"Error in if (str_count(string = f[[j]], pattern = \\\"\\\\\\\\S+\\\") == 1) { : \\n  argument is of length zero\"   \n## ---\n## Error in eval(expr, envir, enclos) : object 'x' not found\n## ---\n## Error in file(file, \"rt\") : cannot open the connection\n## ---\n## Error in UseMethod(\"as.data.table\") : \n##   no applicable method for 'as.data.table' applied to an object of class \"table\"\n## ---"
  },
  {
    "objectID": "slides/01-slides.html#getting-help",
    "href": "slides/01-slides.html#getting-help",
    "title": "Getting Started",
    "section": "Getting Help",
    "text": "Getting Help\n\n\n\nGoogle it!!\n\nUse the exact error message\nInclude the package name\ninclude “R” in the search\n\n\n\n\nStack Overflow\n\nReproducible examples\n\nPackage “issue” pages\nr_spatial slack channel\nCommon errors\n\n\n\n\nAsk Me"
  },
  {
    "objectID": "slides/01-slides.html#logistics",
    "href": "slides/01-slides.html#logistics",
    "title": "Getting Started",
    "section": "Logistics",
    "text": "Logistics\n\n\nMeet on Mondays and Wednesdays\n~45 min lecture, 30 min practice\n4 major sections\nReadings"
  },
  {
    "objectID": "slides/01-slides.html#course-webpage",
    "href": "slides/01-slides.html#course-webpage",
    "title": "Getting Started",
    "section": "Course Webpage",
    "text": "Course Webpage\nhttps://isdrfall22.classes.spaseslab.com/\n\n\nSyllabus\nSchedule\nLectures\nAssignments\nResources"
  },
  {
    "objectID": "slides/01-slides.html#assignments",
    "href": "slides/01-slides.html#assignments",
    "title": "Getting Started",
    "section": "Assignments",
    "text": "Assignments\n\nCheck out the syllabus for more on grading!\n\n\n\n\n\nSelf-reflections (3x)\n\nYour goals for the course\nEvaluation criteria\nChecking in\n\nCoding exercises (4x)\n\nProblem solving\nReproducible workflows\nThinking critically\n\n\n\n\nFinal project (1st draft, final draft)\n\nPractice a full analysis workflow\nIntegrate analysis & visuals to tell a story"
  },
  {
    "objectID": "slides/01-slides.html#orientation-to-rstudio-and-our-rstudio-server",
    "href": "slides/01-slides.html#orientation-to-rstudio-and-our-rstudio-server",
    "title": "Getting Started",
    "section": "Orientation to RStudio and our RStudio server",
    "text": "Orientation to RStudio and our RStudio server"
  },
  {
    "objectID": "slides/01-slides.html#introduce-yourself-to-git",
    "href": "slides/01-slides.html#introduce-yourself-to-git",
    "title": "Getting Started",
    "section": "Introduce yourself to Git",
    "text": "Introduce yourself to Git\n\nLots of ways, but one easy way is:\n\n\nlibrary(usethis) #you may need to install this using install.packages('usethis')\nuse_git_config(user.name = \"Jane Doe\", user.email = \"jane@example.org\") #your info here\n\n\nGenerate a PAT token if you don’t have one (make sure you save it somewhere)\n\n\nusethis::create_github_token()"
  },
  {
    "objectID": "slides/01-slides.html#introduce-yourself-to-git-contd",
    "href": "slides/01-slides.html#introduce-yourself-to-git-contd",
    "title": "Getting Started",
    "section": "Introduce yourself to Git (cont’d)",
    "text": "Introduce yourself to Git (cont’d)\n\nStore your credentials for use (times out after 1 hr)\n\n\ngitcreds::gitcreds_set()\n\n\nVerify\n\n\ngitcreds::gitcreds_get()"
  },
  {
    "objectID": "slides/01-slides.html#joining-the-assignment-and-cloning-the-repo",
    "href": "slides/01-slides.html#joining-the-assignment-and-cloning-the-repo",
    "title": "Getting Started",
    "section": "Joining the assignment and cloning the repo",
    "text": "Joining the assignment and cloning the repo\n\nClick this link\nBring the project into RStudio\n\n\nGo to File>New Project and choose the “Version Control” option\nSelect “Git” (Not Subversion)\nPaste the link from the “Clone Repository” button into the “Repository URL” space"
  },
  {
    "objectID": "slides/01-slides.html#the-git-workflow",
    "href": "slides/01-slides.html#the-git-workflow",
    "title": "Getting Started",
    "section": "The git workflow",
    "text": "The git workflow\n\nMake sure to pull everytime you start working on a project\nMake some changes to code\nSave those changes\nCommit your changes\nPush your work to the remote!"
  },
  {
    "objectID": "slides/01-slides.html#checking-in",
    "href": "slides/01-slides.html#checking-in",
    "title": "Getting Started",
    "section": "Checking in",
    "text": "Checking in\n\nWhat are some advantages and disadvantages of using R for spatial analysis\nWhat can I clarify about the course?\nHow do you feel about git and github classroom? How can I make that easier for you?"
  },
  {
    "objectID": "slides/02-slides.html#checking-in",
    "href": "slides/02-slides.html#checking-in",
    "title": "Basic Data Structures in R",
    "section": "Checking in",
    "text": "Checking in\n\nWhat are some advantages and disadvantages of using R for spatial analysis\nWhat can I clarify about the course?\nHow do you feel about git and github classroom? How can I make that easier for you?"
  },
  {
    "objectID": "slides/02-slides.html#todays-plan",
    "href": "slides/02-slides.html#todays-plan",
    "title": "Basic Data Structures in R",
    "section": "Today’s Plan",
    "text": "Today’s Plan\n\n\nUnderstanding data types and their role in R\nReading, subsetting, and manipulating data\nGetting help\nFirst assignment is live!"
  },
  {
    "objectID": "slides/02-slides.html#data-types",
    "href": "slides/02-slides.html#data-types",
    "title": "Basic Data Structures in R",
    "section": "Data types",
    "text": "Data types\n\n\nThe basic schema that R uses to store data.\nCreates expectations for allowable values\nSets the “rules” for how your data can be manipulated\nAffects storage and combination with other data types\nFour most common: Logical, Numeric, Integer, Character"
  },
  {
    "objectID": "slides/02-slides.html#logical-data",
    "href": "slides/02-slides.html#logical-data",
    "title": "Basic Data Structures in R",
    "section": "Logical Data",
    "text": "Logical Data\n\nData take on the value of either TRUE or FALSE.\nSpecial type of logical called NA to represent missing values\nCan be coerced to integers when numeric data is requires (TRUE = 1; FALSE = 0)"
  },
  {
    "objectID": "slides/02-slides.html#logical-data-contd",
    "href": "slides/02-slides.html#logical-data-contd",
    "title": "Basic Data Structures in R",
    "section": "Logical Data (cont’d)",
    "text": "Logical Data (cont’d)\n\nCan be the outcome of logical test\n\n\nx <- runif(10,-10, 10) #generate 10 random numbers between -10 and 10\n(y <- x > 5) #test whether the values are greater than 5 and assign to object y\n\n [1]  TRUE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE\n\ntypeof(y) #how is R storing the object?\n\n[1] \"logical\"\n\nmean(y) #gives the proportion of y that is greater than 5\n\n[1] 0.5\n\nx[c(3,6,8)] <- NA #set the 3rd, 6th, and 8th value to NA\nis.na(x) #check which values are NA\n\n [1] FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE"
  },
  {
    "objectID": "slides/02-slides.html#numeric-data",
    "href": "slides/02-slides.html#numeric-data",
    "title": "Basic Data Structures in R",
    "section": "Numeric Data",
    "text": "Numeric Data\n\nAll of the elements of an object (or variable) are numbers that could have decimals\nR can store this as either double (at least 2 decimal points) or integer\n\n\nx <- runif(10,-10, 10) #generate 10 random numbers between -10 and 10\ntypeof(x) #how is R storing the object?\n\n[1] \"double\"\n\nclass(x) #describes how R will treat the object \n\n[1] \"numeric\""
  },
  {
    "objectID": "slides/02-slides.html#integer-data",
    "href": "slides/02-slides.html#integer-data",
    "title": "Basic Data Structures in R",
    "section": "Integer Data",
    "text": "Integer Data\n\nInteger data is a special case of numeric data with no decimals\n\n\nmode(x) <- \"integer\"\nx\n\n [1]  0 -5  8 -1 -9  7  7 -6  8  0\n\nclass(x)\n\n[1] \"integer\"\n\ntypeof(x)\n\n[1] \"integer\"\n\nz <- sample.int(100, size=10) #sample 10 integers between 1 and 100\ntypeof(z)\n\n[1] \"integer\"\n\nclass(z)\n\n[1] \"integer\""
  },
  {
    "objectID": "slides/02-slides.html#character-data",
    "href": "slides/02-slides.html#character-data",
    "title": "Basic Data Structures in R",
    "section": "Character Data",
    "text": "Character Data\n\nRepresent string values\nStrings tend to be a word or multiple words\nCan be used with logical tests\n\n\nchar <- c(\"Sarah\", \"Tracy\", \"Jon\") #use c() to combine multiple entries\ntypeof(char)\n\n[1] \"character\"\n\nchar == \"Jon\"\n\n[1] FALSE FALSE  TRUE\n\nchar[char==\"Jon\"] <- \"Jeff\"\nchar\n\n[1] \"Sarah\" \"Tracy\" \"Jeff\""
  },
  {
    "objectID": "slides/02-slides.html#factors",
    "href": "slides/02-slides.html#factors",
    "title": "Basic Data Structures in R",
    "section": "Factors",
    "text": "Factors\n\nA special case of character data\nData contains a limited number of possible character strings (categorical variables)\nThe levels of a factor describe the possible values (all others coerced to NA)\n\n\n(sex <- factor(c(\"female\", \"female\", \"male\", \"female\", \"male\")))  #by default levels are ordered alphabetically\n\n[1] female female male   female male  \nLevels: female male\n\n(sex <- factor(sex, levels = c(\"male\", \"female\"))) #changing the order of the levels\n\n[1] female female male   female male  \nLevels: male female"
  },
  {
    "objectID": "slides/02-slides.html#coercion",
    "href": "slides/02-slides.html#coercion",
    "title": "Basic Data Structures in R",
    "section": "Coercion",
    "text": "Coercion\n\nSometimes certain functions require a particular class of data require conversion (or coercion)\nmode - implicitly; as.xxx - explicitly\n\n\ntext <- c(\"test1\", \"test2\", \"test1\", \"test1\") # create a character vector\nclass(text)\n\n[1] \"character\"\n\ntext_factor <- as.factor(text) # transform to factor\nclass(text_factor) # recheck the class\n\n[1] \"factor\"\n\nlevels(text_factor)\n\n[1] \"test1\" \"test2\"\n\nas.numeric(text_factor)\n\n[1] 1 2 1 1"
  },
  {
    "objectID": "slides/02-slides.html#data-structures",
    "href": "slides/02-slides.html#data-structures",
    "title": "Basic Data Structures in R",
    "section": "Data structures",
    "text": "Data structures\n\nLots of options for how R stores data\nStructure determines which functions work and how they behave\nlength(), str(), summary(), head(), and tail() can help you explore\nMost of the RSpatial data structures build on these basic structures"
  },
  {
    "objectID": "slides/02-slides.html#vectors",
    "href": "slides/02-slides.html#vectors",
    "title": "Basic Data Structures in R",
    "section": "Vectors",
    "text": "Vectors\n\nA 1-dimensional collection of elements with the same data type\nCombining two datatypes makes R choose\n\n\nseries.1 <- seq(10)\nseries.2 <- seq(from = 0.5, to = 5, by = 0.5)\nseries.abc <- letters[1:10]\nlength(series.1)\n\n[1] 10\n\nlength(series.2)\n\n[1] 10\n\nclass(c(series.abc, series.1)) #combine characters with numbers\n\n[1] \"character\""
  },
  {
    "objectID": "slides/02-slides.html#vectors-contd",
    "href": "slides/02-slides.html#vectors-contd",
    "title": "Basic Data Structures in R",
    "section": "Vectors (cont’d)",
    "text": "Vectors (cont’d)\n\nCan combine them or perform ‘vectorized’ operations\n\n\nseries.comb <- c(series.1, series.2)\nlength(series.comb)\n\n[1] 20\n\nseries.add <- series.1 + series.2\nlength(series.add)\n\n[1] 10\n\nhead(series.add)\n\n[1] 1.5 3.0 4.5 6.0 7.5 9.0\n\n\n\nWhat happens if you try to add the character vector to the numeric vector?"
  },
  {
    "objectID": "slides/02-slides.html#matrices",
    "href": "slides/02-slides.html#matrices",
    "title": "Basic Data Structures in R",
    "section": "Matrices",
    "text": "Matrices\n\nAn extension of the numeric or character vectors to include 2-dimensions (rows and columns)\nArrays extend the idea to multiple dimensions\nElements of matrix must have the same data type\n\n\n(m <- matrix(1:6, nrow = 2, ncol = 3)) #default is to fill by columns\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\ndim(m)\n\n[1] 2 3\n\n(m <- matrix(1:6, nrow = 2, ncol = 3, byrow = TRUE))\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6"
  },
  {
    "objectID": "slides/02-slides.html#lists",
    "href": "slides/02-slides.html#lists",
    "title": "Basic Data Structures in R",
    "section": "Lists",
    "text": "Lists\n\nHold a variety of different data types and structures including more lists.\nUse a lot for functional programming (next week).\n\n\n(xlist <- list(a = \"Waldo\", b = 1:10, data = head(mtcars)))\n\n$a\n[1] \"Waldo\"\n\n$b\n [1]  1  2  3  4  5  6  7  8  9 10\n\n$data\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"
  },
  {
    "objectID": "slides/02-slides.html#lists-contd",
    "href": "slides/02-slides.html#lists-contd",
    "title": "Basic Data Structures in R",
    "section": "Lists (cont’d)",
    "text": "Lists (cont’d)\n\nLists store information in slots\nAdding names to a list can help with accessing data\n\n\nnames(xlist)\n\n[1] \"a\"    \"b\"    \"data\"\n\nclass(xlist$data)\n\n[1] \"data.frame\""
  },
  {
    "objectID": "slides/02-slides.html#data-frames",
    "href": "slides/02-slides.html#data-frames",
    "title": "Basic Data Structures in R",
    "section": "Data Frames",
    "text": "Data Frames\n\nResemble tabular datasets used in spreadsheet programs\nLong vs. wide data\nSpecial type of list where every element has the same length (but can have different types of data)\n\n\n(dat <- data.frame(id = letters[1:5], x = 1:5, y = rep(date(),times=5 )))\n\n  id x                        y\n1  a 1 Wed Aug 24 12:59:21 2022\n2  b 2 Wed Aug 24 12:59:21 2022\n3  c 3 Wed Aug 24 12:59:21 2022\n4  d 4 Wed Aug 24 12:59:21 2022\n5  e 5 Wed Aug 24 12:59:21 2022\n\nis.list(dat)\n\n[1] TRUE\n\nclass(dat)\n\n[1] \"data.frame\""
  },
  {
    "objectID": "slides/02-slides.html#data-frames-contd",
    "href": "slides/02-slides.html#data-frames-contd",
    "title": "Basic Data Structures in R",
    "section": "Data Frames (cont’d)",
    "text": "Data Frames (cont’d)\n\nLots of ways to access and summarize data in data frames\nUseful for making sure your functions are working as intended\n\n\nstr(dat) #compact summary of the structure of a dataframe\n\n'data.frame':   5 obs. of  3 variables:\n $ id: chr  \"a\" \"b\" \"c\" \"d\" ...\n $ x : int  1 2 3 4 5\n $ y : chr  \"Wed Aug 24 12:59:21 2022\" \"Wed Aug 24 12:59:21 2022\" \"Wed Aug 24 12:59:21 2022\" \"Wed Aug 24 12:59:21 2022\" ...\n\nsummary(dat) #estimate summary statistics of data frame\n\n      id                  x          y            \n Length:5           Min.   :1   Length:5          \n Class :character   1st Qu.:2   Class :character  \n Mode  :character   Median :3   Mode  :character  \n                    Mean   :3                     \n                    3rd Qu.:4                     \n                    Max.   :5"
  },
  {
    "objectID": "slides/02-slides.html#data-frames-one-more-time",
    "href": "slides/02-slides.html#data-frames-one-more-time",
    "title": "Basic Data Structures in R",
    "section": "Data Frames (one more time)",
    "text": "Data Frames (one more time)\n\nSpecial cases of names (colnames and rownames)\n\n\ncolnames(dat) #get the names of the variables stored in the data frame\n\n[1] \"id\" \"x\"  \"y\" \n\ndat$y\n\n[1] \"Wed Aug 24 12:59:21 2022\" \"Wed Aug 24 12:59:21 2022\"\n[3] \"Wed Aug 24 12:59:21 2022\" \"Wed Aug 24 12:59:21 2022\"\n[5] \"Wed Aug 24 12:59:21 2022\""
  },
  {
    "objectID": "slides/02-slides.html#tibbles",
    "href": "slides/02-slides.html#tibbles",
    "title": "Basic Data Structures in R",
    "section": "Tibbles",
    "text": "Tibbles\n\nSimilar to data frames, but allow for lists within columns\nDesigned for use with the tidyverse\nFoundation of sf objects\n\n\nlibrary(tidyverse) #load the package necessary\ndat.tib <- tibble(dat)\nis.list(dat.tib)\n\n[1] TRUE\n\n## [1] TRUE\n\nclass(dat.tib)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\""
  },
  {
    "objectID": "slides/02-slides.html#a-note-on-the-tidyverse",
    "href": "slides/02-slides.html#a-note-on-the-tidyverse",
    "title": "Basic Data Structures in R",
    "section": "A Note on the tidyverse",
    "text": "A Note on the tidyverse\n\nA self-contained universe of packages and functions designed to work together\nRely on “verbs” to make coding more intuitive\nBenefits and drawbacks"
  },
  {
    "objectID": "slides/02-slides.html#reading-data",
    "href": "slides/02-slides.html#reading-data",
    "title": "Basic Data Structures in R",
    "section": "Reading Data",
    "text": "Reading Data\n\nThe first step in any data analysis\nDepends on the file type (.csv, .txt, .shp)\nCHECK YOURSELF\n\n\ncars <- read.table('file/cars.txt')\nstr(cars)\n\n'data.frame':   50 obs. of  2 variables:\n $ speed: int  4 4 7 7 8 9 10 10 10 11 ...\n $ dist : int  2 10 4 22 16 10 18 26 34 17 ...\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00"
  },
  {
    "objectID": "slides/02-slides.html#reading-data-contd",
    "href": "slides/02-slides.html#reading-data-contd",
    "title": "Basic Data Structures in R",
    "section": "Reading Data (cont’d)",
    "text": "Reading Data (cont’d)\n\ntidyverse convention is to use “verb_object”\nFor reading data that means read_ instead of read.\nDifferent default behaviors!!\n\n\ncars_tv <- read_table('file/cars.txt')\nstr(cars_tv)\n\nspec_tbl_df [50 × 2] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ \"speed\": chr [1:50] \"\\\"1\\\"\" \"\\\"2\\\"\" \"\\\"3\\\"\" \"\\\"4\\\"\" ...\n $ \"dist\" : num [1:50] 4 4 7 7 8 9 10 10 10 11 ...\n - attr(*, \"problems\")= tibble [50 × 5] (S3: tbl_df/tbl/data.frame)\n  ..$ row     : int [1:50] 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ col     : chr [1:50] NA NA NA NA ...\n  ..$ expected: chr [1:50] \"2 columns\" \"2 columns\" \"2 columns\" \"2 columns\" ...\n  ..$ actual  : chr [1:50] \"3 columns\" \"3 columns\" \"3 columns\" \"3 columns\" ...\n  ..$ file    : chr [1:50] \"'file/cars.txt'\" \"'file/cars.txt'\" \"'file/cars.txt'\" \"'file/cars.txt'\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   `\"speed\"` = col_character(),\n  ..   `\"dist\"` = col_double()\n  .. )"
  },
  {
    "objectID": "slides/02-slides.html#reading-data-contd-1",
    "href": "slides/02-slides.html#reading-data-contd-1",
    "title": "Basic Data Structures in R",
    "section": "Reading Data (cont’d)",
    "text": "Reading Data (cont’d)\n\nsummary(cars_tv)\n\n   \"speed\"              \"dist\"    \n Length:50          Min.   : 4.0  \n Class :character   1st Qu.:12.0  \n Mode  :character   Median :15.0  \n                    Mean   :15.4  \n                    3rd Qu.:19.0  \n                    Max.   :25.0  \n\nhead(cars_tv)\n\n# A tibble: 6 × 2\n  `\"speed\"` `\"dist\"`\n  <chr>        <dbl>\n1 \"\\\"1\\\"\"          4\n2 \"\\\"2\\\"\"          4\n3 \"\\\"3\\\"\"          7\n4 \"\\\"4\\\"\"          7\n5 \"\\\"5\\\"\"          8\n6 \"\\\"6\\\"\"          9\n\n\nWhat do you notice??"
  },
  {
    "objectID": "slides/02-slides.html#selecting-data",
    "href": "slides/02-slides.html#selecting-data",
    "title": "Basic Data Structures in R",
    "section": "Selecting Data",
    "text": "Selecting Data\n\nWe often want to access subsets of our data\nFor named objects we can use $\n\n\nspeed <- cars$speed #assign the whole speed column to an object\nhead(speed)\n\n[1] 4 4 7 7 8 9"
  },
  {
    "objectID": "slides/02-slides.html#selecting-data-contd",
    "href": "slides/02-slides.html#selecting-data-contd",
    "title": "Basic Data Structures in R",
    "section": "Selecting Data (cont’d)",
    "text": "Selecting Data (cont’d)\n\nMore generally we can use [] (can use index and logicals)\n\n\n(speed2 <- cars$speed[2]) # get the vector named speed and take the 2nd element in that vector\n\n[1] 4\n\n(speed3 <- cars[4,2]) #get the vector located in the 2nd column and take the 4th element\n\n[1] 22\n\n(speed20 <- cars[cars$speed > 20,]) #return all columns where speed >20\n\n   speed dist\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85"
  },
  {
    "objectID": "slides/02-slides.html#selecting-data-contd-1",
    "href": "slides/02-slides.html#selecting-data-contd-1",
    "title": "Basic Data Structures in R",
    "section": "Selecting Data (cont’d)",
    "text": "Selecting Data (cont’d)\n\nFor lists we use [[]] to access a particular slot and [] to access data in that slot\n\n\nxlist <- list(a = \"Waldo\", b = 1:10, data = head(mtcars))\nxlist[[3]][1,2] #get the 3rd slot in the list and return the value in the 1st row, 2nd column\n\n[1] 6"
  },
  {
    "objectID": "slides/02-slides.html#selecting-data-contd-2",
    "href": "slides/02-slides.html#selecting-data-contd-2",
    "title": "Basic Data Structures in R",
    "section": "Selecting Data (cont’d)",
    "text": "Selecting Data (cont’d)\n\nIn the tidyverse we use select() to choose columns\nThe %>% operator allows us to link steps together\n\n\nspeed <- read.table('file/cars.txt') %>% \n  select(., speed)\nhead(speed)\n\n  speed\n1     4\n2     4\n3     7\n4     7\n5     8\n6     9"
  },
  {
    "objectID": "slides/02-slides.html#selecting-data-contd-3",
    "href": "slides/02-slides.html#selecting-data-contd-3",
    "title": "Basic Data Structures in R",
    "section": "Selecting Data (cont’d)",
    "text": "Selecting Data (cont’d)\n\nUse slice to get rows based on position\n\n\n(speed2 <- read.table('file/cars.txt') %>% \n  select(., speed) %>% \n   slice(., 2))\n\n  speed\n2     4"
  },
  {
    "objectID": "slides/02-slides.html#selecting-data-contd-4",
    "href": "slides/02-slides.html#selecting-data-contd-4",
    "title": "Basic Data Structures in R",
    "section": "Selecting Data (cont’d)",
    "text": "Selecting Data (cont’d)\n\nUsefilter to choose rows that meet a condition\n\n\n(speed2 <- read.table('file/cars.txt') %>% \n  filter(., speed > 20))\n\n   speed dist\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85"
  },
  {
    "objectID": "slides/02-slides.html#changing-data",
    "href": "slides/02-slides.html#changing-data",
    "title": "Basic Data Structures in R",
    "section": "Changing Data",
    "text": "Changing Data\n\nUpdating data (CAUTION)\nOften using a combination of index and logicals\n\n\nx <- runif(10,-10, 10) #generate 10 random numbers between -10 and 10\nx[c(3,6,8)] <- NA #set the 3rd, 6th, and 8th value to NA\nis.na(x) #check which values are NA\n\n [1] FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE"
  },
  {
    "objectID": "slides/02-slides.html#changing-data-1",
    "href": "slides/02-slides.html#changing-data-1",
    "title": "Basic Data Structures in R",
    "section": "Changing Data",
    "text": "Changing Data\n\nCreating new variables\nCan use $\n\n\nhead(mtcars, 3)\n\n               mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4     21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710    22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n\nmtcars$hpwt <- mtcars$hp/mtcars$wt\nhead(mtcars[,c(1, 5:12)],3)\n\n               mpg drat    wt  qsec vs am gear carb     hpwt\nMazda RX4     21.0 3.90 2.620 16.46  0  1    4    4 41.98473\nMazda RX4 Wag 21.0 3.90 2.875 17.02  0  1    4    4 38.26087\nDatsun 710    22.8 3.85 2.320 18.61  1  1    4    1 40.08621"
  },
  {
    "objectID": "slides/02-slides.html#changing-data-2",
    "href": "slides/02-slides.html#changing-data-2",
    "title": "Basic Data Structures in R",
    "section": "Changing Data",
    "text": "Changing Data\n\nCreating new variables\nUsing tidyverse, mutate creates new variables for the entire dataset\n\n\nmtcars_update <- mtcars %>% \n  mutate(., hpwt = hp/wt)\nhead(mtcars_update[,c(1, 5:12)], 3)\n\n               mpg drat    wt  qsec vs am gear carb     hpwt\nMazda RX4     21.0 3.90 2.620 16.46  0  1    4    4 41.98473\nMazda RX4 Wag 21.0 3.90 2.875 17.02  0  1    4    4 38.26087\nDatsun 710    22.8 3.85 2.320 18.61  1  1    4    1 40.08621"
  },
  {
    "objectID": "slides/02-slides.html#changing-data-3",
    "href": "slides/02-slides.html#changing-data-3",
    "title": "Basic Data Structures in R",
    "section": "Changing Data",
    "text": "Changing Data\n\nCreating new variables\nUsing summarise creates group level summaries\n\n\nmtcars_group <- mtcars %>% \n group_by(., cyl) %>% \n  summarise(., meanmpg = mean(mpg))\nmtcars_group\n\n# A tibble: 3 × 2\n    cyl meanmpg\n  <dbl>   <dbl>\n1     4    26.7\n2     6    19.7\n3     8    15.1"
  },
  {
    "objectID": "slides/02-slides.html#kinds-of-errors",
    "href": "slides/02-slides.html#kinds-of-errors",
    "title": "Basic Data Structures in R",
    "section": "2 Kinds of Errors",
    "text": "2 Kinds of Errors\n\nSyntax Errors: Your code won’t actually run\nSemantic Errors: Your code runs without error, but the result is unexpected"
  },
  {
    "objectID": "slides/02-slides.html#asking-good-questions",
    "href": "slides/02-slides.html#asking-good-questions",
    "title": "Basic Data Structures in R",
    "section": "Asking good questions",
    "text": "Asking good questions\n\nWhat are you trying to do?\nWhat isn’t working?\nWhat are you expecting?\nWhy aren’t common solutions working?"
  },
  {
    "objectID": "slides/02-slides.html#reproducible-examples",
    "href": "slides/02-slides.html#reproducible-examples",
    "title": "Basic Data Structures in R",
    "section": "Reproducible examples",
    "text": "Reproducible examples\n\nDon’t require someone to have your data or your computer\nMinimal amount of information and code to reproduce your error\nIncludes both code and your operating environment info\nSee the reprex package."
  },
  {
    "objectID": "slides/03-slides.html#for-today",
    "href": "slides/03-slides.html#for-today",
    "title": "Quarto, literate programming, and pseudocode",
    "section": "For today",
    "text": "For today\n\nIntroduce literate programming\nDescribe pseudocode and its utility for designing an analysis\nIntroduce Quarto as a means of documenting your work\nPractice workflow"
  },
  {
    "objectID": "slides/03-slides.html#what-is-literate-progamming",
    "href": "slides/03-slides.html#what-is-literate-progamming",
    "title": "Quarto, literate programming, and pseudocode",
    "section": "What is literate progamming?",
    "text": "What is literate progamming?\n\nLet us change our traditional attitude to the construction of programs: Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do.\n\n— Donald Knuth, CSLI, 1984"
  },
  {
    "objectID": "slides/03-slides.html#what-is-literate-programming",
    "href": "slides/03-slides.html#what-is-literate-programming",
    "title": "Quarto, literate programming, and pseudocode",
    "section": "What is literate programming?",
    "text": "What is literate programming?\n\nDocumentation containing code (not vice versa!)\nDirect connection between code and explanation\nConvey meaning to humans rather than telling computer what to do!\nMultiple “scales” possible"
  },
  {
    "objectID": "slides/03-slides.html#why-literate-programming",
    "href": "slides/03-slides.html#why-literate-programming",
    "title": "Quarto, literate programming, and pseudocode",
    "section": "Why literate programming?",
    "text": "Why literate programming?\n\nYour analysis scripts are computer software\nIntegrate math, figures, code, and narrative in one place\nExplaining something helps you learn it"
  },
  {
    "objectID": "slides/03-slides.html#pseudocode-and-literate-programming",
    "href": "slides/03-slides.html#pseudocode-and-literate-programming",
    "title": "Quarto, literate programming, and pseudocode",
    "section": "Pseudocode and literate programming",
    "text": "Pseudocode and literate programming\n\nAn informal way of writing the ‘logic’ of your program\nBalance between readability and precision\nAvoid syntactic drift"
  },
  {
    "objectID": "slides/03-slides.html#writing-pseudocode",
    "href": "slides/03-slides.html#writing-pseudocode",
    "title": "Quarto, literate programming, and pseudocode",
    "section": "Writing pseudocode",
    "text": "Writing pseudocode\n\n\n\nFocus on statements\nMathematical operations\nConditionals\nIteration\nExceptions"
  },
  {
    "objectID": "slides/03-slides.html#what-is-quarto",
    "href": "slides/03-slides.html#what-is-quarto",
    "title": "Quarto, literate programming, and pseudocode",
    "section": "What is Quarto?",
    "text": "What is Quarto?\n\nA multi-language platform for developing reproducible documents\nA ‘lab notebook’ for your analyses\nAllows transparent, reproducible scientific reports and presentations"
  },
  {
    "objectID": "slides/03-slides.html#key-components",
    "href": "slides/03-slides.html#key-components",
    "title": "Quarto, literate programming, and pseudocode",
    "section": "Key components",
    "text": "Key components\n\nMetadata and global options: YAML\nText, figures, and tables: Markdown and LaTeX\nCode: knitr (or jupyter if you’re into that sort of thing)"
  },
  {
    "objectID": "slides/03-slides.html#yaml---yet-another-markup-language",
    "href": "slides/03-slides.html#yaml---yet-another-markup-language",
    "title": "Quarto, literate programming, and pseudocode",
    "section": "YAML - Yet Another Markup Language",
    "text": "YAML - Yet Another Markup Language\n\nAllows you to set (or change) output format\nProvide options that apply to the entire document\nSpacing matters!"
  },
  {
    "objectID": "slides/03-slides.html#formatting-text",
    "href": "slides/03-slides.html#formatting-text",
    "title": "Quarto, literate programming, and pseudocode",
    "section": "Formatting Text",
    "text": "Formatting Text\n\nBasic formatting via Markdown\nFancier options using Divs and spans via Pandoc\nFenced Divs start and end with ::: (can be any number >3 but must match)"
  },
  {
    "objectID": "slides/03-slides.html#adding-code-chunks",
    "href": "slides/03-slides.html#adding-code-chunks",
    "title": "Quarto, literate programming, and pseudocode",
    "section": "Adding Code Chunks",
    "text": "Adding Code Chunks\n\nUse 3x ``` on each end\nInclude the engine {r} (or python or Julia)\nInclude options beneath the “fence” using a hashpipe (#|)"
  },
  {
    "objectID": "slides/04-slides.html#objectives",
    "href": "slides/04-slides.html#objectives",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "Objectives",
    "text": "Objectives\n\nDescribe the basic components of functions\nIntroduce the apply and map family of functions\nPractice designing functions for repetitive tasks"
  },
  {
    "objectID": "slides/04-slides.html#what-are-functions",
    "href": "slides/04-slides.html#what-are-functions",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "What are functions?",
    "text": "What are functions?\n\nA specific class of R object (can call function inside functions)\n\n\nrg <- paste(\"The range of mpg is\", sum(mean(mtcars$mpg), sd(mtcars$mpg)), \"-\", sum(mean(mtcars$mpg), -sd(mtcars$mpg)))\nrg\n\n[1] \"The range of mpg is 26.1175730520891 - 14.0636769479109\"\n\n\n\nA self-contained (i.e., modular) piece of code that performs a specific task\nAllows powerful customization and extension of R"
  },
  {
    "objectID": "slides/04-slides.html#why-use-functions",
    "href": "slides/04-slides.html#why-use-functions",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "Why use functions?",
    "text": "Why use functions?\n\nCopy-and-paste and repetitive typing are prone to errors\nEvocative names and modular code make your analysis more tractable\nUpdate in one place!\n\n\nIf you are copy-and-pasting more than 2x, consider a function!"
  },
  {
    "objectID": "slides/04-slides.html#getting-started",
    "href": "slides/04-slides.html#getting-started",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "Getting started",
    "text": "Getting started\n\nSketch out the steps in the algorithm (pseudocode!)\nDevelop working code for each step\nAnonymize\n\n\ndo_something <- function(arg1, arg2, arg3){\n  intermediate_process <- manipulate(arg1,arg2, arg3)\n  clean_output <- cleanup(intermediate_process)\n  return(clean_output)\n}"
  },
  {
    "objectID": "slides/04-slides.html#structure-of-functions-names",
    "href": "slides/04-slides.html#structure-of-functions-names",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "Structure of functions: Names",
    "text": "Structure of functions: Names\n\n\n\nWhat will your function do?\nShort, but clear!\nAvoid using reserved words or functions that already exist\nUse snake_case\n\n\n\nsomething <- function(...){\n}\n\n\nNot Great\n\n\ndo_something_ultraspecific <- function(...){\n}\n\n\nBetter\n\n\ndo_something <- function(...){\n}\n\n\nPretty good"
  },
  {
    "objectID": "slides/04-slides.html#structure-of-functions-arguments",
    "href": "slides/04-slides.html#structure-of-functions-arguments",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "Structure of functions: Arguments",
    "text": "Structure of functions: Arguments\n\nProvide the data that the function will work on\nProvide other arguments that control the details of the computation (often with defaults)\nCalled by name or position (names should be descriptive)\n\n\nnums <- rnorm(n = 1000, mean=2, sd=1.5)\n\n\nSame As\n\n\nnums <- rnorm(1000, 2, 1.5)"
  },
  {
    "objectID": "slides/04-slides.html#structure-of-functions-body",
    "href": "slides/04-slides.html#structure-of-functions-body",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "Structure of functions: Body",
    "text": "Structure of functions: Body\n\nThe body of the function appears between the {}\nThis is where the function does its work\n\n\n# Compute confidence interval around mean using normal approximation\nmean_ci <- function(x, conf = 0.95) {\n  se <- sd(x) / sqrt(length(x))\n  alpha <- 1 - conf\n  mean(x) + se * qnorm(c(alpha / 2, 1 - alpha / 2))\n}\n\nx <- runif(100)\nmean_ci(x)\n\n[1] 0.4328836 0.5415704\n\nmean_ci(x, conf = 0.99)\n\n[1] 0.4158077 0.5586463"
  },
  {
    "objectID": "slides/04-slides.html#structure-of-functions-return",
    "href": "slides/04-slides.html#structure-of-functions-return",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "Structure of functions: Return",
    "text": "Structure of functions: Return\n\nDefault is to return the last argument evaluated\nCan use return() to return an earlier value\nCan use list to return multiple values\nA note on the Environment\n\n\nmean_ci <- function(x, conf = 0.95) {\n  se <- sd(x) / sqrt(length(x))\n  alpha <- 1 - conf\n  ci <- mean(x) + se * qnorm(c(alpha / 2, 1 - alpha / 2))\n  myresults <- list(alpha = alpha, ci = ci, se = se)\n  return(myresults)\n}\n\nci_result <- mean_ci(x)"
  },
  {
    "objectID": "slides/04-slides.html#structure-of-functions-return-1",
    "href": "slides/04-slides.html#structure-of-functions-return-1",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "Structure of functions: Return",
    "text": "Structure of functions: Return\n\nstr(ci_result)\n\nList of 3\n $ alpha: num 0.05\n $ ci   : num [1:2] 0.433 0.542\n $ se   : num 0.0277"
  },
  {
    "objectID": "slides/04-slides.html#iteration",
    "href": "slides/04-slides.html#iteration",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "Iteration",
    "text": "Iteration\n\nAnother tool for reducing code duplication\nIteration for when you need to repeat the same task on different columns or datasets\nImperative iteration uses loops (for and while)\nFunctional iteration combines functions with the apply family to break computational challenges into independent pieces."
  },
  {
    "objectID": "slides/04-slides.html#loops",
    "href": "slides/04-slides.html#loops",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "Loops",
    "text": "Loops\n\nUse counters (for) or conditionals (while) to repeat a set of tasks\n3 key components\n\nOutput - before you can loop, you need a place to store the results\nSequence - defines what you are looping over\nBody - defines what the code is actually doing"
  },
  {
    "objectID": "slides/04-slides.html#loops-1",
    "href": "slides/04-slides.html#loops-1",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "Loops",
    "text": "Loops\n\nlibrary(tidyverse)\ndf <- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\noutput <- vector(\"double\", ncol(df))  # 1. output\nfor (i in seq_along(df)) {            # 2. sequence\n  output[[i]] <- median(df[[i]])      # 3. body\n}\noutput\n\n[1] -0.5016472 -0.3887528  0.2770325  0.2178513\n\n#> [1] -0.24576245 -0.28730721 -0.05669771  0.14426335"
  },
  {
    "objectID": "slides/04-slides.html#the-apply-family",
    "href": "slides/04-slides.html#the-apply-family",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "The apply family",
    "text": "The apply family\n\nVectorized functions that eliminate explicit for loops\nDiffer by the class they work on and the output they return\napply, lapply are most common; extensions for parallel processing (e.g., parallel::mclapply)"
  },
  {
    "objectID": "slides/04-slides.html#the-apply-family-1",
    "href": "slides/04-slides.html#the-apply-family-1",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "The apply family",
    "text": "The apply family\n\napply for vectors and data frames\nArgs: X for the data, MARGIN how will the function be applied, (1=rows, 2=columns), FUN for your function, ... for other arguments to the function\n\n\napply(mtcars, 2, mean)\n\n       mpg        cyl       disp         hp       drat         wt       qsec \n 20.090625   6.187500 230.721875 146.687500   3.596563   3.217250  17.848750 \n        vs         am       gear       carb \n  0.437500   0.406250   3.687500   2.812500"
  },
  {
    "objectID": "slides/04-slides.html#the-apply-family-2",
    "href": "slides/04-slides.html#the-apply-family-2",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "The apply family",
    "text": "The apply family\n\nlapply for lists (either input or output)\nArgs: X for the data, FUN for your function, ... for other arguments to the function\n\n\ndata <- list(item1 = 1:4, \n             item2 = rnorm(10), \n             item3 = rnorm(20, 1), \n             item4 = rnorm(100, 5))\n\n# get the mean of each list item \nlapply(data, mean)\n\n$item1\n[1] 2.5\n\n$item2\n[1] -0.3173127\n\n$item3\n[1] 1.294093\n\n$item4\n[1] 5.088717"
  },
  {
    "objectID": "slides/04-slides.html#the-map-family",
    "href": "slides/04-slides.html#the-map-family",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "The map family",
    "text": "The map family\n\nSimilar to apply, but more consistent input/output\nAll take a vector for input\nDifference is based on the output you expect\nIntegrates with tidyverse"
  },
  {
    "objectID": "slides/04-slides.html#the-map-family-1",
    "href": "slides/04-slides.html#the-map-family-1",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "The map family",
    "text": "The map family\n\nmap(): output is a list\nmap_int(): output is an integer vector\nmap_lgl(): output is a logical vector\nmap_dbl(): output is a double vector\nmap_chr(): output is a character vector\nmap_df(), map_dfr(), map_dfc(): output is a dataframe (r and c specify how to combine the data)"
  },
  {
    "objectID": "slides/04-slides.html#some-parting-thoughts",
    "href": "slides/04-slides.html#some-parting-thoughts",
    "title": "Repetitive Tasks and Functional Programming",
    "section": "Some parting thoughts",
    "text": "Some parting thoughts\n\nTransparency vs. speed\nTesting\nMoving forward"
  },
  {
    "objectID": "slides/06-slides.html#objectives",
    "href": "slides/06-slides.html#objectives",
    "title": "Spatial Data is Special Data",
    "section": "Objectives",
    "text": "Objectives\n\nArticulate why we care about space\nDescribe elements of spatial data\nDefine a coordinate reference system and its importance\nDescribe several ways to load spatial data into R\nIdentify projections in R"
  },
  {
    "objectID": "slides/06-slides.html#locations-relations-and-understanding",
    "href": "slides/06-slides.html#locations-relations-and-understanding",
    "title": "Spatial Data is Special Data",
    "section": "Locations, Relations, and Understanding",
    "text": "Locations, Relations, and Understanding\n\nGeography uses location to understand how social and physical processes give rise to the environment we experience\nGeographic Information Systems provide a structure for storing, visualizing, and describing location data.\nGeoComputation and GIScience integrate math, stats, and high-performance computing to move beyond description."
  },
  {
    "objectID": "slides/06-slides.html#location-lets-us-ask",
    "href": "slides/06-slides.html#location-lets-us-ask",
    "title": "Spatial Data is Special Data",
    "section": "Location lets us ask:",
    "text": "Location lets us ask:\n\nQuestions about geographic distribution\nQuestions about geographic interaction\nQuestions about geographic change\nQuestions about geographic association\nQuestions about causation?"
  },
  {
    "objectID": "slides/06-slides.html#location-vs.-place",
    "href": "slides/06-slides.html#location-vs.-place",
    "title": "Spatial Data is Special Data",
    "section": "Location vs. Place",
    "text": "Location vs. Place\n\nPlace: an area having unique physical and human characteristics interconnected with other places\nLocation: the actual position on the earth’s surface\nSense of Place: the emotions someone attaches to an area based on experiences\nPlace is location plus meaning"
  },
  {
    "objectID": "slides/06-slides.html#describing-location",
    "href": "slides/06-slides.html#describing-location",
    "title": "Spatial Data is Special Data",
    "section": "Describing Location",
    "text": "Describing Location\n\nnominal: (potentially contested) place names\nabsolute: the physical location on the earth’s surface"
  },
  {
    "objectID": "slides/06-slides.html#describing-absolute-locations",
    "href": "slides/06-slides.html#describing-absolute-locations",
    "title": "Spatial Data is Special Data",
    "section": "Describing Absolute Locations",
    "text": "Describing Absolute Locations\n\nCoordinates: 2 or more measurements that specify location relative to a reference system\n\n\n\n\n\nCartesian coordinate system\norigin (O) = the point at which both measurement systems intersect\nAdaptable to multiple dimensions (e.g. z for altitude)\n\n\n\n\n\n\nCartesian Coordinate System"
  },
  {
    "objectID": "slides/06-slides.html#locations-on-a-globe",
    "href": "slides/06-slides.html#locations-on-a-globe",
    "title": "Spatial Data is Special Data",
    "section": "Locations on a Globe",
    "text": "Locations on a Globe\n\nThe earth is not flat…\n\n\n\n\n\n\nLatitude and Longitude\n\n\n\n\n\nGlobal Reference Systems (GRS)\nGraticule: the grid formed by the intersection of longitude and latitude\nThe graticule is based on an ellipsoid model of earth’s surface and contained in the datum"
  },
  {
    "objectID": "slides/06-slides.html#global-reference-systems",
    "href": "slides/06-slides.html#global-reference-systems",
    "title": "Spatial Data is Special Data",
    "section": "Global Reference Systems",
    "text": "Global Reference Systems\n\nThe datum describes which ellipsoid to use and the precise relations between locations on earth’s surface and Cartesian coordinates\n\n\nGeodetic datums (e.g., WGS84): distance from earth’s center of gravity\nLocal data (e.g., NAD83): better models for local variation in earth’s surface"
  },
  {
    "objectID": "slides/06-slides.html#the-earth-is-not-flat",
    "href": "slides/06-slides.html#the-earth-is-not-flat",
    "title": "Spatial Data is Special Data",
    "section": "The Earth is Not Flat",
    "text": "The Earth is Not Flat\n\n\n\n\nBut maps, screens, and publications are…\nProjections describe how the data should be translated to a flat surface\nRely on ‘developable surfaces’\n\n\n\n\n\n\nDevelopable Surfaces\n\n\n\n\n\nProjection necessarily induces some form of distortion (tearing, compression, or shearing("
  },
  {
    "objectID": "slides/06-slides.html#choosing-projections",
    "href": "slides/06-slides.html#choosing-projections",
    "title": "Spatial Data is Special Data",
    "section": "Choosing Projections",
    "text": "Choosing Projections\n\n\n\n\n\n\nSome projections minimize distortion of angle, area, or distance\nOthers attempt to avoid extreme distortion of any kind\nParticularly challenging for raster data"
  },
  {
    "objectID": "slides/06-slides.html#choosing-projections-1",
    "href": "slides/06-slides.html#choosing-projections-1",
    "title": "Spatial Data is Special Data",
    "section": "Choosing Projections",
    "text": "Choosing Projections\n\nEqual-area for thematic maps\nConformal for presentations\nMercator or equidistant for navigation and distance"
  },
  {
    "objectID": "slides/06-slides.html#data-types-and-r-packages",
    "href": "slides/06-slides.html#data-types-and-r-packages",
    "title": "Spatial Data is Special Data",
    "section": "Data Types and R Packages",
    "text": "Data Types and R Packages\n\n\nData Types\n\nVector Data\n\nPoint features\nLine features\nArea features (polygons)\n\nRaster Data\n\nSpatially continuous field\nBased on pixels (not points)"
  },
  {
    "objectID": "slides/06-slides.html#mapping-loaction-coordinate-reference-systems",
    "href": "slides/06-slides.html#mapping-loaction-coordinate-reference-systems",
    "title": "Spatial Data is Special Data",
    "section": "Mapping loaction: Coordinate Reference Systems",
    "text": "Mapping loaction: Coordinate Reference Systems\n\nIncludes: Datum, ellipsoid, units, and other information (e.g., False Easting, Central Meridian) to further map the projection to the GCS\nNot all projections have/require all of the parameters\nR stores these data in several formats (EPSG, Proj, and WKT)\nLots of projection info available at spatialreference.org"
  },
  {
    "objectID": "slides/06-slides.html#mapping-loaction-coordinate-reference-systems-1",
    "href": "slides/06-slides.html#mapping-loaction-coordinate-reference-systems-1",
    "title": "Spatial Data is Special Data",
    "section": "Mapping loaction: Coordinate Reference Systems",
    "text": "Mapping loaction: Coordinate Reference Systems\n\nPrimarily accessed using sf::st_crs() or terra::crs()\n\n\nf <- rast(system.file(\"ex/meuse.tif\", package=\"terra\"))\nnc <- st_read(system.file(\"shape/nc.shp\", package=\"sf\"))\nst_crs(nc)\ncrs(nc)"
  },
  {
    "objectID": "slides/06-slides.html#mapping-location-extent",
    "href": "slides/06-slides.html#mapping-location-extent",
    "title": "Spatial Data is Special Data",
    "section": "Mapping location: Extent",
    "text": "Mapping location: Extent\n\nExtent: The amount of the Earth’s surface represented by the mapped features\n\nR has a very specific definition of extent: the rectangular region encompassed by the data"
  },
  {
    "objectID": "slides/06-slides.html#using-r-to-access-the-extent",
    "href": "slides/06-slides.html#using-r-to-access-the-extent",
    "title": "Spatial Data is Special Data",
    "section": "Using R to access the extent",
    "text": "Using R to access the extent\n\nUsing st_bbox() from the sf package\n\n\nnc.shp <- st_read(system.file(\"shape/nc.shp\", package=\"sf\")) \n\nReading layer `nc' from data source \n  `/Library/Frameworks/R.framework/Versions/4.2/Resources/library/sf/shape/nc.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 100 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\nGeodetic CRS:  NAD27\n\nmeuse.rst <- rast(system.file(\"ex/meuse.tif\", package=\"terra\"))\nst_bbox(nc.shp)\n\n     xmin      ymin      xmax      ymax \n-84.32385  33.88199 -75.45698  36.58965 \n\nst_bbox(meuse.rst)\n\n  xmin   ymin   xmax   ymax \n178400 329400 181600 334000"
  },
  {
    "objectID": "slides/06-slides.html#using-r-to-access-the-extent-1",
    "href": "slides/06-slides.html#using-r-to-access-the-extent-1",
    "title": "Spatial Data is Special Data",
    "section": "Using R to access the extent",
    "text": "Using R to access the extent\n\nUsing ext() from the terra package\n\n\next(nc.shp)\n\nSpatExtent : -84.3238525390625, -75.4569778442383, 33.8819923400879, 36.5896492004395 (xmin, xmax, ymin, ymax)\n\next(meuse.rst)\n\nSpatExtent : 178400, 181600, 329400, 334000 (xmin, xmax, ymin, ymax)"
  },
  {
    "objectID": "slides/06-slides.html#mapping-location-resolution",
    "href": "slides/06-slides.html#mapping-location-resolution",
    "title": "Spatial Data is Special Data",
    "section": "Mapping location: Resolution",
    "text": "Mapping location: Resolution\n\nResolution: the accuracy that the location and shape of a map’s features can be depicted\nMinimum Mapping Unit: The minimum size and dimensions that can be reliably represented at a given map scale.\nMap scale vs. scale of analysis"
  },
  {
    "objectID": "slides/06-slides.html#mapping-location-resolution-1",
    "href": "slides/06-slides.html#mapping-location-resolution-1",
    "title": "Spatial Data is Special Data",
    "section": "Mapping location: Resolution",
    "text": "Mapping location: Resolution"
  },
  {
    "objectID": "slides/06-slides.html#using-r-to-access-resolution",
    "href": "slides/06-slides.html#using-r-to-access-resolution",
    "title": "Spatial Data is Special Data",
    "section": "Using R to access resolution",
    "text": "Using R to access resolution\n\nThematically defined for vector datasets (check your metadata!!)\nUsing res() in terra\n\n\nf <- rast(system.file(\"ex/meuse.tif\", package=\"terra\"))\nres(f)\n\n[1] 40 40"
  },
  {
    "objectID": "slides/06-slides.html#todays-goals",
    "href": "slides/06-slides.html#todays-goals",
    "title": "Spatial Data is Special Data",
    "section": "Today’s goals",
    "text": "Today’s goals\n\nArticulate why we care about space\nDescribe elements of spatial data\nDefine a coordinate reference system and its importance\nDescribe several ways to load spatial data into R\nIdentify projections in R"
  },
  {
    "objectID": "slides/07-slides.html#objectives",
    "href": "slides/07-slides.html#objectives",
    "title": "Spatial Data as Vectors",
    "section": "Objectives",
    "text": "Objectives\n\nArticulate the role of the data model in geographic information systems\nDescribe the key elements of vector data\nUse the sf package to read and manipulate vector data\nDefine geometry in the context of vector objects and troubleshoot common problems"
  },
  {
    "objectID": "slides/07-slides.html#what-is-a-data-model",
    "href": "slides/07-slides.html#what-is-a-data-model",
    "title": "Spatial Data as Vectors",
    "section": "What is a data model?",
    "text": "What is a data model?\n\n\nData: a collection of discrete values that describe phenomena\nYour brain stores millions of pieces of data\nComputers are not your brain\n\nNeed to organize data systematically\nBe able to display and access efficiently\nNeed to be able to store and access repeatedly\n\nData models solve this problem"
  },
  {
    "objectID": "slides/07-slides.html#types-of-spatial-data-models",
    "href": "slides/07-slides.html#types-of-spatial-data-models",
    "title": "Spatial Data as Vectors",
    "section": "2 Types of Spatial Data Models",
    "text": "2 Types of Spatial Data Models\n\nRaster: grid-cell tessellation of an area. Each raster describes the value of a single phenomenon. More next week…\nVector: (many) attributes associated with locations defined by coordinates"
  },
  {
    "objectID": "slides/07-slides.html#the-vector-data-model",
    "href": "slides/07-slides.html#the-vector-data-model",
    "title": "Spatial Data as Vectors",
    "section": "The Vector Data Model",
    "text": "The Vector Data Model\n\n\n\n\nVertices (i.e., discrete x-y locations) define the shape of the vector\nThe organization of those vertices define the shape of the vector\nGeneral types: points, lines, polygons\n\n\n\n\n\n\nImage Source: Colin Williams (NEON)"
  },
  {
    "objectID": "slides/07-slides.html#vectors-in-action",
    "href": "slides/07-slides.html#vectors-in-action",
    "title": "Spatial Data as Vectors",
    "section": "Vectors in Action",
    "text": "Vectors in Action\n\n\nUseful for locations with discrete, well-defined boundaries\nVery precise (not necessarily accurate)\nNot the same as the vector data class\n\n\n\nImage Source: QGIS User’s manual"
  },
  {
    "objectID": "slides/07-slides.html#representing-vector-data-in-r",
    "href": "slides/07-slides.html#representing-vector-data-in-r",
    "title": "Spatial Data as Vectors",
    "section": "Representing vector data in R",
    "text": "Representing vector data in R\n\n\n\n\n\nFrom Lovelace et al.\n\n\n\n\n\nsf hierarchy reflects increasing complexity of geometry\n\nst_point, st_linestring, st_polygon for single features\nst_multi* for multiple features of the same type\nst_geometrycollection for multiple feature types\nst_as_sfc creates the geometry list column for many sf operations"
  },
  {
    "objectID": "slides/07-slides.html#points",
    "href": "slides/07-slides.html#points",
    "title": "Spatial Data as Vectors",
    "section": "Points",
    "text": "Points\n\nlibrary(sf)\nproj <- st_crs('+proj=longlat +datum=WGS84')\nlong <- c(-116.7, -120.4, -116.7, -113.5, -115.5, -120.8, -119.5, -113.7, -113.7, -110.7)\nlat <- c(45.3, 42.6, 38.9, 42.1, 35.7, 38.9, 36.2, 39, 41.6, 36.9)\nst_multipoint(cbind(long, lat)) %>% st_sfc(., crs = proj)\n\nGeometry set for 1 feature \nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: -120.8 ymin: 35.7 xmax: -110.7 ymax: 45.3\nCRS:           +proj=longlat +datum=WGS84"
  },
  {
    "objectID": "slides/07-slides.html#points-1",
    "href": "slides/07-slides.html#points-1",
    "title": "Spatial Data as Vectors",
    "section": "Points",
    "text": "Points\n\nplot(st_multipoint(cbind(long, lat)) %>% \n                   st_sfc(., crs = proj))"
  },
  {
    "objectID": "slides/07-slides.html#lines",
    "href": "slides/07-slides.html#lines",
    "title": "Spatial Data as Vectors",
    "section": "Lines",
    "text": "Lines\n\nlon <- c(-116.8, -114.2, -112.9, -111.9, -114.2, -115.4, -117.7)\nlat <- c(41.3, 42.9, 42.4, 39.8, 37.6, 38.3, 37.6)\nlonlat <- cbind(lon, lat)\npts <- st_multipoint(lonlat)\n\nsfline <- st_multilinestring(list(pts[1:3,], pts[4:7,]))\nstr(sfline)\n\nList of 2\n $ : num [1:3, 1:2] -116.8 -114.2 -112.9 41.3 42.9 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"lon\" \"lat\"\n $ : num [1:4, 1:2] -111.9 -114.2 -115.4 -117.7 39.8 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"lon\" \"lat\"\n - attr(*, \"class\")= chr [1:3] \"XY\" \"MULTILINESTRING\" \"sfg\""
  },
  {
    "objectID": "slides/07-slides.html#lines-1",
    "href": "slides/07-slides.html#lines-1",
    "title": "Spatial Data as Vectors",
    "section": "Lines",
    "text": "Lines\n\nplot(st_multilinestring(list(pts[1:3,], pts[4:7,])))"
  },
  {
    "objectID": "slides/07-slides.html#polygons",
    "href": "slides/07-slides.html#polygons",
    "title": "Spatial Data as Vectors",
    "section": "Polygons",
    "text": "Polygons\n\nouter = matrix(c(0,0,10,0,10,10,0,10,0,0),ncol=2, byrow=TRUE)\nhole1 = matrix(c(1,1,1,2,2,2,2,1,1,1),ncol=2, byrow=TRUE)\nhole2 = matrix(c(5,5,5,6,6,6,6,5,5,5),ncol=2, byrow=TRUE)\ncoords = list(outer, hole1, hole2)\npl1 = st_polygon(coords)"
  },
  {
    "objectID": "slides/07-slides.html#polygons-1",
    "href": "slides/07-slides.html#polygons-1",
    "title": "Spatial Data as Vectors",
    "section": "Polygons",
    "text": "Polygons\n\nplot(pl1)"
  },
  {
    "objectID": "slides/07-slides.html#but-what-about-actual-data",
    "href": "slides/07-slides.html#but-what-about-actual-data",
    "title": "Spatial Data as Vectors",
    "section": "But what about actual data?",
    "text": "But what about actual data?\n\nConvert a data frame to sf object\n\nUseful for situations where point locations given as columns in spreadsheet\nRequires that you the projection used when the data were collected\nUsing the meuse dataset (use ?sp::meuse to learn more about it)\n\n\n\nlibrary(sp)\ndata(meuse)\nhead(meuse, n=3)[,1:10]\n\n       x      y cadmium copper lead zinc  elev       dist   om ffreq\n1 181072 333611    11.7     85  299 1022 7.909 0.00135803 13.6     1\n2 181025 333558     8.6     81  277 1141 6.983 0.01222430 14.0     1\n3 181165 333537     6.5     68  199  640 7.800 0.10302900 13.0     1"
  },
  {
    "objectID": "slides/07-slides.html#plotting-sf-objects",
    "href": "slides/07-slides.html#plotting-sf-objects",
    "title": "Spatial Data as Vectors",
    "section": "Plotting sf objects",
    "text": "Plotting sf objects\n\nQuick way to check your data\nRemember that sf has geometry and attributes\n\n\nplot(meuse_sf)"
  },
  {
    "objectID": "slides/07-slides.html#plotting-sf-objects-1",
    "href": "slides/07-slides.html#plotting-sf-objects-1",
    "title": "Spatial Data as Vectors",
    "section": "Plotting sf objects",
    "text": "Plotting sf objects\n\nplot(meuse_sf['lead'])"
  },
  {
    "objectID": "slides/07-slides.html#plotting-sf-objects-2",
    "href": "slides/07-slides.html#plotting-sf-objects-2",
    "title": "Spatial Data as Vectors",
    "section": "Plotting sf objects",
    "text": "Plotting sf objects\n\nplot(st_geometry(meuse_sf))"
  },
  {
    "objectID": "slides/07-slides.html#common-problems-with-vector-data",
    "href": "slides/07-slides.html#common-problems-with-vector-data",
    "title": "Spatial Data as Vectors",
    "section": "Common Problems with Vector Data",
    "text": "Common Problems with Vector Data\n\n\n\n\nVectors and scale\nSlivers and overlaps\nUndershoots and overshoots\nSelf-intersections and rings\n\n\n\n\n\n\nTopology Errors - Saylor Acad.\n\n\n\n\n\nWe’ll use st_is_valid() to check this, but fixing can be tricky"
  },
  {
    "objectID": "slides/07-slides.html#fixing-problematic-topology",
    "href": "slides/07-slides.html#fixing-problematic-topology",
    "title": "Spatial Data as Vectors",
    "section": "Fixing Problematic Topology",
    "text": "Fixing Problematic Topology\n\nst_make_valid() for simple cases\nst_buffer with dist=0\nMore complex errors need more complex approaches"
  },
  {
    "objectID": "slides/07-slides.html#a-note-on-vectors",
    "href": "slides/07-slides.html#a-note-on-vectors",
    "title": "Spatial Data as Vectors",
    "section": "A Note on Vectors",
    "text": "A Note on Vectors\n\nMoving forward we will rely primarily on the sf package for vector manipulation. Some packages require objects to be a different class. terra, for example, relies on SpatVectors. You can use as() to coerce objects from one type to another (assuming a method exists). You can also explore other packages. Many packages provide access to the ‘spatial’ backbones of R (like geos and gdal), they just differ in how the “verbs” are specified. For sf operations the st_ prefix is typical. For rgeos operations, the g prefix is common."
  },
  {
    "objectID": "slides/08-slides.html#objectives",
    "href": "slides/08-slides.html#objectives",
    "title": "Vector Operations Part 1",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today, you should be able to:\n\nUnderstand predicates and measures in the context of spatial operations in sf\nDefine valid geometries and approaches for assessing geometries in R\nUse st_* and sf_* to evaluate attributes of geometries and calculate measurements"
  },
  {
    "objectID": "slides/08-slides.html#revisiting-simple-features",
    "href": "slides/08-slides.html#revisiting-simple-features",
    "title": "Vector Operations Part 1",
    "section": "Revisiting Simple Features",
    "text": "Revisiting Simple Features\n\n\n\n\nThe sf package relies on a simple feature data model to represent geometries\n\nhierarchical\nstandardized methods\ncomplementary binary and human-readable encoding\n\n\n\n\n\n\n\n\n\n\n\n\ntype\ndescription\n\n\n\n\nPOINT\nsingle point geometry\n\n\nMULTIPOINT\nset of points\n\n\nLINESTRING\nsingle linestring (two or more points connected by straight lines)\n\n\nMULTILINESTRING\nset of linestrings\n\n\nPOLYGON\nexterior ring with zero or more inner rings, denoting holes\n\n\nMULTIPOLYGON\nset of polygons\n\n\nGEOMETRYCOLLECTION\nset of the geometries above"
  },
  {
    "objectID": "slides/08-slides.html#standaridized-methods",
    "href": "slides/08-slides.html#standaridized-methods",
    "title": "Vector Operations Part 1",
    "section": "Standaridized Methods",
    "text": "Standaridized Methods\n\nWe can categorize sf operations based on what they return and/or how many geometries they accept as input.\n\n\n\n\n\nOutput Categories\n\nPredicates: evaluate a logical statement asserting that a property is TRUE\nMeasures: return a numeric value with units based on the units of the CRS\nTransformations: create new geometries based on input geometries.\n\n\n\n\n\n\nInput Geometries\n\nUnary: operate on a single geometry at a time (meaning that if you have a MULTI* object the function works on each geometry individually)\nBinary: operate on pairs of geometries\nn-ary: operate on sets of geometries"
  },
  {
    "objectID": "slides/08-slides.html#remembering-valid-geometries",
    "href": "slides/08-slides.html#remembering-valid-geometries",
    "title": "Vector Operations Part 1",
    "section": "Remembering Valid Geometries",
    "text": "Remembering Valid Geometries\n\nA linestring is simple if it does not intersect\n\n\n\n\nlibrary(sf)\n(ls = st_linestring(rbind(c(0,0), c(1,1), \n                          c(2,2), c(0,2), \n                          c(1,1), c(2,0))))\nc(is_simple = st_is_simple(ls))\n\nis_simple \n    FALSE"
  },
  {
    "objectID": "slides/08-slides.html#remembering-valid-geometries-1",
    "href": "slides/08-slides.html#remembering-valid-geometries-1",
    "title": "Vector Operations Part 1",
    "section": "Remembering Valid Geometries",
    "text": "Remembering Valid Geometries\n\n\n\n\nValid polygons\n\nAre closed (i.e., the last vertex equals the first)\nHave holes (inner rings) that inside the the exterior boundary\nHave holes that touch the exterior at no more than one vertex (they don’t extend across a line)\n\nFor multipolygons, adjacent polygons touch only at points\n\nDo not repeat their own path"
  },
  {
    "objectID": "slides/08-slides.html#empty-geometries",
    "href": "slides/08-slides.html#empty-geometries",
    "title": "Vector Operations Part 1",
    "section": "Empty Geometries",
    "text": "Empty Geometries\n\nEmpty geometries arise when an operation produces NULL outcomes (like looking for the intersection between two non-intersecting polygons)\nsf allows empty geometries to make sure that information about the data type is retained\nSimilar to a data.frame with no rows or a list with NULL values\nMost vector operations require simple, valid geometries"
  },
  {
    "objectID": "slides/08-slides.html#using-unary-predicates",
    "href": "slides/08-slides.html#using-unary-predicates",
    "title": "Vector Operations Part 1",
    "section": "Using Unary Predicates",
    "text": "Using Unary Predicates\n\nUnary predicates accept single geometries (or geometry collections)\nProvide helpful ways to check whether your data is ready to analyze\nUse the st_ prefix and return TRUE/FALSE\n\n\n\n\n\n\n\n\n\npredicate\nasks…\n\n\n\n\nis_simple\nis the geometry self-intersecting (i.e., simple)?\n\n\nis_valid\nis the geometry valid?\n\n\nis_empty\nis the geometry column of an object empty?\n\n\nis_longlat\ndoes the object have geographic coordinates? (FALSE if coords are projected, NA if no crs)\n\n\nis(geometry, class)\nis the geometry of a particular class?"
  },
  {
    "objectID": "slides/08-slides.html#using-unary-predicates-1",
    "href": "slides/08-slides.html#using-unary-predicates-1",
    "title": "Vector Operations Part 1",
    "section": "Using Unary Predicates",
    "text": "Using Unary Predicates\n\n\n\nnc <- st_read(\n  system.file(\"shape/nc.shp\", package=\"sf\"), \n  quiet=TRUE)\nplot(st_geometry(nc))\n\n\n\n\n\n\nst_is_longlat(nc)\n\n[1] TRUE\n\nany(is.na(st_is_valid(nc)))\n\n[1] FALSE"
  },
  {
    "objectID": "slides/08-slides.html#checking-geometries-with-unary-predicates",
    "href": "slides/08-slides.html#checking-geometries-with-unary-predicates",
    "title": "Vector Operations Part 1",
    "section": "Checking Geometries With Unary Predicates",
    "text": "Checking Geometries With Unary Predicates\n\nBefore conducting costly analyses, it’s worth checking for:\n\n\n\nempty geometries, using any(is.na(st_dimension(x)))\ncorrupt geometries, using any(is.na(st_is_valid(x)))\ninvalid geometries, using any(na.omit(st_is_valid(x)) == FALSE); in case of corrupt and/or invalid geometries,\nin case of invalid geometries, query the reason for invalidity by st_is_valid(x, reason = TRUE)\n\n\nInvalid geometries will require transformation (next week!)"
  },
  {
    "objectID": "slides/08-slides.html#binary-predicates-1",
    "href": "slides/08-slides.html#binary-predicates-1",
    "title": "Vector Operations Part 1",
    "section": "Binary Predicates",
    "text": "Binary Predicates\n\n\nAccept exactly two geometries (or collections)\nAlso return logical outcomes\nBased on the Dimensionally Extended 9-Intersection Model (DE-9IM)\n\n\n\n\n\n\npredicate\nmeaning\ninverse of\n\n\n\n\ncontains\nNone of the points of A are outside B\nwithin\n\n\ncontains_properly\nA contains B and B has no points in common with the boundary of A\n\n\n\ncovers\nNo points of B lie in the exterior of A\ncovered_by\n\n\ncovered_by\nInverse of covers\n\n\n\ncrosses\nA and B have some but not all interior points in common\n\n\n\ndisjoint\nA and B have no points in common\nintersects\n\n\nequals\nA and B are topologically equal: node order or number of nodes may differ; identical to A contains B AND A within B\n\n\n\nequals_exact\nA and B are geometrically equal, and have identical node order\n\n\n\nintersects\nA and B are not disjoint\ndisjoint\n\n\nis_within_distance\nA is closer to B than a given distance\n\n\n\nwithin\nNone of the points of B are outside A\ncontains\n\n\ntouches\nA and B have at least one boundary point in common, but no interior points\n\n\n\noverlaps\nA and B have some points in common; the dimension of these is identical to that of A and B\n\n\n\nrelate\ngiven a mask pattern, return whether A and B adhere to this pattern"
  },
  {
    "objectID": "slides/08-slides.html#measures-1",
    "href": "slides/08-slides.html#measures-1",
    "title": "Vector Operations Part 1",
    "section": "Measures",
    "text": "Measures\nUnary Measures\n\nReturn quantities of individual geometries\n\n\n\n\n\n\n\n\n\nmeasure\nreturns\n\n\n\n\ndimension\n0 for points, 1 for linear, 2 for polygons, possibly NA for empty geometries\n\n\narea\nthe area of a geometry\n\n\nlength\nthe length of a linear geometry\n\n\n\n\nBinary Measures\n\nst_distance returns the distance between pairs of geometries"
  },
  {
    "objectID": "slides/09-slides.html#your-final-project",
    "href": "slides/09-slides.html#your-final-project",
    "title": "Vector Operations Part 1I",
    "section": "Your final project",
    "text": "Your final project\n\nAt least 5 datasets total (1 tabular, 1 vector, 1 raster, and 2 of your choosing)\nChoose 1 statistical approach to address your research question\nVisualizations - minimum of 3. 1 location map; the others should help address your question\nSubmission formats\nA note about your discussion"
  },
  {
    "objectID": "slides/09-slides.html#objectives",
    "href": "slides/09-slides.html#objectives",
    "title": "Vector Operations Part 1I",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today, you should be able to:\n\nComplete a workflow for identifying and remedying invalid geometries\nDescribe the various unary, binary, and n-ary transformers\nUse predicates and dplyr::filter to subset spatial data"
  },
  {
    "objectID": "slides/09-slides.html#revisiting-predicates-and-measures",
    "href": "slides/09-slides.html#revisiting-predicates-and-measures",
    "title": "Vector Operations Part 1I",
    "section": "Revisiting predicates and measures",
    "text": "Revisiting predicates and measures\n\nPredicates: evaluate a logical statement asserting that a property is TRUE\nMeasures: return a numeric value with units based on the units of the CRS\nUnary, binary, and n-ary distinguish how many geometries each function accepts and returns"
  },
  {
    "objectID": "slides/09-slides.html#transformations",
    "href": "slides/09-slides.html#transformations",
    "title": "Vector Operations Part 1I",
    "section": "Transformations",
    "text": "Transformations\n\n\nTransformations: create new geometries based on input geometries"
  },
  {
    "objectID": "slides/09-slides.html#unary-transformations",
    "href": "slides/09-slides.html#unary-transformations",
    "title": "Vector Operations Part 1I",
    "section": "Unary Transformations",
    "text": "Unary Transformations\n\n\n\n\n\n\n\n\ntransformer\nreturns a geometry …\n\n\n\n\ncentroid\nof type POINT with the geometry’s centroid\n\n\nbuffer\nthat is this larger (or smaller) than the input geometry, depending on the buffer size\n\n\njitter\nthat was moved in space a certain amount, using a bivariate uniform distribution\n\n\nwrap_dateline\ncut into pieces that do no longer cover the dateline\n\n\nboundary\nwith the boundary of the input geometry\n\n\nconvex_hull\nthat forms the convex hull of the input geometry\n\n\nline_merge\nafter merging connecting LINESTRING elements of a MULTILINESTRING into longer LINESTRINGs.\n\n\nmake_valid\nthat is valid\n\n\nnode\nwith added nodes to linear geometries at intersections without a node; only works on individual linear geometries\n\n\npoint_on_surface\nwith a (arbitrary) point on a surface\n\n\npolygonize\nof type polygon, created from lines that form a closed ring"
  },
  {
    "objectID": "slides/09-slides.html#unary-transformations-contd",
    "href": "slides/09-slides.html#unary-transformations-contd",
    "title": "Vector Operations Part 1I",
    "section": "Unary Transformations (cont’d)",
    "text": "Unary Transformations (cont’d)\n\n\n\n\n\n\n\n\ntransformer\nreturns a geometry …\n\n\n\n\nsegmentize\na (linear) geometry with nodes at a given density or minimal distance\n\n\nsimplify\nsimplified by removing vertices/nodes (lines or polygons)\n\n\nsplit\nthat has been split with a splitting linestring\n\n\ntransform\ntransformed or convert to a new coordinate reference system (chapter @ref(cs))\n\n\ntriangulate\nwith Delauney triangulated polygon(s) (figure @ref(fig:vor))\n\n\nvoronoi\nwith the Voronoi tessellation of an input geometry (figure @ref(fig:vor))\n\n\nzm\nwith removed or added Z and/or M coordinates\n\n\ncollection_extract\nwith subgeometries from a GEOMETRYCOLLECTION of a particular type\n\n\ncast\nthat is converted to another type\n\n\n+\nthat is shifted over a given vector\n\n\n*\nthat is multiplied by a scalar or matrix"
  },
  {
    "objectID": "slides/09-slides.html#common-uses-of-unary-transformers",
    "href": "slides/09-slides.html#common-uses-of-unary-transformers",
    "title": "Vector Operations Part 1I",
    "section": "Common uses of Unary Transformers",
    "text": "Common uses of Unary Transformers\n\nCreating valid geometries\nReprojecting your data\nCombining or changing geometries"
  },
  {
    "objectID": "slides/09-slides.html#binary-transformers",
    "href": "slides/09-slides.html#binary-transformers",
    "title": "Vector Operations Part 1I",
    "section": "Binary Transformers",
    "text": "Binary Transformers\n\n\n\n\n\n\n\n\n\nfunction\nreturns\ninfix operator\n\n\n\n\nintersection\nthe overlapping geometries for pair of geometries\n&\n\n\nunion\nthe combination of the geometries; removes internal boundaries and duplicate points, nodes or line pieces\n|\n\n\ndifference\nthe geometries of the first after removing the overlap with the second geometry\n/\n\n\nsym_difference\nthe combinations of the geometries after removing where they intersect; the negation (opposite) of intersection\n%/%\n\n\ncrop\ncrop an sf object to a specific rectangle"
  },
  {
    "objectID": "slides/09-slides.html#binary-transformers-1",
    "href": "slides/09-slides.html#binary-transformers-1",
    "title": "Vector Operations Part 1I",
    "section": "Binary Transformers",
    "text": "Binary Transformers"
  },
  {
    "objectID": "slides/09-slides.html#common-uses-of-binary-transformers",
    "href": "slides/09-slides.html#common-uses-of-binary-transformers",
    "title": "Vector Operations Part 1I",
    "section": "Common Uses of Binary Transformers",
    "text": "Common Uses of Binary Transformers\n\nRelating partially overlapping datasets to each other\nReducing the extent of vector objects"
  },
  {
    "objectID": "slides/09-slides.html#n-ary-transformers",
    "href": "slides/09-slides.html#n-ary-transformers",
    "title": "Vector Operations Part 1I",
    "section": "N-ary Transformers",
    "text": "N-ary Transformers\n\nSimilar to Binary (except st_crop)\nunion can be applied to a set of geometries to return its geometrical union\nintersection and difference take a single argument, but operate (sequentially) on all pairs, triples, quadruples, etc."
  },
  {
    "objectID": "slides/09-slides.html#subsetting-data-1",
    "href": "slides/09-slides.html#subsetting-data-1",
    "title": "Vector Operations Part 1I",
    "section": "Subsetting Data",
    "text": "Subsetting Data\n\nOften want to restrict analyses to particular locations\nCan combine predicates with [] to subset based on geography\nCan also use dplyr::filter and dplyr::select to subset using attributes"
  },
  {
    "objectID": "slides/09-slides.html#using-predicates",
    "href": "slides/09-slides.html#using-predicates",
    "title": "Vector Operations Part 1I",
    "section": "Using predicates",
    "text": "Using predicates\n\nCan combine predicates with [] to subset based on topological relations\nx[y, , op = st_intersects]\nst_filter( x = x, y = y, .predicate = st_intersects)"
  },
  {
    "objectID": "slides/09-slides.html#using-dplyr",
    "href": "slides/09-slides.html#using-dplyr",
    "title": "Vector Operations Part 1I",
    "section": "Using dplyr",
    "text": "Using dplyr\n\n\nfilter returns rows that match a criteria\nselect returns columns\n\n\n\n\n\nlibrary(tidyverse)\ndurham.cty <- nc %>% \n  filter(., NAME == \"Durham\")\n## We can also use the bracket approach\ndurham.cty2 <- nc[nc$NAME == \"Durham\",]\n\nplot(st_geometry(nc))\nplot(st_geometry(durham.cty), add=TRUE, col=\"blue\")\n\n\n\n\n\n\nnc.select <- nc %>% \n  select(., c(\"BIR79\", \"SID79\"))\nplot(nc.select)"
  },
  {
    "objectID": "slides/10-slides.html#objectives",
    "href": "slides/10-slides.html#objectives",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Objectives",
    "text": "Objectives\n\nBy the end of today, you should be able to:\n\nDescribe the raster data model and its representation in R\nAccess the elements that define a raster\nBuild rasters from scratch using matrix operations and terra"
  },
  {
    "objectID": "slides/10-slides.html#defining-the-raster-data-model-1",
    "href": "slides/10-slides.html#defining-the-raster-data-model-1",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Defining the Raster Data Model",
    "text": "Defining the Raster Data Model\n\n\n\n\nVector data describe the “exact” locations of features on a landscape (including a Cartesian landscape)\nRaster data represent spatially continuous phenomena (NA is possible)\nDepict the alignment of data on a regular lattice (often a square)\n\nOperations mimic those for matrix objects in R\n\nGeometry is implicit; the spatial extent and number of rows and columns define the cell size"
  },
  {
    "objectID": "slides/10-slides.html#types-of-raster-data",
    "href": "slides/10-slides.html#types-of-raster-data",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Types of Raster Data",
    "text": "Types of Raster Data\n\n\n\n\n\n\n\n\n\n\nRegular: constant cell size; axes aligned with Easting and Northing\nRotated: constant cell size; axes not aligned with Easting and Northing\nSheared: constant cell size; axes not parallel\nRectilinear: cell size varies along a dimension\nCurvilinear: cell size and orientation dependent on the other dimension"
  },
  {
    "objectID": "slides/10-slides.html#types-of-raster-data-1",
    "href": "slides/10-slides.html#types-of-raster-data-1",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Types of Raster Data",
    "text": "Types of Raster Data\n\nContinuous: numeric data representing a measurement (e.g., elevation, precipitation)\nCategorical: integer data representing factors (e.g., land use, land cover)"
  },
  {
    "objectID": "slides/10-slides.html#continuous-rasters",
    "href": "slides/10-slides.html#continuous-rasters",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Continuous Rasters",
    "text": "Continuous Rasters\n\n\n\nmintemp <- rast(\"ftp://ftp.hafro.is/pub/data/rasters/Iceland_minbtemp.tif\")\nmintemp\n\nclass       : SpatRaster \ndimensions  : 340, 375, 1  (nrow, ncol, nlyr)\nresolution  : 2000, 2000  (x, y)\nextent      : -1050226, -300225.9, -699984.3, -19984.32  (xmin, xmax, ymin, ymax)\ncoord. ref. : +proj=laea +lat_0=69 +lon_0=-4 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs \nsource      : Iceland_minbtemp.tif \nname        : Iceland_minbtemp \nmin value   :       -0.9982879 \nmax value   :        8.6031137"
  },
  {
    "objectID": "slides/10-slides.html#categorical-rasters",
    "href": "slides/10-slides.html#categorical-rasters",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Categorical Rasters",
    "text": "Categorical Rasters\n\n\n\n\nRequires a classification matrix and coercion to factor\nlevels allows you to define the categories\n\n\n\n# Create classification matrix\ncm <- matrix(c(\n  -2, 2, 0,\n  2, 4, 1,\n  4, 10, 2), ncol = 3, byrow = TRUE)\n\n# Create a raster with integers\ntemp_reclass <- classify(mintemp, cm)\ntempcats <- c(\"cold\", \"mild\", \"warm\")\nlevels(temp_reclass) <- tempcats\ncats(temp_reclass)\n\n[[1]]\n  value category\n1     0     cold\n2     1     mild\n3     2     warm"
  },
  {
    "objectID": "slides/10-slides.html#adding-dimensions",
    "href": "slides/10-slides.html#adding-dimensions",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Adding Dimensions",
    "text": "Adding Dimensions\n\nWhen data are aligned in space and/or time, more efficient to process as ‘cubes’ or ‘stacks’\nBands of satellite imagery, multiple predictors, spatio-temporal data"
  },
  {
    "objectID": "slides/10-slides.html#a-note-about-support",
    "href": "slides/10-slides.html#a-note-about-support",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "A note about support",
    "text": "A note about support\n\n\nWe talked briefly about the agr option in the st_sf() function\nagr refers to the attribute-geometry-relationship which can be:\n\nconstant = applies to every point in the geometry (lines and polygons are just lots of points)\nidentity = a value unique to a geometry\naggregate = a single value that integrates data across the geometry\n\nSupport is the area to which an attribute applies.\nRasters can have point (attribute refers to the cell center) or cell (attribute refers to an area similar to the pixel) support"
  },
  {
    "objectID": "slides/10-slides.html#rasters-in-r-1",
    "href": "slides/10-slides.html#rasters-in-r-1",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Rasters in R",
    "text": "Rasters in R\n\n\nraster - the original workhorse package; built on sp, rgdal, and rgeos\n\nRasterLayer, RasterStack, and RasterBrick classes\n\nterra - relatively new; developed by the raster folks, but designed to be much faster\n\nSpatRaster and SpatVector classes\n\nstars - developed by sf package developers; tidyverse compatible; designed for spatio-temporal data\n\nstars class\nCrosswalk between raster and stars is available here\nOnly way to deal with rectilinear and curvilinear data"
  },
  {
    "objectID": "slides/10-slides.html#rasters-with-terra",
    "href": "slides/10-slides.html#rasters-with-terra",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Rasters with terra",
    "text": "Rasters with terra\n\nsyntax is different for terra compared to sf\nRepresentation in Environment is also different\nCan break pipes, Be Explicit"
  },
  {
    "objectID": "slides/10-slides.html#rasters-by-construction",
    "href": "slides/10-slides.html#rasters-by-construction",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Rasters by Construction",
    "text": "Rasters by Construction\n\n\n\nmtx <- matrix(1:16, nrow=4)\nmtx\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nrstr <- terra::rast(mtx)\nrstr\n\nclass       : SpatRaster \ndimensions  : 4, 4, 1  (nrow, ncol, nlyr)\nresolution  : 1, 1  (x, y)\nextent      : 0, 4, 0, 4  (xmin, xmax, ymin, ymax)\ncoord. ref. :  \nsource      : memory \nname        : lyr.1 \nmin value   :     1 \nmax value   :    16 \n\n\n\n\n\n\n\n\n\n\n\nNote: you must have raster or terra loaded for plot() to work on Rast* objects; otherwise you get Error in as.double(y) : cannot coerce type 'S4' to vector of type 'double'"
  },
  {
    "objectID": "slides/10-slides.html#rasters-by-construction-origin",
    "href": "slides/10-slides.html#rasters-by-construction-origin",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Rasters by Construction: Origin",
    "text": "Rasters by Construction: Origin\n\nOrigin defines the location of the intersection of the x and y axes\n\n\n\n\nr <- rast(xmin=-4, xmax = 9.5, ncols=10)\nr[] <- runif(ncell(r))\norigin(r)\n\n[1] 0.05 0.00\n\nr2 <- r\norigin(r2) <- c(2,2)"
  },
  {
    "objectID": "slides/10-slides.html#rasters-by-construction-resolution",
    "href": "slides/10-slides.html#rasters-by-construction-resolution",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Rasters by Construction: Resolution",
    "text": "Rasters by Construction: Resolution\n\n\nGeometry is implicit; the spatial extent and number of rows and columns define the cell size\nResolution (res) defines the length and width of an individual pixel\n\n\n\n\n\nr <- rast(xmin=-4, xmax = 9.5, \n          ncols=10)\nres(r)\n\n[1] 1.35 1.00\n\nr2 <- rast(xmin=-4, xmax = 5, \n           ncols=10)\nres(r2)\n\n[1] 0.9 1.0\n\n\n\n\nr <- rast(xmin=-4, xmax = 9.5, \n          res=c(0.5,0.5))\nncol(r)\n\n[1] 27\n\nr2 <- rast(xmin=-4, xmax = 9.5, \n           res=c(5,5))\nncol(r2)\n\n[1] 3"
  },
  {
    "objectID": "slides/10-slides.html#rasters-from-files",
    "href": "slides/10-slides.html#rasters-from-files",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Rasters from Files",
    "text": "Rasters from Files\n\nBuilding rasters useful for templates\nMore common to read from files\n\n\nr <- rast(system.file(\"ex/elev.tif\", package=\"terra\"))\nr\n\nclass       : SpatRaster \ndimensions  : 90, 95, 1  (nrow, ncol, nlyr)\nresolution  : 0.008333333, 0.008333333  (x, y)\nextent      : 5.741667, 6.533333, 49.44167, 50.19167  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : elev.tif \nname        : elevation \nmin value   :       141 \nmax value   :       547"
  },
  {
    "objectID": "slides/10-slides.html#accessing-raster-attributes-coordinate-reference-system",
    "href": "slides/10-slides.html#accessing-raster-attributes-coordinate-reference-system",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Accessing Raster Attributes: Coordinate Reference System",
    "text": "Accessing Raster Attributes: Coordinate Reference System\n\nterra stores CRS in WKT format\nCan set and access using EPSG and proj (deprecated)\nPay attention to case\n\n\nr <- rast(system.file(\"ex/elev.tif\", package=\"terra\"))\ncrs(r)\n\n[1] \"GEOGCRS[\\\"WGS 84\\\",\\n    DATUM[\\\"World Geodetic System 1984\\\",\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    ID[\\\"EPSG\\\",4326]]\""
  },
  {
    "objectID": "slides/10-slides.html#accessing-raster-attributes-coordinate-reference-system-1",
    "href": "slides/10-slides.html#accessing-raster-attributes-coordinate-reference-system-1",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Accessing Raster Attributes: Coordinate Reference System",
    "text": "Accessing Raster Attributes: Coordinate Reference System\n\nr <- rast(system.file(\"ex/elev.tif\", package=\"terra\"))\ncrs(r, describe=TRUE)\n\n    name authority code area         extent\n1 WGS 84      EPSG 4326 <NA> NA, NA, NA, NA\n\ncrs(r, proj=TRUE)\n\n[1] \"+proj=longlat +datum=WGS84 +no_defs\"\n\ncrs(r, parse=TRUE)\n\n [1] \"GEOGCRS[\\\"WGS 84\\\",\"                                   \n [2] \"    DATUM[\\\"World Geodetic System 1984\\\",\"             \n [3] \"        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\"   \n [4] \"            LENGTHUNIT[\\\"metre\\\",1]]],\"                \n [5] \"    PRIMEM[\\\"Greenwich\\\",0,\"                           \n [6] \"        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\"    \n [7] \"    CS[ellipsoidal,2],\"                                \n [8] \"        AXIS[\\\"geodetic latitude (Lat)\\\",north,\"       \n [9] \"            ORDER[1],\"                                 \n[10] \"            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\"\n[11] \"        AXIS[\\\"geodetic longitude (Lon)\\\",east,\"       \n[12] \"            ORDER[2],\"                                 \n[13] \"            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\"\n[14] \"    ID[\\\"EPSG\\\",4326]]\""
  },
  {
    "objectID": "slides/10-slides.html#accessing-raster-attributes-bounding-box",
    "href": "slides/10-slides.html#accessing-raster-attributes-bounding-box",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Accessing Raster Attributes: Bounding box",
    "text": "Accessing Raster Attributes: Bounding box\n\n\nterra uses ext() to get or set the extent/bounding box\nFills cells with NA\n\n\n\n\n\next(r)\n\nSpatExtent : 5.74166666666667, 6.53333333333333, 49.4416666666667, 50.1916666666667 (xmin, xmax, ymin, ymax)\n\nr2 <- r\next(r2) <- c(5, 7, 48, 52)\next(r2)\n\nSpatExtent : 5, 7, 48, 52 (xmin, xmax, ymin, ymax)"
  },
  {
    "objectID": "slides/10-slides.html#converting-vectors-to-rasters",
    "href": "slides/10-slides.html#converting-vectors-to-rasters",
    "title": "Spatial Data as Matrices and Rasters",
    "section": "Converting vectors to rasters",
    "text": "Converting vectors to rasters\n\nSometimes necessary to convert between data models\nraster::rasterize, terra::rasterize, stars::st_rasterize, and fasterize::fasterize all will convert polygons to raster data\nstars::st_polygonize will work in the opposite direction\nterra::vect will read in vectors as SpatVectors or coerce sf to SpatVector"
  },
  {
    "objectID": "slides/11-slides.html#objectives",
    "href": "slides/11-slides.html#objectives",
    "title": "Operations With Raster Data I",
    "section": "Objectives",
    "text": "Objectives\n\nBy the end of today, you should be able to:\n\nEvaluate logical conditions with raster data\nCalculate different measures of raster data\nAlign rasters for spatial processing"
  },
  {
    "objectID": "slides/11-slides.html#revisitng-the-raster-data-model",
    "href": "slides/11-slides.html#revisitng-the-raster-data-model",
    "title": "Operations With Raster Data I",
    "section": "Revisitng the Raster Data Model",
    "text": "Revisitng the Raster Data Model\n\n\n\n\nRaster data represent spatially continuous phenomena (NA is possible)\nDepict the alignment of data on a regular lattice (often a square)\n\nOperations mimic those for matrix objects in R\n\nGeometry is implicit; the spatial extent and number of rows and columns define the cell size"
  },
  {
    "objectID": "slides/11-slides.html#extending-predicates",
    "href": "slides/11-slides.html#extending-predicates",
    "title": "Operations With Raster Data I",
    "section": "Extending predicates",
    "text": "Extending predicates\n\nPredicates: evaluate a logical statement asserting that a property is TRUE\nterra does not follow the same hierarchy as sf so a little trickier"
  },
  {
    "objectID": "slides/11-slides.html#unary-predicates-in-terra",
    "href": "slides/11-slides.html#unary-predicates-in-terra",
    "title": "Operations With Raster Data I",
    "section": "Unary predicates in terra",
    "text": "Unary predicates in terra\n\nCan tell us qualities of a raster dataset\nMany similar operations for SpatVector class (note use of .)\n\n\n\n\n\n\n\n\n\npredicate\nasks…\n\n\n\n\nis.lonlat\nDoes the object have a longitude/latitude CRS?\n\n\ninMemory\nis the object stored in memory?\n\n\nis.factor\nAre there categorical layers?\n\n\nhasValues\nDo the cells have values?"
  },
  {
    "objectID": "slides/11-slides.html#unary-predicates-in-terra-1",
    "href": "slides/11-slides.html#unary-predicates-in-terra-1",
    "title": "Operations With Raster Data I",
    "section": "Unary predicates in terra",
    "text": "Unary predicates in terra\n\n\n\n\nglobal: tests if the raster covers all longitudes (from -180 to 180 degrees) such that the extreme columns are in fact adjacent\n\n\nr <- rast()\nis.lonlat(r)\n\n[1] TRUE\n\nis.lonlat(r, global=TRUE)\n\n[1] TRUE\n\n\n\n\n\n\nperhaps: If TRUE and the crs is unknown, the method returns TRUE if the coordinates are plausible for longitude/latitude\n\n\ncrs(r) <- \"\"\nis.lonlat(r)\n\n[1] NA\n\nis.lonlat(r, perhaps=TRUE, warn=FALSE)\n\n[1] TRUE\n\n\n\ncrs(r) <- \"+proj=lcc +lat_1=48 +lat_2=33 +lon_0=-100 +ellps=WGS84\"\nis.lonlat(r)\n\n[1] FALSE"
  },
  {
    "objectID": "slides/11-slides.html#binary-predicates-in-terra",
    "href": "slides/11-slides.html#binary-predicates-in-terra",
    "title": "Operations With Raster Data I",
    "section": "Binary predicates in terra",
    "text": "Binary predicates in terra\n\nTake exactly 2 inputs, return 1 matrix of cell locs where value is TRUE\nadjacent: identifies cells adajcent to a set of raster cells"
  },
  {
    "objectID": "slides/11-slides.html#unary-measures-in-terra",
    "href": "slides/11-slides.html#unary-measures-in-terra",
    "title": "Operations With Raster Data I",
    "section": "Unary measures in terra",
    "text": "Unary measures in terra\n\nSlightly more flexible than sf\nOne result for each layer in a stack\n\n\n\n\n\n\n\n\n\nmeasure\nreturns\n\n\n\n\ncellSize\narea of individual cells\n\n\nexpanse\nsummed area of all cells\n\n\nvalues\nreturns all cell values\n\n\nncol\nnumber of columns\n\n\nnrow\nnumber of rows\n\n\nncell\nnumber of cells\n\n\nres\nresolution\n\n\next\nminimum and maximum of x and y coords\n\n\norigin\nthe orgin of a SpatRaster\n\n\ncrs\nthe coordinate reference system\n\n\ncats\ncategories of a categorical raster"
  },
  {
    "objectID": "slides/11-slides.html#binary-measures-in-terra",
    "href": "slides/11-slides.html#binary-measures-in-terra",
    "title": "Operations With Raster Data I",
    "section": "Binary measures in terra",
    "text": "Binary measures in terra\n\nReturns a matrix or SpatRaster describing the measure\n\n\n\n\n\n\n\n\n\nmeasure\nreturns\n\n\n\n\ndistance\nshortest distance to non-NA or vector object\n\n\ngridDistance\nshortest distance through adjacent grid cells\n\n\ncostDistance\nShortest distance considering cell-varying friction\n\n\ndirection\nazimuth to cells that are not NA"
  },
  {
    "objectID": "slides/11-slides.html#projecting-raster-data",
    "href": "slides/11-slides.html#projecting-raster-data",
    "title": "Operations With Raster Data I",
    "section": "Projecting raster data",
    "text": "Projecting raster data\n\n\n\n\nTransformation from lat/long to planar CRS involves some loss of precision\nNew cell values estimated using overlap with original cells\nInterpolation for continuous data, nearest neighbor for categorical data\nEqual-area projections are preferred; especially for large areas\n\n\n\n\n\nr <- rast(xmin=-110, xmax=-90, ymin=40, ymax=60, ncols=40, nrows=40)\nvalues(r) <- 1:ncell(r)\nplot(r)"
  },
  {
    "objectID": "slides/11-slides.html#projecting-raster-data-1",
    "href": "slides/11-slides.html#projecting-raster-data-1",
    "title": "Operations With Raster Data I",
    "section": "Projecting raster data",
    "text": "Projecting raster data\n\n\n\nsimple method; alignment not guaranteed\n\n\nnewcrs <- \"+proj=robin +datum=WGS84\"\npr1 <- terra::project(r, newcrs)\nplot(pr1)\n\n\n\n\n\n\nproviding a template to ensure alignment"
  },
  {
    "objectID": "slides/11-slides.html#changing-resolutions",
    "href": "slides/11-slides.html#changing-resolutions",
    "title": "Operations With Raster Data I",
    "section": "Changing resolutions",
    "text": "Changing resolutions\n\naggregate, disaggregate, resample allow changes in cell size\naggregate requires a function (e.g., mean() or min()) to determine what to do with the grouped values\nresample allows changes in cell size and shifting of cell centers (slower)"
  },
  {
    "objectID": "slides/11-slides.html#changing-resolutions-aggregate",
    "href": "slides/11-slides.html#changing-resolutions-aggregate",
    "title": "Operations With Raster Data I",
    "section": "Changing resolutions: aggregate",
    "text": "Changing resolutions: aggregate\n\n\n\nr <- rast()\nvalues(r) <- 1:ncell(r)\nplot(r)\n\n\n\n\n]\n\n\nra <- aggregate(r, 20)\nplot(ra)"
  },
  {
    "objectID": "slides/11-slides.html#changing-resolutions-disagg",
    "href": "slides/11-slides.html#changing-resolutions-disagg",
    "title": "Operations With Raster Data I",
    "section": "Changing resolutions: disagg",
    "text": "Changing resolutions: disagg\n\n\n\nra <- aggregate(r, 20)\nplot(ra)\n\n\n\n\n\n\nrd <- disagg(r, 20)\nplot(rd)"
  },
  {
    "objectID": "slides/11-slides.html#changing-resolutions-resample",
    "href": "slides/11-slides.html#changing-resolutions-resample",
    "title": "Operations With Raster Data I",
    "section": "Changing Resolutions: resample",
    "text": "Changing Resolutions: resample\n\nr <- rast(nrow=3, ncol=3, xmin=0, xmax=10, ymin=0, ymax=10)\nvalues(r) <- 1:ncell(r)\ns <- rast(nrow=25, ncol=30, xmin=1, xmax=11, ymin=-1, ymax=11)\nx <- resample(r, s, method=\"bilinear\")"
  },
  {
    "objectID": "slides/11-slides.html#on-weds",
    "href": "slides/11-slides.html#on-weds",
    "title": "Operations With Raster Data I",
    "section": "On Weds",
    "text": "On Weds\n\nTransformations of data and coverage\nRaster math\nCell-based functions"
  },
  {
    "objectID": "slides/12-slides.html#objectives",
    "href": "slides/12-slides.html#objectives",
    "title": "Operations With Raster Data II",
    "section": "Objectives",
    "text": "Objectives\n\nBy the end of today, you should be able to:\n\nAccess and manipulate cell values\nGenerate new rasters using mathematical functions\nSummarize rasters using global functions\nGenerate new rasters describing the spatial context of individual cells"
  },
  {
    "objectID": "slides/12-slides.html#revisiting-projections",
    "href": "slides/12-slides.html#revisiting-projections",
    "title": "Operations With Raster Data II",
    "section": "Revisiting Projections",
    "text": "Revisiting Projections\n\nproject changes the entire coordinate reference system\n\n\n\n\n\nlibrary(terra)\na <- rast(ncols=40, nrows=40, xmin=-110, xmax=-90, ymin=40, ymax=60, \n          crs=\"+proj=longlat +datum=WGS84\")\nvalues(a) <- 1:ncell(a)\nnewcrs=\"+proj=lcc +lat_1=48 +lat_2=33 +lon_0=-100 +datum=WGS84\"\nb <- rast(ncols=94, nrows=124, xmin=-944881, xmax=935118, ymin=4664377, ymax=7144377, crs=newcrs)\nw <- project(a, b)\n\n\n\n\n\n\n\n\n\norigin(a)\n\n[1] 0 0\n\norigin(w)\n\n[1] -4881.5  4377.0\n\next(a)\n\nSpatExtent : -110, -90, 40, 60 (xmin, xmax, ymin, ymax)\n\next(w)\n\nSpatExtent : -944881, 935118, 4664377, 7144377 (xmin, xmax, ymin, ymax)\n\nres(a)\n\n[1] 0.5 0.5\n\nres(w)\n\n[1] 19999.99 20000.00"
  },
  {
    "objectID": "slides/12-slides.html#revisiting-projections-1",
    "href": "slides/12-slides.html#revisiting-projections-1",
    "title": "Operations With Raster Data II",
    "section": "Revisiting Projections",
    "text": "Revisiting Projections\n\n\nresample transfers values between SpatRaster objects that do not align\nMust have same crs\n\n\n\n\n\n\na <- rast(ncols=40, nrows=40, xmin=-110, xmax=-90, ymin=40, ymax=60, \n          crs=\"+proj=longlat +datum=WGS84\")\nvalues(a) <- 1:ncell(a)\n\nb <- rast(ncols=94, nrows=124, xmin=-111, xmax=-80, ymin=45, ymax=65)\nw <- resample(a, b)\n\n\n\n\n\n\n\n\n\n\norigin(a)\n\n[1] 0 0\n\norigin(b)\n\n[1] 0.1382979 0.0000000\n\norigin(w)\n\n[1] 0.1382979 0.0000000\n\nres(a)\n\n[1] 0.5 0.5\n\nres(b)\n\n[1] 0.3297872 0.1612903\n\nres(w)\n\n[1] 0.3297872 0.1612903"
  },
  {
    "objectID": "slides/12-slides.html#revisiting-projections-2",
    "href": "slides/12-slides.html#revisiting-projections-2",
    "title": "Operations With Raster Data II",
    "section": "Revisiting Projections",
    "text": "Revisiting Projections\n\nif origin and extent are the same consider using aggregate, disagg, extend or crop"
  },
  {
    "objectID": "slides/12-slides.html#accessing-cell-values",
    "href": "slides/12-slides.html#accessing-cell-values",
    "title": "Operations With Raster Data II",
    "section": "Accessing Cell Values",
    "text": "Accessing Cell Values\n\nWe can extract or change cell values using []\n\n\na <- rast(ncols=10, nrows=10, xmin=-110, xmax=-100, ymin=40, ymax=50, \n          crs=\"+proj=longlat +datum=WGS84\")\nvalues(a) <- 1\nb1 <- a\nb2 <- a\nb1[5,5] <- 10\nb2[1, 1:10 ] <- runif(10,4,10)"
  },
  {
    "objectID": "slides/12-slides.html#raster-math",
    "href": "slides/12-slides.html#raster-math",
    "title": "Operations With Raster Data II",
    "section": "Raster Math",
    "text": "Raster Math\n\nPerforms cell-wise calculations on 1 (or more) SpatRasters\nGenerally works the same as matrix operations\nAll layers must be aligned"
  },
  {
    "objectID": "slides/12-slides.html#raster-math-1",
    "href": "slides/12-slides.html#raster-math-1",
    "title": "Operations With Raster Data II",
    "section": "Raster Math",
    "text": "Raster Math\n\nr <- rast(ncol=5, nrow=5)\nvalues(r) <- 1:ncell(r)\nr2 <- r*2\nr3 <- t(r)\nr4 <- r + r2"
  },
  {
    "objectID": "slides/12-slides.html#cell-wise-operations-1",
    "href": "slides/12-slides.html#cell-wise-operations-1",
    "title": "Operations With Raster Data II",
    "section": "Cell-wise operations",
    "text": "Cell-wise operations\n\nterra has a special set of apply functions\napp, lapp, tapp\napp applies a function to the values of each cell\nlapp applies a function using the layer as the value\ntapp applies the function to a subset of layers"
  },
  {
    "objectID": "slides/12-slides.html#cell-wise-operations-2",
    "href": "slides/12-slides.html#cell-wise-operations-2",
    "title": "Operations With Raster Data II",
    "section": "Cell-wise operations",
    "text": "Cell-wise operations\n\nr <- rast(ncols=10, nrows=10)\nvalues(r) <- 1:ncell(r)\nf <- function(i) (i+1) * 2 * i + sqrt(i)\ns <- app(r, f)"
  },
  {
    "objectID": "slides/12-slides.html#cell-wise-operations-3",
    "href": "slides/12-slides.html#cell-wise-operations-3",
    "title": "Operations With Raster Data II",
    "section": "Cell-wise Operations",
    "text": "Cell-wise Operations\n\ns <- rast(system.file(\"ex/logo.tif\", package=\"terra\")) + 1  \nss <- s[[2:1]]\n\nfvi <- function(x, y){ (x - y ) / (x + y) } \nx <- lapp(ss, fun=fvi)"
  },
  {
    "objectID": "slides/12-slides.html#global-methods",
    "href": "slides/12-slides.html#global-methods",
    "title": "Operations With Raster Data II",
    "section": "Global Methods",
    "text": "Global Methods\n\nProvide summaries of 1 or more layers\nUse zonal to extract values from one layer based on categorical layer\n\n\n\n\nr <- rast(ncols=10, nrows=10)\nvalues(r) <- 1:ncell(r)\nz <- rast(r)\nvalues(z) <- rep(c(1:2, NA, 3:4), each=20)\nnames(z) <- \"zone\"\na <-  zonal(r, z, \"sum\", na.rm=TRUE)\nb <- zonal(r, z, \"sum\", na.rm=TRUE, as.raster=TRUE)\nplot(b)"
  },
  {
    "objectID": "slides/12-slides.html#context-specific-functions",
    "href": "slides/12-slides.html#context-specific-functions",
    "title": "Operations With Raster Data II",
    "section": "Context-specific Functions",
    "text": "Context-specific Functions\n\ndistance and relatives are based on relationships between cells\nfocal provides moving windows for smoothing data\nterrain allows calculation of slope, ruggedness, aspect using elevation rasters\nshade calculates hillshade based on terrain"
  },
  {
    "objectID": "slides/12-slides.html#using-focal",
    "href": "slides/12-slides.html#using-focal",
    "title": "Operations With Raster Data II",
    "section": "Using focal",
    "text": "Using focal\n\nfocal requires a window (w) or weights matrix\nna.policy determines how to deal with NAs in the smoother\nfillvalue and expand tell terra what to do at the edges\n\n\nr <- rast(ncols=10, nrows=10, ext(0, 10, 0, 10))\nvalues(r) <- 1:ncell(r)\n\nf <- focal(r, w=3, fun=function(x, ...) quantile(x, c(.25, .5, .75), ...), na.rm=TRUE) \nplot(f)"
  },
  {
    "objectID": "slides/12-slides.html#using-focal-1",
    "href": "slides/12-slides.html#using-focal-1",
    "title": "Operations With Raster Data II",
    "section": "Using focal",
    "text": "Using focal"
  },
  {
    "objectID": "slides/13-slides.html#objectives",
    "href": "slides/13-slides.html#objectives",
    "title": "Combining Raster and Vector Data",
    "section": "Objectives",
    "text": "Objectives\n\nBy the end of today, you should be able to:\n\nClip, crop, or extend vector and raster data so that extents align\nConvert between raster and vector datasets\nGenerate new rasters describing the spatial arrangement of vector data\nExtract raster values as attributes of vector data"
  },
  {
    "objectID": "slides/13-slides.html#dealing-with-different-extents",
    "href": "slides/13-slides.html#dealing-with-different-extents",
    "title": "Combining Raster and Vector Data",
    "section": "Dealing with Different Extents",
    "text": "Dealing with Different Extents\n\n\n\nRaster extents often larger than our analysis\nReducing memory and computational resources\nMaking attractive maps"
  },
  {
    "objectID": "slides/13-slides.html#using-terracrop",
    "href": "slides/13-slides.html#using-terracrop",
    "title": "Combining Raster and Vector Data",
    "section": "Using terra::crop()",
    "text": "Using terra::crop()\n\n\n\n\n\n\n\n\n\n\nCoordinate Reference System must be the same for both objects\nCrop is based on the (converted) SpatExtent of the 2nd object\nsnap describes how y will be aligned to the raster\nReturns all data within the extent"
  },
  {
    "objectID": "slides/13-slides.html#using-terracrop-1",
    "href": "slides/13-slides.html#using-terracrop-1",
    "title": "Combining Raster and Vector Data",
    "section": "Using terra::crop()",
    "text": "Using terra::crop()\n\n\n\n\nlibrary(sf)\nlibrary(terra)\nlibrary(spDataLarge)\nsrtm = rast(system.file(\"raster/srtm.tif\", package = \"spDataLarge\"))\nzion = read_sf(system.file(\"vector/zion.gpkg\", package = \"spDataLarge\"))\nzion = st_transform(zion, crs(srtm))\n\ncrs(srtm) == crs(zion)\n\n[1] TRUE\n\nsrtm.crop <- crop(x=srtm, y=zion, snap=\"near\")"
  },
  {
    "objectID": "slides/13-slides.html#using-mask",
    "href": "slides/13-slides.html#using-mask",
    "title": "Combining Raster and Vector Data",
    "section": "Using mask()",
    "text": "Using mask()\n\n\nOften want to get rid of all values outside of vector\nCan set mask=TRUE in crop() (y must be SpatVector)\nOr use mask()\n\n\n\n\n\nsrtm.crop.msk <- crop(x=srtm, y=vect(zion), snap=\"near\", mask=TRUE)\nplot(srtm.crop.msk)\n\n\n\n\n\n\nsrtm.msk <- mask(srtm.crop, vect(zion))\nplot(srtm.msk)"
  },
  {
    "objectID": "slides/13-slides.html#using-mask-1",
    "href": "slides/13-slides.html#using-mask-1",
    "title": "Combining Raster and Vector Data",
    "section": "Using mask()",
    "text": "Using mask()\n\n\nAllows more control over what the mask does\nCan set maskvalues and updatevalues to change the resulting raster\nCan also use inverse to mask out the vector\n\n\n\n\n\nsrtm.msk <- mask(srtm.crop, vect(zion), updatevalue=-1000)\nplot(srtm.msk)\n\n\n\n\n\n\nsrtm.msk <- mask(srtm.crop, vect(zion), inverse=TRUE, updatevalue=0)\nplot(srtm.msk)"
  },
  {
    "objectID": "slides/13-slides.html#extending-boundaries",
    "href": "slides/13-slides.html#extending-boundaries",
    "title": "Combining Raster and Vector Data",
    "section": "Extending boundaries",
    "text": "Extending boundaries\n\n\nVector slightly larger than raster\nEspecially when using buffered datasets\nCan use extend\nNot exact; depends on snap()\n\n\n\n\n\nzion.buff <-  zion %>% \n  st_buffer(., 10000)\nsrtm.ext <- extend(srtm, vect(zion.buff))\next(srtm.ext)\n\nSpatExtent : -113.343749879444, -112.74791654615, 37.0479167631968, 37.5979167631601 (xmin, xmax, ymin, ymax)\n\next(vect(zion.buff))\n\nSpatExtent : -113.343652923976, -112.747986193365, 37.0477357596604, 37.5977812137969 (xmin, xmax, ymin, ymax)"
  },
  {
    "objectID": "slides/13-slides.html#converting-between-formats-1",
    "href": "slides/13-slides.html#converting-between-formats-1",
    "title": "Combining Raster and Vector Data",
    "section": "Converting Between Formats",
    "text": "Converting Between Formats\n\nUsing coercion (as, rast, vect) can change class, but not data model\nSometimes we need to actually change the data model"
  },
  {
    "objectID": "slides/13-slides.html#converting-vectors-to-rasters-using-rasterize",
    "href": "slides/13-slides.html#converting-vectors-to-rasters-using-rasterize",
    "title": "Combining Raster and Vector Data",
    "section": "Converting Vectors to Rasters Using rasterize",
    "text": "Converting Vectors to Rasters Using rasterize\n\nA special kind of data aggregation\nx is your SpatVector object\ny is a template raster with the appropriate CRS, resolution, and extent\nfun allows you to specify the value of the resulting raster"
  },
  {
    "objectID": "slides/13-slides.html#using-rasterize",
    "href": "slides/13-slides.html#using-rasterize",
    "title": "Combining Raster and Vector Data",
    "section": "Using rasterize",
    "text": "Using rasterize\n\n\nPresence/Absence\nfield specifies which value should be returned to non-empty cells\n\n\n\n\n\n\ncycle_hire_osm = spData::cycle_hire_osm\ncycle_hire_osm_projected = st_transform(cycle_hire_osm, \"EPSG:27700\")\nraster_template = rast(ext(cycle_hire_osm_projected), resolution = 1000,\n                       crs = st_crs(cycle_hire_osm_projected)$wkt)\nch_raster1 = rasterize(cycle_hire_osm_projected, raster_template,\n                       field = 1)"
  },
  {
    "objectID": "slides/13-slides.html#using-rasterize-1",
    "href": "slides/13-slides.html#using-rasterize-1",
    "title": "Combining Raster and Vector Data",
    "section": "Using rasterize",
    "text": "Using rasterize\n\n\nThe fun argument specifies how we aggregate the data\nUseful for counting occurrences (using length)\n\n\n\n\n\n\nch_raster2 = rasterize(cycle_hire_osm_projected, raster_template, \n                       fun = \"length\")"
  },
  {
    "objectID": "slides/13-slides.html#using-rasterize-2",
    "href": "slides/13-slides.html#using-rasterize-2",
    "title": "Combining Raster and Vector Data",
    "section": "Using rasterize",
    "text": "Using rasterize\n\n\nThe fun argument specifies how we aggregate the data\nCan use a variety of functions\n\n\n\n\n\n\nch_raster3 = rasterize(cycle_hire_osm_projected, raster_template, \n                       field = \"capacity\", fun = sum)"
  },
  {
    "objectID": "slides/13-slides.html#lines-and-polygons",
    "href": "slides/13-slides.html#lines-and-polygons",
    "title": "Combining Raster and Vector Data",
    "section": "Lines and Polygons",
    "text": "Lines and Polygons\n\nCan use rasterize or stars::st_rasterize\nResult depends on the touches argument"
  },
  {
    "objectID": "slides/13-slides.html#converting-rasters-to-vectors",
    "href": "slides/13-slides.html#converting-rasters-to-vectors",
    "title": "Combining Raster and Vector Data",
    "section": "Converting rasters to vectors",
    "text": "Converting rasters to vectors\n\nLess common, but can convert to vector data\nas.points, as.countour, and polygonize\n\n\n\n\n\ndem = rast(system.file(\"raster/dem.tif\", package = \"spDataLarge\"))\ncl = as.contour(dem)"
  },
  {
    "objectID": "slides/13-slides.html#generating-new-data-1",
    "href": "slides/13-slides.html#generating-new-data-1",
    "title": "Combining Raster and Vector Data",
    "section": "Generating New Data",
    "text": "Generating New Data\n\nSometimes we want a raster describing the spatial context of vector data\ndistance is a simple method\nWe’ll use interpolation in the next few weeks"
  },
  {
    "objectID": "slides/13-slides.html#generating-distance-rasters",
    "href": "slides/13-slides.html#generating-distance-rasters",
    "title": "Combining Raster and Vector Data",
    "section": "Generating Distance Rasters",
    "text": "Generating Distance Rasters\n\nreturns a distance matrix or SpatRaster\n\n\ncycle_hire_osm = spData::cycle_hire_osm\ncycle_hire_osm_projected = st_transform(cycle_hire_osm, \"EPSG:27700\")\n\ncycle_dist <- distance(vect(cycle_hire_osm_projected))\nhead(as.matrix(cycle_dist))[1:5, 1:5]\n\n          1         2        3         4         5\n1    0.0000 2550.9619 1736.118  407.1558 1922.3728\n2 2550.9619    0.0000 1072.401 2820.4804  725.2172\n3 1736.1178 1072.4011    0.000 1908.1413  360.7490\n4  407.1558 2820.4804 1908.141    0.0000 2148.0087\n5 1922.3728  725.2172  360.749 2148.0087    0.0000"
  },
  {
    "objectID": "slides/13-slides.html#generating-distance-rasters-1",
    "href": "slides/13-slides.html#generating-distance-rasters-1",
    "title": "Combining Raster and Vector Data",
    "section": "Generating Distance Rasters",
    "text": "Generating Distance Rasters\n\nreturns a distance matrix or SpatRaster\n\n\nraster_template = rast(ext(cycle_hire_osm_projected), resolution = 100,\n                       crs = st_crs(cycle_hire_osm_projected)$wkt)\nch_raster1 = rasterize(cycle_hire_osm_projected, raster_template,\n                       field = 1)\n\nch_dist_rast <- distance(ch_raster1)\nplot(ch_dist_rast)"
  },
  {
    "objectID": "slides/13-slides.html#creating-vector-data-by-extraction",
    "href": "slides/13-slides.html#creating-vector-data-by-extraction",
    "title": "Combining Raster and Vector Data",
    "section": "Creating Vector Data by Extraction",
    "text": "Creating Vector Data by Extraction\n\nSometimes we want to use rasters to create new attributes\nfun controls how the cells are aggregated\n\n\ncycle_hire_osm = spData::cycle_hire_osm\ncycle_hire_osm_proj_buff <- st_transform(cycle_hire_osm, \"EPSG:27700\") %>% \n  st_buffer(., 5000) %>% \n  as(., \"SpatVector\")\n\ncycle_ext <- extract(ch_dist_rast, cycle_hire_osm_proj_buff)\nhead(cycle_ext)\n\n  ID    lyr.1\n1  1 1360.147\n2  1 1280.625\n3  1 1204.159\n4  1 1131.371\n5  1 1063.015\n6  1 1000.000"
  },
  {
    "objectID": "slides/14-slides.html#objectives",
    "href": "slides/14-slides.html#objectives",
    "title": "Building Spatial Databases with Attributes",
    "section": "Objectives",
    "text": "Objectives\n\nBy the end of today, you should be able to:\n\nDefine spatial analysis\nDescribe the steps in planning a spatial analysis\nUnderstand the structure of relational databases\nBegin building a database for spatial analysis"
  },
  {
    "objectID": "slides/14-slides.html#what-is-spatial-analysis-1",
    "href": "slides/14-slides.html#what-is-spatial-analysis-1",
    "title": "Building Spatial Databases with Attributes",
    "section": "What is spatial analysis?",
    "text": "What is spatial analysis?\n\n“The process of examining the locations, attributes, and relationships of features in spatial data through overlay and other analytical techniques in order to address a question or gain useful knowledge. Spatial analysis extracts or creates new information from spatial data”.\n\n— ESRI Dictionary"
  },
  {
    "objectID": "slides/14-slides.html#what-is-spatial-analysis-2",
    "href": "slides/14-slides.html#what-is-spatial-analysis-2",
    "title": "Building Spatial Databases with Attributes",
    "section": "What is spatial analysis?",
    "text": "What is spatial analysis?\n\n\n\nThe process of turning maps into information\nAny- or everything we do with GIS\nThe use of computational and statistical algorithms to understand the relations between things that co-occur in space.\n\n\n\n\n\nJohn Snow’s cholera outbreak map"
  },
  {
    "objectID": "slides/14-slides.html#common-goals-for-spatial-analysis",
    "href": "slides/14-slides.html#common-goals-for-spatial-analysis",
    "title": "Building Spatial Databases with Attributes",
    "section": "Common goals for spatial analysis",
    "text": "Common goals for spatial analysis\n\n\n\n\n\ncourtesy of NatureServe\n\n\n\n\nDescribe and visualize locations or events\nQuantify patterns\nCharacterize ‘suitability’\nDetermine (statistical) relations"
  },
  {
    "objectID": "slides/14-slides.html#common-pitfalls-of-spatial-analysis",
    "href": "slides/14-slides.html#common-pitfalls-of-spatial-analysis",
    "title": "Building Spatial Databases with Attributes",
    "section": "Common pitfalls of spatial analysis",
    "text": "Common pitfalls of spatial analysis\n\nLocational Fallacy: Error due to the spatial characterization chosen for elements of study\nAtomic Fallacy: Applying conclusions from individuals to entire spatial units\nEcological Fallacy: Applying conclusions from aggregated information to individuals\n\n\n\nSpatial analysis is an inherently complex endeavor and one that is advancing rapidly. So-called “best practices” for addressing many of these issues are still being developed and debated. This doesn’t mean you shouldn’t do spatial analysis, but you should keep these things in mind as you design, implement, and interpret your analyses"
  },
  {
    "objectID": "slides/14-slides.html#workflows-for-spatial-analysis-1",
    "href": "slides/14-slides.html#workflows-for-spatial-analysis-1",
    "title": "Building Spatial Databases with Attributes",
    "section": "Workflows for spatial analysis",
    "text": "Workflows for spatial analysis\n\n\n\nAcquisition (not really a focus, but see Resources)\nGeoprocessing\nAnalysis\nVisualization\n\n\n\n\n\ncourtesy of University of Illinois"
  },
  {
    "objectID": "slides/14-slides.html#geoprocessing",
    "href": "slides/14-slides.html#geoprocessing",
    "title": "Building Spatial Databases with Attributes",
    "section": "Geoprocessing",
    "text": "Geoprocessing\nManipulation of data for subsequent use\n\nAlignment\nData cleaning and transformation\nCombination of multiple datasets\nSelection and subsetting"
  },
  {
    "objectID": "slides/14-slides.html#databases-and-attributes-1",
    "href": "slides/14-slides.html#databases-and-attributes-1",
    "title": "Building Spatial Databases with Attributes",
    "section": "Databases and attributes",
    "text": "Databases and attributes\n\n\n\n\n\ncourtesy of Giscommons\n\n\n\n\n\nPrevious focus has been largely on location\nGeographic data often also includes non-spatial data\nAttributes: Non-spatial information that further describes a spatial feature\nTypically stored in tables where each row represents a spatial feature\n\nWide vs. long format"
  },
  {
    "objectID": "slides/14-slides.html#common-attribute-operations",
    "href": "slides/14-slides.html#common-attribute-operations",
    "title": "Building Spatial Databases with Attributes",
    "section": "Common attribute operations",
    "text": "Common attribute operations\n\nsf designed to work with tidyverse\nAllows use of dplyr data manipulation verbs\nCan use scales package for units\nAlso allows %>% to chain together multiple steps\ngeometries are “sticky”\nPay attention to masking!!"
  },
  {
    "objectID": "slides/14-slides.html#revisiting-the-tidyverse",
    "href": "slides/14-slides.html#revisiting-the-tidyverse",
    "title": "Building Spatial Databases with Attributes",
    "section": "Revisiting the tidyverse",
    "text": "Revisiting the tidyverse\n\nFields contain individual attributes\nSelecting fields\n\n\n\n\ncolnames(world)\n\n [1] \"iso_a2\"    \"name_long\" \"continent\" \"region_un\" \"subregion\" \"type\"     \n [7] \"area_km2\"  \"pop\"       \"lifeExp\"   \"gdpPercap\" \"geom\"     \n\nhead(world)[,1:3] %>% \n  st_drop_geometry()\n\n# A tibble: 6 × 3\n  iso_a2 name_long      continent    \n* <chr>  <chr>          <chr>        \n1 FJ     Fiji           Oceania      \n2 TZ     Tanzania       Africa       \n3 EH     Western Sahara Africa       \n4 CA     Canada         North America\n5 US     United States  North America\n6 KZ     Kazakhstan     Asia         \n\n\n\n\nworld %>%\n  dplyr::select(name_long, continent) %>%\n  st_drop_geometry() %>% \n  head(.) \n\n# A tibble: 6 × 2\n  name_long      continent    \n  <chr>          <chr>        \n1 Fiji           Oceania      \n2 Tanzania       Africa       \n3 Western Sahara Africa       \n4 Canada         North America\n5 United States  North America\n6 Kazakhstan     Asia"
  },
  {
    "objectID": "slides/14-slides.html#revisiting-the-tidyverse-1",
    "href": "slides/14-slides.html#revisiting-the-tidyverse-1",
    "title": "Building Spatial Databases with Attributes",
    "section": "Revisiting the tidyverse",
    "text": "Revisiting the tidyverse\n\nFeatures refer to the individual observations in the dataset\nSelecting features\n\n\n\n\nhead(world)[1:3, 1:3] %>% \n  st_drop_geometry()\n\n# A tibble: 3 × 3\n  iso_a2 name_long      continent\n* <chr>  <chr>          <chr>    \n1 FJ     Fiji           Oceania  \n2 TZ     Tanzania       Africa   \n3 EH     Western Sahara Africa   \n\n\n\n\nworld %>%\n  filter(continent == \"Asia\") %>% \n    dplyr::select(name_long, continent) %>%\n  st_drop_geometry() %>% \n  head(.)\n\n# A tibble: 6 × 2\n  name_long   continent\n  <chr>       <chr>    \n1 Kazakhstan  Asia     \n2 Uzbekistan  Asia     \n3 Indonesia   Asia     \n4 Timor-Leste Asia     \n5 Israel      Asia     \n6 Lebanon     Asia"
  },
  {
    "objectID": "slides/14-slides.html#revisiting-the-tidyverse-2",
    "href": "slides/14-slides.html#revisiting-the-tidyverse-2",
    "title": "Building Spatial Databases with Attributes",
    "section": "Revisiting the tidyverse",
    "text": "Revisiting the tidyverse\n\nCreating new fields\n\n\nworld %>%\n  filter(continent == \"Asia\") %>% \n    dplyr::select(name_long, continent, pop, gdpPercap ,area_km2) %>%\n  mutate(., dens = pop/area_km2,\n         totGDP = gdpPercap * pop) %>%\n  st_drop_geometry() %>% \n  head(.)\n\n# A tibble: 6 × 7\n  name_long   continent       pop gdpPercap area_km2   dens  totGDP\n  <chr>       <chr>         <dbl>     <dbl>    <dbl>  <dbl>   <dbl>\n1 Kazakhstan  Asia       17288285    23587. 2729811.   6.33 4.08e11\n2 Uzbekistan  Asia       30757700     5371.  461410.  66.7  1.65e11\n3 Indonesia   Asia      255131116    10003. 1819251. 140.   2.55e12\n4 Timor-Leste Asia        1212814     6263.   14715.  82.4  7.60e 9\n5 Israel      Asia        8215700    31702.   22991. 357.   2.60e11\n6 Lebanon     Asia        5603279    13831.   10099. 555.   7.75e10"
  },
  {
    "objectID": "slides/14-slides.html#revisiting-the-tidyverse-3",
    "href": "slides/14-slides.html#revisiting-the-tidyverse-3",
    "title": "Building Spatial Databases with Attributes",
    "section": "Revisiting the tidyverse",
    "text": "Revisiting the tidyverse\n\nCreating new fields"
  },
  {
    "objectID": "slides/14-slides.html#revisiting-the-tidyverse-4",
    "href": "slides/14-slides.html#revisiting-the-tidyverse-4",
    "title": "Building Spatial Databases with Attributes",
    "section": "Revisiting the tidyverse",
    "text": "Revisiting the tidyverse\n\nAggregating data\n\n\n\n\nworld %>%\n  st_drop_geometry(.) %>% \n  group_by(continent) %>%\n  summarize(pop = sum(pop, na.rm = TRUE))\n\n# A tibble: 8 × 2\n  continent                      pop\n  <chr>                        <dbl>\n1 Africa                  1154946633\n2 Antarctica                       0\n3 Asia                    4311408059\n4 Europe                   669036256\n5 North America            565028684\n6 Oceania                   37757833\n7 Seven seas (open ocean)          0\n8 South America            412060811"
  },
  {
    "objectID": "slides/14-slides.html#joining-aspatial-data-1",
    "href": "slides/14-slides.html#joining-aspatial-data-1",
    "title": "Building Spatial Databases with Attributes",
    "section": "Joining (a)spatial data",
    "text": "Joining (a)spatial data\n\n\n\nRequires a “key” field\nMultiple outcomes possible\nThink about your final data form"
  },
  {
    "objectID": "slides/14-slides.html#left-join",
    "href": "slides/14-slides.html#left-join",
    "title": "Building Spatial Databases with Attributes",
    "section": "Left Join",
    "text": "Left Join\n\nUseful for adding other attributes not in your spatial data\nReturns all of the records in x attributed with y\nPay attention to the number of rows!"
  },
  {
    "objectID": "slides/14-slides.html#left-join-1",
    "href": "slides/14-slides.html#left-join-1",
    "title": "Building Spatial Databases with Attributes",
    "section": "Left Join",
    "text": "Left Join"
  },
  {
    "objectID": "slides/14-slides.html#left-join-2",
    "href": "slides/14-slides.html#left-join-2",
    "title": "Building Spatial Databases with Attributes",
    "section": "Left Join",
    "text": "Left Join\n\n\n\nhead(coffee_data)\n\n# A tibble: 6 × 3\n  name_long                coffee_production_2016 coffee_production_2017\n  <chr>                                     <int>                  <int>\n1 Angola                                       NA                     NA\n2 Bolivia                                       3                      4\n3 Brazil                                     3277                   2786\n4 Burundi                                      37                     38\n5 Cameroon                                      8                      6\n6 Central African Republic                     NA                     NA\n\n\n\n\nworld_coffee = left_join(world, coffee_data)\nnrow(world_coffee)\n\n[1] 177"
  },
  {
    "objectID": "slides/14-slides.html#left-join-3",
    "href": "slides/14-slides.html#left-join-3",
    "title": "Building Spatial Databases with Attributes",
    "section": "Left Join",
    "text": "Left Join"
  },
  {
    "objectID": "slides/14-slides.html#inner-join",
    "href": "slides/14-slides.html#inner-join",
    "title": "Building Spatial Databases with Attributes",
    "section": "Inner Join",
    "text": "Inner Join\n\nUseful for subsetting to “complete” records\nReturns all of the records in x with matching y\nPay attention to the number of rows!"
  },
  {
    "objectID": "slides/14-slides.html#inner-join-1",
    "href": "slides/14-slides.html#inner-join-1",
    "title": "Building Spatial Databases with Attributes",
    "section": "Inner Join",
    "text": "Inner Join"
  },
  {
    "objectID": "slides/14-slides.html#inner-join-2",
    "href": "slides/14-slides.html#inner-join-2",
    "title": "Building Spatial Databases with Attributes",
    "section": "Inner Join",
    "text": "Inner Join\n\n\n\nworld_coffee_inner = inner_join(world, coffee_data)\nnrow(world_coffee_inner)\n\n[1] 45\n\n\n\n\nsetdiff(coffee_data$name_long, world$name_long)\n\n[1] \"Congo, Dem. Rep. of\" \"Others\""
  },
  {
    "objectID": "slides/14-slides.html#inner-join-3",
    "href": "slides/14-slides.html#inner-join-3",
    "title": "Building Spatial Databases with Attributes",
    "section": "Inner Join",
    "text": "Inner Join"
  },
  {
    "objectID": "slides/15-slides.html#update-on-assignments",
    "href": "slides/15-slides.html#update-on-assignments",
    "title": "Building Spatial Databases based on Location",
    "section": "Update on assignments",
    "text": "Update on assignments\n\nAssignment 2 due by 14 Oct\nSelf-assessment due 18 Oct\nResubmits\nFinal Project"
  },
  {
    "objectID": "slides/15-slides.html#objectives",
    "href": "slides/15-slides.html#objectives",
    "title": "Building Spatial Databases based on Location",
    "section": "Objectives",
    "text": "Objectives\nBy the end of today you should be able to:\n\nCreate new features based on topological relationships\nUse topological subsetting to reduce features\nUse spatial joins to add attributes based on location"
  },
  {
    "objectID": "slides/15-slides.html#what-is-spatial-analysis",
    "href": "slides/15-slides.html#what-is-spatial-analysis",
    "title": "Building Spatial Databases based on Location",
    "section": "What is spatial analysis?",
    "text": "What is spatial analysis?\n\n“The process of examining the locations, attributes, and relationships of features in spatial data through overlay and other analytical techniques in order to address a question or gain useful knowledge. Spatial analysis extracts or creates new information from spatial data”.\n\n— ESRI Dictionary"
  },
  {
    "objectID": "slides/15-slides.html#workflows-for-spatial-analysis",
    "href": "slides/15-slides.html#workflows-for-spatial-analysis",
    "title": "Building Spatial Databases based on Location",
    "section": "Workflows for spatial analysis",
    "text": "Workflows for spatial analysis\n\n\n\n\n\ncourtesy of Humboldt State University\n\n\n\n\nAlign processing with objectives\nImagining the visualizations and analysis clarifies file formats and variables\nHelps build reproducibility"
  },
  {
    "objectID": "slides/15-slides.html#databases-and-attributes",
    "href": "slides/15-slides.html#databases-and-attributes",
    "title": "Building Spatial Databases based on Location",
    "section": "Databases and Attributes",
    "text": "Databases and Attributes\n\n\n\n\n\ncourtesy of Giscommons\n\n\n\n\n\nAttributes: Information that further describes a spatial feature\nAttributes → predictors for analysis\nLast week focus on thematic relations between datasets\n\nShared ‘keys’ help define linkages between objects\n\nSometimes we are interested in attributes that describe location (overlaps, contains, distance)\nSometimes we want to join based on location rather than thematic connections\n\nMust have the same CRS"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Dr. Matt Williamson\n   4125 Environmental Research Building\n   mattwilliamson@boisestate.edu\n   MwilliamsonMatt\n   Schedule an appointment\n\n\n\n\n\n   Mondays and Wednesdays\n   August 22–December 16, 2022\n   1:30–2:45 PM\n   Mathematics 126\n   Slack"
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course Description",
    "text": "Course Description\nSpatial data are ubiquitous and form the basis for many of our inquiries into social, ecological, and evolutionary processes. As such, developing the skills necessary for incorporating spatial data into reproducible statistical workflows is critical. In this course, we will introduce the core components of manipulating spatial data within the R statistical environment including managing vector and raster data, projections, extraction of data values, interpolation, and plotting. Students will also learn to prototype and benchmark different workflows to aid in applying the appropriate tools to their research questions."
  },
  {
    "objectID": "syllabus.html#course-objectives",
    "href": "syllabus.html#course-objectives",
    "title": "Syllabus",
    "section": "Course Objectives",
    "text": "Course Objectives\nStudents completing this course should be able to:\n\nDevelop reproducible workflows for manipulating, visualizing, and analyzing spatial data.\nDesign statistical analyses that integrate geospatial and tabular data\n\nConstruct appropriate data visualizations for conveying geospatial data\nSelect the appropriate R packages and functions for manipulating different types of spatial data\nGenerate custom functions to automate repetitive processing tasks"
  },
  {
    "objectID": "syllabus.html#expectations",
    "href": "syllabus.html#expectations",
    "title": "Syllabus",
    "section": "Expectations",
    "text": "Expectations\nBe nice. Be honest. Try hard.\nThe beauty of working with open source software is the community of users working on problems just like yours (and nothing like yours). Like any community, this one functions best when its members are kind, genuine, and make good-faith efforts to solve their problems along the way (more on this below).\nYou can (and should) expect me to:\n\nCreate a space where you can ask questions without fear of embarrassment or retribution\nProvide feedback on your work within 1 week of submission\nRespond to email and slack messages within 48 hours\nMake every attempt to answer your questions (when I can) or point you toward resources that may help\n\nIn turn, I expect you to:\n\nTreat all of us with respect and compassion\nMake an honest effort to work through the assignments\nDemonstrate that you have tried to solve your coding errors before asking me\nCommunicate with me when the course isn’t working for you"
  },
  {
    "objectID": "syllabus.html#prerequisite-knowledge-and-skills",
    "href": "syllabus.html#prerequisite-knowledge-and-skills",
    "title": "Syllabus",
    "section": "Prerequisite Knowledge and Skills",
    "text": "Prerequisite Knowledge and Skills\nYou can succeed in this class.\nSome familiarity with the R statistical environment is helpful, but not necessary. My goal is to foster an environment where we are all learning from each other and sharing the tips and tricks that help us along the way. Learning R can be difficult at first—it’s like learning a new language, just like Spanish, French, or Chinese. I find it helpful to remember the following:\n\nIt’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later. Even experienced programmers find themselves bashing their heads against seemingly intractable errors. If you’re finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, e-mail me, etc.\n\n— Hadley Wickham\n\n\nIf you want to start learning a few of the basics, the Resources tab has some background information to get you started. Note that this is not an exhaustive list - the number of new R tutorials available on the internet seems to be growing exponentially.\n\nGetting Help With R problems\nI am happy to help you work through your R coding challenges, but there are a lot of you and only one of me. Moreover, I may not always know exactly how to fix your problem any better than you do. In order to make sure that I am not the primary obstacle to your ability to complete the class assignments, I’m asking that you use the following steps prior to emailing/Slacking me with your coding questions. When you send me a question, please let me know what you searched, why the solutions you found don’t work for you, and what output you are expecting We’ll spend a bit of time on asking better questions and getting better answers so don’t worry if you aren’t quite sure how this all works.\n\nGoogle it! Searching for help with R on Google can sometimes be tricky. Google is generally smart enough to figure out what you mean when you search for “r reproject polygons”, but if it does struggle, try searching for “rstats” instead (e.g. “rstats reproject polygons”). Also, since most of your R work will deal with the RSpatial packages, it’s often easier to just search for the package name and operation rather than the letter “r” (e.g. “sf reproject polygons”). I often paste the specific error message I get along with the spatial package I’m using to try and help Google find my solutions.\nAsk your colleagues We have an r_spatial chatroom at Slack where anyone in this class can ask questions and anyone can answer. Ask questions about code or class materials. You’ll likely have similar questions as your peers, and you’ll likely be able to answer other peoples’ questions too. As a bonus, Slack allows you to format code to make it easy for all of us to copy and paste your code and distinguish it from the rest of your question.\nUse the forums Two of the most important sources for help with R-coding are StackOverflow (a Q&A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse (i.e. you)). If you aren’t able to find an answer to your question from the thousands of existing questions, you can post your own. You’ll need to create a reproducible example so others can figure out what you’re trying to do and what error you’re receiving, but you’d be amazed how helpful the community can be.\nAsk me! Sign up for a time to meet with me during student hours at https://calendly.com/mattwilliamson/. I’ll want to know what searches you’ve tried (so I don’t chase down answers that you’ve already seen) and what approaches you’ve tried and why they haven’t worked. Remember, I’m here to help (but not write your code for you)."
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "Syllabus",
    "section": "Course Materials",
    "text": "Course Materials\n\nR and RStudio\nR is free, but it can sometimes be a pain to install and configure especially when dealing with spatial packages (we’ll talk more about why this is during class). To make life easier, I have set up an online RStudio server service, which lets you run a full instance of RStudio in your web browser. This means you won’t have to install anything on your computer and we should be able to avoid a number of the machine-specific issues that pop-up when 20 students have 20 different computers, operating systems (OS), etc. If you haven’t installed R on your local machine and would like some help getting that set up, there’ a useful set of instructions for installing R, RStudio, and all the tidyverse packages here.\n\n\nGit and Github Classroom\nAll assignments will be managed using Github classroom. This will allow each you to have your own repositories for each assignment and make it easier for me to comment on and help with your code. To use this, you should sign up for the GitHub Student Developers Pack as soon as possible and send me your github username. Once I have that, I can add you to the course and make sure that you have access to all of the necessary data and example code.\n\n\nReadings\nThe goal of this course is primarily to get you started with spatial workflows in R. That said, maps (and the spatial data that produce them) are extremely powerful. Although most of this course will focus on getting the code right, I’ll mix in a few readings each week to help tie the technical details of our code back to the broader contexts of spatial analysis."
  },
  {
    "objectID": "syllabus.html#course-schedule",
    "href": "syllabus.html#course-schedule",
    "title": "Syllabus",
    "section": "Course Schedule",
    "text": "Course Schedule\nThis course is organized in 4 sections:\n\nGetting Started: Data types in R, course tools, getting help, functional programming\nSpatial Data Operations in R\nStatistical Workflows for Spatial Data\nVisualizing Spatial Data\n\nThe schedule page provides an overview of what to expect each week.\nThis syllabus reflects a plan for the semester. Deviations may become necessary as the course progresses."
  },
  {
    "objectID": "syllabus.html#assignments-and-grades",
    "href": "syllabus.html#assignments-and-grades",
    "title": "Syllabus",
    "section": "Assignments and Grades",
    "text": "Assignments and Grades\nI teach this course because I believe that a) we can learn a lot about social and ecological processes by studying where they happen, b) integrating spatial analysis directly into statistical workflows makes those analyses more robust and reproducible, and c) overcoming coding challenges can provide a profound sense of accomplishment. That said, I recognize that there are many reasons that you are taking this course and that my objectives may differ from yours. In order to make sure that you get what you need out of this class, we’ll be using a mix of approaches for determining your grade in this course.\nSelf-assessment: During the first week of the course, I’m going to ask you to reflect on what you want out of this course (concepts, skills, practice, etc.). This assessment will help me do a better job of aligning the content of the course to your specific needs. We’ll check in on this mid-semester to make sure things are on track and again at the end of the semester to give you a chance to evaluate how well you did in the course. Grading for the self-assessment is described on the assignments page.\nExercises: There are four homework assignments, one for each ‘unit’ of the course. These exercises are designed to reinforce the material we cover in lecture, give you practice designing and implementing your own workflows, and build habits that promote reproducibility in science. Rather than assign arbitrary points to each assignment, I’m going to grade your assignments using the following ‘levels’ (inspired by Sarah K. Johnson’s description of her graduate data analysis course at Tufts):\n\nPlease Resubmit: This indicates that either your code does not run as written (i.e., your Rmarkdown document will not compile on my computer), you did not use Git as instructed, and/or that your responses to the questions I posed indicate that you do not quite understand the material as well as I would like. You’ll need to schedule an appointment to talk with me and we’ll work out what you need to do to get credit for the assignment. Although there isn’t a hard deadline for this resubmission, the assignments build on each other so it’s in your best interest to complete the resubmission before the next assignment. Failure to resubmit will result in no credit for the assignment.\nResubmit If You Like: This indicates that all of the code works as written and that you used Git, but that you may have missed some important concepts. Your are welcome to resubmit the assignment and address my comments to help polish the final product, but it is not required for you to get credit for the assignment.\nGood To Go: All of your code works, you completed the necessary Git steps, and all of the pieces are there and polished. I may have some minor comments, but I don’t need you to address them for this assignment.\n\nFinal Project: The final project asks you to conduct an entire spatial analysis from layout to results. Grades on the final project are based on your objectives and your self-assessment of whether or not you achieved those objectives. Your first draft of the final project will be due December 2. I’ll make comments based on the same categories for the assignments and you’ll have time to revise your submission prior to the final deadline of December 16.\nYou can find descriptions for all the assignments on the assignments page.\n\nGrades\nWe’ll use a form of contract grading to determine your grades in the course. Contract grading allows us to have a conversation about what you want out of the course, what you expect to put into it, and what I think you need to be successful in deploying the skills we learn here. Based on your goals for course, we’ll sign a contract that instantiates your objectives into the grade you’ll recieve for the course. Complete the assignments and meet your objectives and you’ll get the grade you chose.\nThe expectations for the grades are:\n\nA You complete all of the self-assessments and 4 of the assignments (including the final project) to the “Good to Go” level and 1 to the “Resubmit If You Like” level. In addition, you meet or exceed 90% of your objectives for the course and the final project.\nB You complete all of the self-assessments and 3 of the assignments (including the final project) to the “Good to Go” level and 2 to the “Resubmit If You Like” level. In addition, you meet or exceed 80% of your objectives for the course and the final project.\nC You complete all of the self-assessments and 2 of the assignments (including the final project) to the “Good to Go” level and 3 to the “Resubmit If You Like” level. In addition, you meet or exceed 70% of your objectives for the course and the final project.\nD You complete all of the self-assessments, and 1 of the assignments (including the final project) to the “Good to Go” level and 4 to the “Resubmit If You Like” level. In addition, you meet or exceed 60% of your objectives for the course and the final project.\n\n\n\nAttendance and incomplete assignments\nAttendance is an important part of this course. You are allowed to miss 2 classes without providing any justification (stuff happens). Beyond that, each additional absence will result in a 0.5 grading reduction (i.e., an A becomes and A-). Similarly, completing the assignments to a satisfactory level is vital to ensure you have a firm grip on the code and concepts. Hence, each assignment that fails to achieve a “Resubmit If You Like” will result in 0.5 grading reduction.\n\n\nLate work\nWith the exception of the self-assessments and the final project, there’s no such thing as late work. I would highly recommend staying caught up as much as possible, but if you need to turn something in late, that’s fine—there’s no penalty."
  },
  {
    "objectID": "syllabus.html#student-wellbeing",
    "href": "syllabus.html#student-wellbeing",
    "title": "Syllabus",
    "section": "Student Wellbeing",
    "text": "Student Wellbeing\nIf you are struggling for any reason (COVID, relationship, family, or life’s stresses) and believe these may impact your performance in the course, I encourage you to contact the Dean of Students at (208) 426-1527 or emaildeanofstundents@boisestate.edu for support. If you notice a significant change in your mood, sleep, feelings of hopelessness or a lack of self worth, consider connecting immediately with Counseling Services (1529 Belmont Street, Norco Building) at (208) 426-1459 or email healthservices@boisestate.edu.\n\nLearning during a pandemic\nIf you tell me you’re having trouble, I will not judge you or think less of you. I hope you’ll extend me the same grace.\nYou never owe me personal information about your health (mental or physical). You are always welcome to talk to me about things that you’re going through, though. If I can’t help you, I usually know somebody who can.\nIf you need extra help, or if you need more time with something, or if you feel like you’re behind or not understanding everything, do not suffer in silence! Talk to me! I will work with you. I promise."
  },
  {
    "objectID": "syllabus.html#this-course-was-designed-with-you-in-mind",
    "href": "syllabus.html#this-course-was-designed-with-you-in-mind",
    "title": "Syllabus",
    "section": "This course was designed with you in mind",
    "text": "This course was designed with you in mind\nI developed this course to provide a welcoming environment and effective, equitable learning experience for all students. If you encounter barriers in this course, please bring them to my attention so that I may work to address them.\n\nThis class’s community is inclusive.\nStudents in this class represent a rich variety of backgrounds and perspectives. The Human-Environment Systems group is committed to providing an atmosphere for learning that respects diversity and creates inclusive environments in our courses. While working together to build this community, we ask all members to: * share their unique experiences, values, and beliefs, if comfortable doing so.\n\nlisten deeply to one another.\nhonor the uniqueness of their peers.\nappreciate the opportunity we have to learn from each other in this community.\nuse this opportunity together to discuss ways in which we can create an inclusive environment in this course and across the campus community.\nrecognize opportunities to invite a community member to exhibit more inclusive, equitable speech or behavior—and then also invite them into further conversation. We also expect community members to respond with gratitude and to take a moment of reflection when they receive such an invitation, rather than react immediately from defensiveness.\nkeep confidential any discussions that the community has of a personal (or professional) nature, unless the speaker has given explicit permission to share what they have said.\nrespect the right of students to be addressed and referred to by the names and pronouns that correspond to their gender identities, including the use of non-binary pronouns.\n\n\n\nWe use each other’s preferred names and pronouns.\nI will ask you to let me know your preferred or adopted name and gender pronoun(s), and I will make those changes to my own records and address you that way in all cases.\nTo change to a preferred name so that it displays on all BSU sites, including Canvas and our course roster, contact the Registrar’s Office at (208) 426-4249. Note that only a legal name change can alter your name on BSU official and legal documents (e.g., your transcript).\n\n\nThis course is accessible to students with disabilities.\nI recognize that navigating your education and life can often be more difficult if you have disabilities. I want you to achieve at your highest capacity in this class. If you have a disability, I need to know if you encounter inequitable opportunities in my course related to:\n\naccessing and understanding course materials engaging with course materials and other students in the course\ndemonstrating your skills and knowledge on assignments and exams.\n\nIf you have a documented disability, you may be eligible for accommodations in all of your courses. To learn more, make an appointment with the university’s Educational Access Center.\n\n\nFor students responsible for children\nI recognize the unique challenges that can arise for students who are also parents or guardians of children. Any student needing to temporarily bring children or another dependent to class is welcome to do so to stay engaged with the class."
  },
  {
    "objectID": "syllabus.html#academic-integrity",
    "href": "syllabus.html#academic-integrity",
    "title": "Syllabus",
    "section": "Academic Integrity",
    "text": "Academic Integrity\nAcademic integrity is the principle that asks students to engage with their academic work to the fullest and to behave honestly, transparently, and ethically in every assignment and every interaction with a peer, professor, or research participant. When a strong culture of academic integrity is fostered by students and faculty in an academic program, students learn more, build positive relationships and collaborations, and can feel more confident in the value of their degrees.\nIn order to cultivate fairness and credibility, everyone must participate in upholding academic integrity. Students in this class are responsible for asking for help or clarification when it’s needed, speaking up when they see unethical behavior taking place, and understanding and adhering to the Student Code of Conduct, including the section on academic misconduct. Boise State and I take academic misconduct very seriously. It’s important to know that when a student engages in academic misconduct, I will report the incident to the Office of the Dean of Students. I also have the right to assign sanctions, which could include requirements to revise or redo work, complete educational assignments to learn about academic integrity, and grade penalties ranging from lower credit on an assignment to failing this class1. Students should learn more by reviewing the Student Code of Conduct."
  }
]